{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_flags(method, url):\n",
    "    if ssl_flag:\n",
    "        return request(method, url)\n",
    "    else:\n",
    "        return request(method, url, verify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get info using bs id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_dataservice_bs_id(url, bs_id, bs_attrs, pt_attrs, dx_attrs):\n",
    "    p = 5\n",
    "    bs_id = bs_id.rstrip('\\n')\n",
    "    bs_url = url + '/biospecimens/' + bs_id\n",
    "    # sys.stderr.write(bs_url + '\\n')\n",
    "    bs_info = ''\n",
    "    try:\n",
    "        bs_info = request_flags('GET', bs_url)\n",
    "    except Exception as e:\n",
    "        sys.stderr.write('Got error ' + str(e) + ', trying again after a pause of ' + str(p) + ' seconds\\n')\n",
    "        sleep(5)\n",
    "        try:\n",
    "            bs_info = request_flags('GET', bs_url)\n",
    "        except Exception as e1:\n",
    "            sys.stderr.write('Repeat failed with error ' + str(e1) + '\\n')\n",
    "            exit(1)\n",
    "    result = []\n",
    "    if bs_info.json()['_status']['code'] == 404:\n",
    "        result.append(bs_info.json()['_status']['message'])\n",
    "        sys.stderr.write(bs_id + ' not found!\\n')\n",
    "        return bs_id, result\n",
    "    dx_url = url + bs_info.json()['_links']['diagnoses']\n",
    "    dx_dict = {}\n",
    "    dx_obj = ''\n",
    "    try:\n",
    "        dx_obj = request_flags('GET', dx_url) if len(dx_attrs) > 0 else 'NoDX'\n",
    "    except Exception as e:\n",
    "        sys.stderr.write('Got error ' + str(e) + ', trying again after a pause of ' + str(p) + ' seconds\\n')\n",
    "        sleep(5)\n",
    "        try:\n",
    "            dx_obj = request_flags('GET', dx_url) if len(dx_attrs) > 0 else 'NoDX'\n",
    "        except Exception as e1:\n",
    "            sys.stderr.write('Repeat failed with error ' + str(e1) + '\\n')\n",
    "            exit(1)\n",
    "    # dir(bs_info)\n",
    "    pt_url = bs_info.json()['_links']['participant']\n",
    "    pt_info = ''\n",
    "    if len(pt_attrs) > 0:\n",
    "        try:\n",
    "            pt_info = request_flags('GET', url + pt_url)\n",
    "    \n",
    "        except Exception as e:\n",
    "            sys.stderr.write('Got error ' + str(e) + ', trying again after a pause of ' + str(p) + ' seconds\\n')\n",
    "            sleep(5)\n",
    "            try:\n",
    "                pt_info = request_flags('GET', url + pt_url)\n",
    "            except Exception as e1:\n",
    "                sys.stderr.write('Repeat failed with error ' + str(e1) + '\\n')\n",
    "                exit(1)\n",
    "        result.append(pt_info.json()['results']['kf_id'])\n",
    "    for attr in bs_attrs:\n",
    "        # sys.stderr.write(attr + ': ')\n",
    "        res = bs_info.json()['results'][attr]\n",
    "        if res is None:\n",
    "            res = 'NULL'\n",
    "        # sys.stderr.write(res + '\\n')\n",
    "        result.append(str(res))\n",
    "    for attr in pt_attrs:\n",
    "        # sys.stderr.write(attr + ': ')\n",
    "        res = pt_info.json()['results'][attr]\n",
    "        if res is None:\n",
    "            res = 'NULL'\n",
    "        # sys.stderr.write(res + '\\n')\n",
    "        result.append(res)\n",
    "    for attr in dx_attrs:\n",
    "        dx_dict[attr] = []\n",
    "        for cur_res in dx_obj.json()['results']:\n",
    "            dx_dict[attr].append(str(cur_res[attr]))\n",
    "        result.append(';'.join(dx_dict[attr]))\n",
    "                                 \n",
    "    return bs_id, result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query dataservice by pt ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_dataservice_pt_id(url, pt_id, bs_attrs, pt_attrs, dx_attrs, out_fh):\n",
    "    pt_id = pt_id.rstrip('\\n')\n",
    "    pt_url = url + '/participants/' + pt_id\n",
    "    try:\n",
    "    # sys.stderr.write(bs_url + '\\n')\n",
    "        pt_info = request_flags('GET', pt_url)\n",
    "        bs_url = pt_info.json()['_links']['biospecimens']\n",
    "        bs_list = request_flags('GET', url + bs_url)\n",
    "        res_set = []\n",
    "        for bs_info in bs_list.json()['results']:\n",
    "            dx_url = url + bs_info['_links']['diagnoses']\n",
    "            dx_dict = {}\n",
    "            dx_obj = request_flags('GET', dx_url) if len(dx_attrs) > 0 else 'NoDX'\n",
    "            # dir(bs_info)\n",
    "\n",
    "            result = []\n",
    "            result.append(bs_info['kf_id'])\n",
    "            result.append(pt_info.json()['results']['kf_id'])\n",
    "\n",
    "            for attr in bs_attrs:\n",
    "                # sys.stderr.write(attr + ': ')\n",
    "                res = bs_info[attr]\n",
    "                if res is None:\n",
    "                    res = 'NULL'\n",
    "                # sys.stderr.write(res + '\\n')\n",
    "                result.append(res)\n",
    "            for attr in pt_attrs:\n",
    "                # sys.stderr.write(attr + ': ')\n",
    "                res = pt_info.json()['results'][attr]\n",
    "                if res is None:\n",
    "                    res = 'NULL'\n",
    "                # sys.stderr.write(res + '\\n')\n",
    "                result.append(res)\n",
    "            for attr in dx_attrs:\n",
    "                dx_dict[attr] = []\n",
    "                for cur_res in dx_obj.json()['results']:\n",
    "                    dx_dict[attr].append(str(cur_res[attr]))\n",
    "                result.append(';'.join(dx_dict[attr]))\n",
    "            res_set.append('\\t'.join(result))\n",
    "        return res_set\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + '\\n')\n",
    "        sys.stderr.write('Had trouble processing ' + pt_id + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up imports and output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from requests import request\n",
    "import concurrent.futures\n",
    "from time import sleep\n",
    "# set to 1 for normal operation, 0 to ignore cert validation\n",
    "ssl_flag = 1\n",
    "fname = '/Users/brownm28/Documents/2018-Sep-25_Maris_FY16/peddy_results/bs_id_list.txt'\n",
    "file_list = fname\n",
    "bs_attrs = ['external_aliquot_id', 'analyte_type', 'source_text_tissue_type', 'composition', 'external_sample_id']\n",
    "# pt_attrs = ['external_id', 'gender', 'ethnicity', 'race']\n",
    "pt_attrs = []\n",
    "# dx_attrs = ['source_text_diagnosis', 'age_at_event_days', 'source_text_tumor_location']\n",
    "dx_attrs = []\n",
    "url = 'https://kf-api-dataservice.kidsfirstdrc.org/'\n",
    "out_fh = open('/Users/brownm28/Documents/2018-Sep-25_Maris_FY16/peddy_results/tum_ds_info.txt', 'w')\n",
    "out_fh.write('BS_ID\\tPT_ID\\t' + '\\t'.join(bs_attrs) + '\\t' + '\\t'.join(pt_attrs))\n",
    "if len(dx_attrs) > 0:\n",
    "    out_fh.write('\\t' + '\\t'.join(dx_attrs) )\n",
    "out_fh.write('\\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get by bs id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed 10 bs ids\n",
      "Processed 20 bs ids\n",
      "Processed 30 bs ids\n",
      "Processed 40 bs ids\n",
      "Processed 50 bs ids\n",
      "Processed 60 bs ids\n",
      "Processed 70 bs ids\n",
      "Processed 80 bs ids\n",
      "Processed 90 bs ids\n",
      "Processed 100 bs ids\n",
      "Processed 110 bs ids\n",
      "Processed 120 bs ids\n",
      "Processed 130 bs ids\n",
      "Processed 140 bs ids\n",
      "Processed 150 bs ids\n",
      "Processed 160 bs ids\n",
      "Processed 170 bs ids\n",
      "Processed 180 bs ids\n",
      "Processed 190 bs ids\n",
      "Processed 200 bs ids\n",
      "Processed 210 bs ids\n",
      "Processed 220 bs ids\n",
      "Processed 230 bs ids\n",
      "Processed 240 bs ids\n",
      "Processed 250 bs ids\n",
      "Processed 260 bs ids\n",
      "Processed 270 bs ids\n",
      "Processed 280 bs ids\n",
      "Processed 290 bs ids\n",
      "Processed 300 bs ids\n",
      "Processed 310 bs ids\n",
      "Processed 320 bs ids\n",
      "Processed 330 bs ids\n",
      "Processed 340 bs ids\n",
      "Processed 350 bs ids\n",
      "Processed 360 bs ids\n",
      "Processed 370 bs ids\n",
      "Processed 380 bs ids\n",
      "Processed 390 bs ids\n",
      "Processed 400 bs ids\n",
      "Processed 410 bs ids\n",
      "Processed 420 bs ids\n",
      "Processed 430 bs ids\n",
      "Processed 440 bs ids\n",
      "Processed 450 bs ids\n",
      "Processed 460 bs ids\n",
      "Processed 470 bs ids\n",
      "Processed 480 bs ids\n",
      "Processed 490 bs ids\n",
      "Processed 500 bs ids\n",
      "Processed 510 bs ids\n",
      "Processed 520 bs ids\n",
      "Processed 530 bs ids\n",
      "Processed 540 bs ids\n",
      "Processed 550 bs ids\n",
      "Processed 560 bs ids\n",
      "Processed 570 bs ids\n",
      "Processed 580 bs ids\n",
      "Processed 590 bs ids\n",
      "Processed 600 bs ids\n",
      "Processed 610 bs ids\n",
      "Processed 620 bs ids\n",
      "Processed 630 bs ids\n",
      "Processed 640 bs ids\n",
      "Processed 650 bs ids\n",
      "Processed 660 bs ids\n",
      "Processed 670 bs ids\n",
      "Processed 680 bs ids\n",
      "Processed 690 bs ids\n",
      "Processed 700 bs ids\n",
      "Processed 710 bs ids\n",
      "Processed 720 bs ids\n",
      "Processed 730 bs ids\n",
      "Processed 740 bs ids\n",
      "Processed 750 bs ids\n",
      "Processed 760 bs ids\n",
      "Processed 770 bs ids\n",
      "Processed 780 bs ids\n",
      "Processed 790 bs ids\n",
      "Processed 800 bs ids\n",
      "Processed 810 bs ids\n",
      "Processed 820 bs ids\n",
      "Processed 830 bs ids\n",
      "Processed 840 bs ids\n",
      "Processed 850 bs ids\n",
      "Processed 860 bs ids\n",
      "Processed 870 bs ids\n",
      "Processed 880 bs ids\n",
      "Processed 890 bs ids\n",
      "Processed 900 bs ids\n",
      "Processed 910 bs ids\n",
      "Processed 920 bs ids\n",
      "Processed 930 bs ids\n",
      "Processed 940 bs ids\n",
      "Processed 950 bs ids\n",
      "Processed 960 bs ids\n",
      "Processed 970 bs ids\n",
      "Processed 980 bs ids\n",
      "Processed 990 bs ids\n",
      "Processed 1000 bs ids\n",
      "Processed 1010 bs ids\n",
      "Processed 1020 bs ids\n",
      "Processed 1030 bs ids\n",
      "Processed 1040 bs ids\n",
      "Processed 1050 bs ids\n",
      "Processed 1060 bs ids\n",
      "Processed 1070 bs ids\n",
      "Processed 1080 bs ids\n",
      "Processed 1090 bs ids\n",
      "Processed 1100 bs ids\n",
      "Processed 1110 bs ids\n",
      "Processed 1120 bs ids\n",
      "Processed 1130 bs ids\n",
      "Processed 1140 bs ids\n",
      "Processed 1150 bs ids\n",
      "Processed 1160 bs ids\n",
      "Processed 1170 bs ids\n",
      "Processed 1180 bs ids\n",
      "Processed 1190 bs ids\n",
      "Processed 1200 bs ids\n",
      "Processed 1210 bs ids\n",
      "Processed 1220 bs ids\n",
      "Processed 1230 bs ids\n",
      "Processed 1240 bs ids\n",
      "Processed 1250 bs ids\n",
      "Processed 1260 bs ids\n",
      "Processed 1270 bs ids\n",
      "Processed 1280 bs ids\n",
      "Processed 1290 bs ids\n",
      "Processed 1300 bs ids\n",
      "Processed 1310 bs ids\n",
      "Processed 1320 bs ids\n",
      "Processed 1330 bs ids\n",
      "Processed 1340 bs ids\n",
      "Processed 1350 bs ids\n",
      "Processed 1360 bs ids\n",
      "Processed 1370 bs ids\n",
      "Processed 1380 bs ids\n",
      "Processed 1390 bs ids\n",
      "Processed 1400 bs ids\n",
      "Processed 1410 bs ids\n",
      "Processed 1420 bs ids\n",
      "Processed 1430 bs ids\n",
      "Processed 1440 bs ids\n",
      "Done!"
     ]
    }
   ],
   "source": [
    "\n",
    "x = 1\n",
    "m = 10\n",
    "th = 24\n",
    "with concurrent.futures.ThreadPoolExecutor(th) as bs_exec:\n",
    "    bs_results = {\n",
    "    bs_exec.submit(query_dataservice_bs_id, url, bs_id, bs_attrs, pt_attrs, dx_attrs): bs_id for bs_id in open(file_list)}\n",
    "    for bs_result in concurrent.futures.as_completed(bs_results):\n",
    "        if x % m == 0:\n",
    "            sys.stderr.write('Processed ' + str(x) + ' bs ids\\n')\n",
    "        (cur_bs_id, bs_info) = bs_result.result()\n",
    "        out_fh.write(cur_bs_id + '\\t' + '\\t'.join(bs_info) + '\\n')\n",
    "        x += 1\n",
    "out_fh.close()\n",
    "sys.stderr.write('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get by pt id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed 25 pt ids\n",
      "Processed 50 pt ids\n",
      "Processed 75 pt ids\n",
      "Processed 100 pt ids\n",
      "Processed 125 pt ids\n",
      "Processed 150 pt ids\n",
      "Processed 175 pt ids\n",
      "Processed 200 pt ids\n",
      "Processed 225 pt ids\n",
      "Processed 250 pt ids\n",
      "Processed 275 pt ids\n",
      "Processed 300 pt ids\n",
      "Processed 325 pt ids\n",
      "Processed 350 pt ids\n",
      "Processed 375 pt ids\n",
      "Processed 400 pt ids\n",
      "Processed 425 pt ids\n",
      "Processed 450 pt ids\n",
      "Processed 475 pt ids\n",
      "Processed 500 pt ids\n",
      "Processed 525 pt ids\n",
      "Processed 550 pt ids\n",
      "Processed 575 pt ids\n",
      "Processed 600 pt ids\n",
      "Processed 625 pt ids\n",
      "Processed 650 pt ids\n",
      "Processed 675 pt ids\n",
      "Processed 700 pt ids\n",
      "Processed 725 pt ids\n",
      "Processed 750 pt ids\n",
      "Processed 775 pt ids\n",
      "Processed 800 pt ids\n",
      "Processed 825 pt ids\n",
      "Processed 850 pt ids\n",
      "Processed 875 pt ids\n",
      "Processed 900 pt ids\n",
      "Processed 925 pt ids\n",
      "Processed 950 pt ids\n",
      "Processed 975 pt ids\n",
      "Processed 1000 pt ids\n",
      "Processed 1025 pt ids\n",
      "Processed 1050 pt ids\n",
      "Processed 1075 pt ids\n",
      "Processed 1100 pt ids\n",
      "Processed 1125 pt ids\n",
      "Processed 1150 pt ids\n",
      "Processed 1175 pt ids\n",
      "Processed 1200 pt ids\n",
      "Processed 1225 pt ids\n",
      "Processed 1250 pt ids\n",
      "Processed 1275 pt ids\n",
      "Processed 1300 pt ids\n",
      "Processed 1325 pt ids\n",
      "Processed 1350 pt ids\n",
      "Processed 1375 pt ids\n",
      "Processed 1400 pt ids\n",
      "Processed 1425 pt ids\n",
      "Processed 1450 pt ids\n",
      "Processed 1475 pt ids\n",
      "Processed 1500 pt ids\n",
      "Processed 1525 pt ids\n",
      "Processed 1550 pt ids\n",
      "Processed 1575 pt ids\n",
      "Processed 1600 pt ids\n",
      "Processed 1625 pt ids\n",
      "Processed 1650 pt ids\n",
      "Processed 1675 pt ids\n",
      "Processed 1700 pt ids\n",
      "Processed 1725 pt ids\n",
      "Processed 1750 pt ids\n",
      "Processed 1775 pt ids\n",
      "Processed 1800 pt ids\n",
      "Done!"
     ]
    }
   ],
   "source": [
    "#out_fh = open('/Users/brownm28/Documents/2019-Mar-22_cbttc-hakon/hakon_metadata.txt', 'w')\n",
    "x = 1\n",
    "m = 25\n",
    "th = 40\n",
    "with concurrent.futures.ThreadPoolExecutor(th) as pt_exec:\n",
    "    pt_results = {\n",
    "    pt_exec.submit(query_dataservice_pt_id, url, pt_id, bs_attrs, pt_attrs, dx_attrs, out_fh): pt_id for pt_id in open(file_list)}\n",
    "    for pt_result in concurrent.futures.as_completed(pt_results):\n",
    "        if x % m == 0:\n",
    "            sys.stderr.write('Processed ' + str(x) + ' pt ids\\n')\n",
    "        (res_list) = pt_result.result()\n",
    "        out_fh.write('\\n'.join(res_list) + '\\n')\n",
    "        x += 1\n",
    "out_fh.close()\n",
    "sys.stderr.write('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get info using cram - bs id pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cram_id_pair in open(file_list):\n",
    "    (cram, bs_id) = cram_id_pair.rstrip('\\n').split('\\t')\n",
    "    sys.stderr.write(cram + '\\t' + bs_id + '\\n')\n",
    "    bs_info = query_dataservice(url, bs_id, bs_attrs, pt_attrs)\n",
    "    sys.stdout.write(bs_id + '\\t' + '\\t'.join(bs_info) + '\\t' + cram + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get PT from study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pt_batch(cur_pt_res_dict, pt_ids):\n",
    "    pt_id = cur_pt_res_dict['kf_id']\n",
    "    pt_ids.append(pt_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def luke_study_walker(url, study_id):\n",
    "    f = 0\n",
    "    lim = 100\n",
    "    x = lim\n",
    "    next_link = ''\n",
    "    init_link = url + '/participants?study_id=' + study_id + '&limit=' + str(lim)\n",
    "    sys.stderr.write('Processing first batch of ' + str(lim) + ' ' + init_link + '\\n')\n",
    "    init_pt = request('GET', init_link)\n",
    "    pt_ids = []\n",
    "\n",
    "    if 'next' in init_pt.json()['_links']:\n",
    "        next_link = url + init_pt.json()['_links']['next'] + '&limit=' + str(lim)\n",
    "    else:\n",
    "        f = 1\n",
    "    # process_pt_batch(url, init_pt.json()['results'], file_dict, pt_bs_id_dict)\n",
    "    with concurrent.futures.ThreadPoolExecutor(40) as pt_exec:\n",
    "        pt_results = {pt_exec.submit(process_pt_batch, pt_res_dict, pt_ids): pt_res_dict\n",
    "                      for pt_res_dict in init_pt.json()['results']}\n",
    "    while f == 0:\n",
    "        x += lim\n",
    "        sys.stderr.write('Processing next batch of ' + str(lim) + ' ' + next_link + '\\n')\n",
    "        sys.stderr.flush()\n",
    "        next_pt = request('GET', next_link)\n",
    "        if 'next' in next_pt.json()['_links']:\n",
    "            next_link = url + next_pt.json()['_links']['next'] + '&limit=' + str(lim)\n",
    "        else:\n",
    "            f = 1\n",
    "            sys.stderr.write('Last batch\\n')\n",
    "        # multi-thread iterating through patient links\n",
    "        with concurrent.futures.ThreadPoolExecutor(40) as pt_exec:\n",
    "            pt_results = {pt_exec.submit(process_pt_batch, pt_res_dict, pt_ids): pt_res_dict\n",
    "                      for pt_res_dict in next_pt.json()['results']}\n",
    "\n",
    "    return pt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing first batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551727692.931717&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551727744.578031&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551727796.450033&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551727848.798689&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551727898.96681&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551727948.013785&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551727998.186601&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728047.762582&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728097.892586&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728146.460387&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728197.983571&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728245.670042&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728293.024227&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728342.230293&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728392.1438&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728441.309267&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728488.8676&study_id=SD_JWS3V24D&limit=100\n",
      "Processing next batch of 100 https://kf-api-dataservice.kidsfirstdrc.org//participants?after=1551728535.465329&study_id=SD_JWS3V24D&limit=100\n",
      "Last batch\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from requests import request\n",
    "import concurrent.futures\n",
    "from time import sleep\n",
    "\n",
    "study_id = 'SD_JWS3V24D'\n",
    "url = 'https://kf-api-dataservice.kidsfirstdrc.org/'\n",
    "pt_ids = luke_study_walker(url, study_id)\n",
    "out = open('/Users/brownm28/Documents/2019-Mar-22_cbttc-hakon/pt_ids.txt', 'w')\n",
    "out.write('\\n'.join(pt_ids))\n",
    "out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sequencing center by BS ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_center(bs_id):\n",
    "    p = 5\n",
    "    bs_id = bs_id.rstrip('\\n')\n",
    "    bs_url = url + \"/biospecimens/\" + bs_id\n",
    "    # sys.stderr.write(bs_url + '\\n')\n",
    "    bs_info = ''\n",
    "    try:\n",
    "        bs_info = request_flags('GET', bs_url)\n",
    "    except Exception as e:\n",
    "        sys.stderr.write('Got error ' + str(e) + ', trying again after a pause of ' + str(p) + ' seconds\\n')\n",
    "        sleep(5)\n",
    "        try:\n",
    "            bs_info = request_flags('GET', bs_url)\n",
    "        except Exception as e1:\n",
    "            sys.stderr.write('Repeat failed with error ' + str(e1) + '\\n')\n",
    "            exit(1)\n",
    "    seq_link = bs_info.json()['_links']['sequencing_center']\n",
    "    seq_info = ''\n",
    "    try:\n",
    "        seq_info = request_flags('GET', url + \"/\" + seq_link)\n",
    "    except Exception as e:\n",
    "        sys.stderr.write('Got error ' + str(e) + ', trying again after a pause of ' + str(p) + ' seconds\\n')\n",
    "        sleep(5)\n",
    "        try:\n",
    "            seq_info = request_flags('GET', url + \"/\" + seq_link)\n",
    "        except Exception as e1:\n",
    "            sys.stderr.write('Repeat failed with error ' + str(e1) + '\\n')\n",
    "            exit(1)\n",
    "    sq_id = seq_info.json()['results']['kf_id']\n",
    "    sq_name = seq_info.json()['results']['name']\n",
    "    info_list.append(\"\\t\".join([bs_id, sq_id, sq_name]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed 100 bs ids\n",
      "Processed 200 bs ids\n",
      "Processed 300 bs ids\n",
      "Processed 400 bs ids\n",
      "Processed 500 bs ids\n",
      "Processed 600 bs ids\n",
      "Processed 700 bs ids\n",
      "Processed 800 bs ids\n",
      "Processed 900 bs ids\n",
      "Processed 1000 bs ids\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from requests import request\n",
    "import concurrent.futures\n",
    "from time import sleep\n",
    "\n",
    "ssl_flag = 1\n",
    "bs_id_file = open('/Users/brownm28/Documents/PORTAL_LOADS/CBTTC_COMPLETE/2020-Jan-21_KF_UPDATE/rna_bs_ids.txt')\n",
    "bs_id_list = []\n",
    "url = 'https://kf-api-dataservice.kidsfirstdrc.org'\n",
    "for line in bs_id_file:\n",
    "    bs_id_list.append(line.rstrip('\\n'))\n",
    "info_list = []\n",
    "x = 1\n",
    "m = 100\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(40) as sq_exec:\n",
    "    sq_results = {sq_exec.submit(get_seq_center, bs_id): bs_id for bs_id in bs_id_list}\n",
    "    for sq_results in concurrent.futures.as_completed(sq_results):\n",
    "        if x % m == 0:\n",
    "            sys.stderr.write('Processed ' + str(x) + ' bs ids\\n')\n",
    "        x += 1\n",
    "\n",
    "sq_file = open('/Users/brownm28/Documents/PORTAL_LOADS/CBTTC_COMPLETE/2020-Jan-21_KF_UPDATE/seq_center_bd_ids.txt', 'w')\n",
    "sq_file.write('BS_ID\\tSQ_ID\\tSQ_Value\\n')\n",
    "for line in info_list:\n",
    "    sq_file.write(line + '\\n')\n",
    "sq_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
