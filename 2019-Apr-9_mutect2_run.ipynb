{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sevenbridges as sbg\n",
    "from sevenbridges.errors import SbgError\n",
    "from sevenbridges.http.error_handlers import rate_limit_sleeper, maintenance_sleeper\n",
    "import sys\n",
    "import re\n",
    "import concurrent.futures\n",
    "import pdb\n",
    "config = sbg.Config(profile='turbo')\n",
    "api = sbg.Api(config=config, error_handlers=[rate_limit_sleeper, maintenance_sleeper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_refs(api, project, exome_flag, calling_list, mode):\n",
    "    ref_dict = {}\n",
    "    ref_dict['indexed_reference_fasta'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.fasta'])[0]\n",
    "    ref_dict['reference_dict'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.dict'])[0]\n",
    "    ref_dict['af_only_gnomad_vcf'] = api.files.query(project=project, names=['af-only-gnomad.hg38.vcf.gz'])[0]\n",
    "    ref_dict['exac_common_vcf'] = api.files.query(project=project, names=['small_exac_common_3.hg38.vcf.gz'])[0]\n",
    "    ref_dict['wgs_calling_interval_list'] = api.files.query(project=project, names=[calling_list])[0]\n",
    "    ref_dict['exome_flag'] = exome_flag\n",
    "    ref_dict['vep_cache'] = api.files.query(project=project, names=['homo_sapiens_vep_93_GRCh38_convert_cache.tar.gz'])[0]\n",
    "    ref_dict['select_vars_mode'] = mode\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(src_task, prefix):\n",
    "    if re.search(prefix, src_task.name) and (suffix is None or re.search(suffix, src_task.name)):\n",
    "        try:\n",
    "            tumor_id = src_task.inputs[src_tumor_id]\n",
    "            normal_id = src_task.inputs[src_normal_id]\n",
    "            new_task_name = task_prefix + tumor_id + \" \" + normal_id\n",
    "            if new_task_name in task_dict:\n",
    "                sys.stderr.write('Duplicated, check inputs for ' + new_task_name + '\\n')\n",
    "                return None\n",
    "            else:\n",
    "                task_dict[new_task_name] = 1\n",
    "            inputs = {}\n",
    "            for key in ref_objs:\n",
    "                inputs[key] = ref_objs[key]\n",
    "            inputs['input_tumor_name'] = tumor_id\n",
    "            inputs['input_normal_name'] = normal_id\n",
    "            inputs['input_tumor_aligned'] = src_task.inputs[src_tumor_align]\n",
    "            inputs['input_normal_aligned'] = src_task.inputs[src_normal_align]\n",
    "            task = api.tasks.create(name=new_task_name, project=project, app=app_name, inputs=inputs, run=False)\n",
    "            task.inputs['output_basename'] = task.id\n",
    "            task.save()\n",
    "            return task.name + '\\t' + task.id + '\\n'\n",
    "        except Exception as e:\n",
    "            sys.stderr.write(str(e) + '\\n')\n",
    "            sys.stderr.write('Failed to parse and process input task ' + src_task.name + ' ' + src_task.id + '\\n')\n",
    "            exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project='kfdrc-harmonization/sd-bhjxbdqk-10'\n",
    "exome_flag = 'N'\n",
    "# set input names as different versions of pipe have them named differently\n",
    "src_tumor_align = 'input_tumor_aligned'\n",
    "src_normal_align = 'input_normal_aligned'\n",
    "src_tumor_id = 'input_tumor_name'\n",
    "src_normal_id = 'input_normal_name'\n",
    "task_prefix = 'CNMC_MUTECT2_SOMATIC RPT: '\n",
    "prefix = 'CNMC_MUTECT2_SOMATIC:'\n",
    "suffix = None\n",
    "\n",
    "ref_objs = get_refs(api, project, exome_flag)\n",
    "\n",
    "tasks = api.tasks.query(project=project, status='COMPLETED').all()\n",
    "app_name = project + '/kfdrc-mutect2-wf'\n",
    "i = 1\n",
    "n = 50\n",
    "task_dict={}\n",
    "out_fh = open('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/pnoc_wgs_tasks.txt', 'w')\n",
    "with concurrent.futures.ThreadPoolExecutor(8) as executor:\n",
    "    results = {executor.submit(get_inputs, task, prefix): task for task in tasks}\n",
    "    for result in concurrent.futures.as_completed(results):\n",
    "        if i % n == 0:\n",
    "            sys.stderr.write(str(i) + ' tasks set up\\n')\n",
    "        i += 1\n",
    "        if result.result() is not None:\n",
    "            out_fh.write(result.result())\n",
    "out_fh.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get error logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project='kfdrc-harmonization/sd-bhjxbdqk-8'\n",
    "for line in open('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/mutect2_fail_task_ids.txt'):\n",
    "    tid = line.rstrip('\\n')\n",
    "    task = api.tasks.get(tid)\n",
    "    i = 0\n",
    "    for job in task.get_execution_details().jobs:\n",
    "        if job.status == 'FAILED':\n",
    "            log_obj = api.files.get(id=job.logs['job.err.log'].id)\n",
    "            log_obj.download('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/' + tid + '_' + job.name + '.' + log_obj.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removed failed run outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-08'\n",
    "tasks = api.tasks.query(project=project, status='FAILED').all()\n",
    "files = api.files.query(project=project).all()\n",
    "out_fail = open('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/2019-04-16_1538_FAILED.txt', 'w')\n",
    "out_fail.write('Task ID\\tTask Name\\n')\n",
    "fail_list = []\n",
    "for task in tasks:\n",
    "    fail_list.append(task.id)\n",
    "    out_fail.write(task.id + '\\t' + task.name + '\\n')\n",
    "out_fail.close()\n",
    "del_log = open('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/2019-04-16_1538_FAILED_DEL.log', 'w')\n",
    "for fobj in files:\n",
    "    parts = fobj.name.split('.')\n",
    "    if parts[0] in fail_list:\n",
    "        # pdb.set_trace()\n",
    "        del_log.write('DELETING file from failed task ' + parts[0] + ' ' + fobj.name + '\\n')\n",
    "        del_log.flush()\n",
    "        # fobj.delete()\n",
    "        # break\n",
    "del_log.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove deprecated run outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-08'\n",
    "tasks = api.tasks.query(project=project, status='COMPLETED').all()\n",
    "files = api.files.query(project=project).all()\n",
    "out_fail = open('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/2019-04-17_1530_DEPRECATED.txt', 'w')\n",
    "out_fail.write('Task ID\\tTask Name\\n')\n",
    "fail_list = []\n",
    "for task in tasks:\n",
    "    if task.id == '5ea21b42-488a-4680-aced-225af61d0843':\n",
    "        pdb.set_trace()\n",
    "        hold=1\n",
    "    if re.search('CBTTC_MUTECT2_SOMATIC:', task.name):\n",
    "        fail_list.append(task.id)\n",
    "        out_fail.write(task.id + '\\t' + task.name + '\\t' + task.status + '\\n')\n",
    "out_fail.close()\n",
    "#pdb.set_trace()\n",
    "# del_log = open('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/2019-04-16_1600_DEPRECATED_DEL.log', 'w')\n",
    "# for fobj in files:\n",
    "#     parts = fobj.name.split('.')\n",
    "#     if parts[0] in fail_list:\n",
    "#         # pdb.set_trace()\n",
    "#         del_log.write('DELETING file from failed task ' + parts[0] + ' ' + fobj.name + '\\n')\n",
    "#         del_log.flush()\n",
    "#         fobj.delete()\n",
    "#         # break\n",
    "# del_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-09'\n",
    "tasks = api.tasks.query(project=project, status='COMPLETED').all()\n",
    "out_fh = open('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/pnoc_tasks.txt', 'w')\n",
    "for task in tasks:\n",
    "    if re.search('PNOC_WGS_MUTECT2', task.name):\n",
    "        out_fh.write(task.name  + '\\t' + task.id + '\\n')\n",
    "out_fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pnoc WES mutect2 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-m3dbxd12'\n",
    "calling_list = 'Strexome_targets_intersect_sorted_padded100.GRCh38.bed.gz'\n",
    "exome_flag = 'Y'\n",
    "mode = 'gatk'\n",
    "ref_objs = get_refs(api, project, exome_flag, calling_list, mode)\n",
    "manifest = open('/Users/brownm28/Documents/2019-Feb-27_cbttc_ngs_checkmate/pnoc_wes/tn_pairs_from_tasks.txt')\n",
    "head = next(manifest)\n",
    "tn_pairs = []\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    tn_pairs.append([info[0], info[1]])\n",
    "files = api.files.query(project=project).all()\n",
    "cram_file_objs = {}\n",
    "for file_obj in files:\n",
    "    if file_obj.name[-4:] == 'cram' and 'Reharmonization' in file_obj.tags:\n",
    "        cram_file_objs[file_obj.metadata['Kids First Biospecimen ID']] = file_obj\n",
    "app_name = project + '/kfdrc-mutect2-wf'\n",
    "out_fh = open('/Users/brownm28/Documents/2019-Apr-24_pnoc_wes_mutect2/pnoc_wes_tasks.txt', 'w')\n",
    "for pair in tn_pairs:\n",
    "    inputs = ref_objs\n",
    "    inputs['input_tumor_name'] = pair[0]\n",
    "    inputs['input_normal_name'] = pair[1]\n",
    "    inputs['input_tumor_aligned'] = cram_file_objs[pair[0]]\n",
    "    inputs['input_normal_aligned'] = cram_file_objs[pair[1]]\n",
    "    task_name = 'PNOC_WES_MUTECT2_SOMATIC: ' + pair[0] + ' ' + pair[1]\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=inputs, run=False)\n",
    "    inputs['output_basename'] = task.id\n",
    "    task.save()\n",
    "    out_fh.write(task_name + '\\t' + task.id + '\\n')\n",
    "out_fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## manual run tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_info in open('/Users/brownm28/Documents/2019-Apr-24_pnoc_wes_mutect2/pnoc_wes_tasks.txt'):\n",
    "    (tname, tid) = task_info.rstrip('\\n').split('\\t')\n",
    "    task = api.tasks.get(tid)\n",
    "    if task.status == 'DRAFT':\n",
    "        try:\n",
    "            task.run()\n",
    "        except Exception as e:\n",
    "            sys.stderr.write('Could not run task becaause of ' + str(e) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compare task ID with output IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'PNOC_WES_MUTECT2_SOMATIC'\n",
    "project = 'kfdrc-harmonization/sd-m3dbxd12'\n",
    "tasks = api.tasks.query(status='COMPLETED', project=project).all()\n",
    "for task in tasks:\n",
    "    if re.match(prefix, task.name):\n",
    "        print (task.name + '\\t' + task.id + '\\t' + task.outputs['mutect2_vep_vcf'].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PNOC WGS Single Genotype Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_refs(api):\n",
    "    ref_dict = {}\n",
    "    ref_dict['axiomPoly_resource_vcf'] = api.files.query(project=project, names=['Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz'])[0]\n",
    "    ref_dict['reference_dict'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.dict'])[0]\n",
    "    ref_dict['dbsnp_vcf'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.dbsnp138.vcf'])[0]\n",
    "    ref_dict['hapmap_resource_vcf'] = api.files.query(project=project, names=['hapmap_3.3.hg38.vcf.gz'])[0]\n",
    "    ref_dict['mills_resource_vcf'] = api.files.query(project=project, names=['Mills_and_1000G_gold_standard.indels.hg38.vcf.gz'])[0]\n",
    "    ref_dict['omni_resource_vcf'] = api.files.query(project=project, names=['1000G_omni2.5.hg38.vcf.gz'])[0]\n",
    "    ref_dict['one_thousand_genomes_resource_vcf'] = api.files.query(project=project, names=['1000G_phase1.snps.high_confidence.hg38.vcf.gz'])[0]\n",
    "    ref_dict['ref_fasta'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.fasta'])[0]\n",
    "    ref_dict['ref_tar_gz'] = api.files.query(project=project, names=['hg38_snpeff.tgz'])[0]\n",
    "    ref_dict['unpadded_intervals_file'] = api.files.query(project=project, names=['hg38.even.handcurated.20k.intervals'])[0]\n",
    "    ref_dict['wgs_evaluation_interval_list'] = api.files.query(project=project, names=['wgs_evaluation_regions.hg38.interval_list'])[0]\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-09'\n",
    "manifest = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/controlfreec/pnoc_snp_Call/gvcf-manifest.csv')\n",
    "head = next(manifest)\n",
    "ref_obj = get_refs(api)\n",
    "app_name = project + \"/kf-single-genotype\"\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    in_dict = {}\n",
    "    for key in ref_obj:\n",
    "        in_dict[key] = ref_obj[key]\n",
    "    in_dict['input_vcfs'] = api.files.get(info[0])\n",
    "    task_name = \"SINGLE GENOTYPE GATK: \" + info[6] + \" \" + info[12]\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "    task.inputs['output_vcf_basename'] = task.id\n",
    "    task.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun VCF2MAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vep_refs(api):\n",
    "    try:\n",
    "        ref_dict = {}\n",
    "        ref_dict['reference'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.fasta'])[0]\n",
    "        #ref_dict['cache'] = api.files.query(project=project, names=['homo_sapiens_vep_93_GRCh38_convert_cache.tar.gz'])[0]\n",
    "        ref_dict['cache'] = api.files.get('5d701792e4b0950c45b0d798')\n",
    "        ref_dict['tool_name'] = tool_name\n",
    "        ref_dict['strip_info'] = strip_info\n",
    "        return ref_dict\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"failed setting up refs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_vep_task(line):\n",
    "    try:\n",
    "        info = line.rstrip('\\n').split(',')\n",
    "        in_dict = {}\n",
    "        for key in ref_objs:\n",
    "            in_dict[key] = ref_objs[key]\n",
    "        in_dict['tumor_id'] = info[tid]\n",
    "        in_dict['normal_id'] = info[nid]\n",
    "        in_dict['input_vcf'] = api.files.get(info[0])\n",
    "        task_name = task_prefix + \" \" + info[tid] + \" \" + info[nid]\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "        task.inputs['output_basename'] = task.id\n",
    "        task.save()\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"failed setting up task\")\n",
    "#         pdb.set_trace()\n",
    "#         hold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/pbta-lancet-vardict-analysis'\n",
    "app_name = project + '/temp-rerun-vcf2maf'\n",
    "tool_name = 'lancet'\n",
    "strip_info = \"INFO/CSQ\"\n",
    "task_prefix = \"VCF2MAF LANCET WGS PBTA RPT:\"\n",
    "ref_objs = get_vep_refs(api)\n",
    "manifest_fn = '/Users/brownm28/Documents/2019-Nov-12_PBTA_v10/pbta_lancet_WGS-manifest.csv'\n",
    "manifest = open(manifest_fn)\n",
    "head = next(manifest)\n",
    "header = head.rstrip('\\n').split(',')\n",
    "tid = -5\n",
    "nid = -7\n",
    "# pdb.set_trace()\n",
    "with concurrent.futures.ThreadPoolExecutor(8) as executor:\n",
    "    results = {executor.submit(set_up_vep_task, line): line for line in manifest}\n",
    "# for line in manifest:\n",
    "#     set_up_vep_task(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
