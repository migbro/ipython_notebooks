{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sevenbridges as sbg\n",
    "from sevenbridges.errors import SbgError\n",
    "from sevenbridges.http.error_handlers import rate_limit_sleeper, maintenance_sleeper\n",
    "import sys\n",
    "import re\n",
    "import pdb\n",
    "import concurrent.futures\n",
    "from requests import request\n",
    "config = sbg.Config(profile='turbo')\n",
    "api = sbg.Api(config=config, error_handlers=[rate_limit_sleeper, maintenance_sleeper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process tasks and tag files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_file(fobj, r_dict, task):\n",
    "    try:\n",
    "        for key in r_dict:\n",
    "            fobj.metadata[key] = r_dict[key]\n",
    "        # fobj.save()\n",
    "        if somatic_flag == 1:\n",
    "            # pdb.set_trace()\n",
    "            fobj.metadata['Kids First Biospecimen ID Normal'] = task.inputs[norm_key]\n",
    "    except Exception as e:\n",
    "        log_file.write('Could not tag ' + fobj.name + ', got error ' + str(e) + '\\n')\n",
    "        log_file.flush()\n",
    "        sys.exit(1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_task(api, r_dict, task, run_pre, id_pre, log_file):\n",
    "    try:\n",
    "        if re.search(run_pre, task.name) and re.search(id_pre, task.name):\n",
    "            id_parse = re.search(id_pre, task.name)\n",
    "            id_value = id_parse.group(0)\n",
    "            log_file.write('Tagging files from ' + task.id + ' ' + task.name + '\\n')\n",
    "            log_file.flush()\n",
    "            id_list = []\n",
    "            for output in task.outputs:\n",
    "                if task.outputs[output] is None:\n",
    "                    log_file.write('No file for key ' + output + ', skipping' + '\\n')\n",
    "                    next\n",
    "                elif type(task.outputs[output]) is list:\n",
    "                    for subfile in task.outputs[output]:\n",
    "                        id_list.append(subfile.id)\n",
    "                else:\n",
    "                    id_list.append(task.outputs[output].id)\n",
    "            task_files = api.files.bulk_get(id_list)\n",
    "            fobj_list = []\n",
    "            for task_file in task_files:\n",
    "                tag_file(task_file.resource, r_dict[id_value], task)\n",
    "                fobj_list.append(task_file.resource)\n",
    "            api.files.bulk_update(fobj_list)\n",
    "    except Exception as e:\n",
    "        log_file.write('Error processing task ' + task.id + ' ' + task.name + ' with error: ' + str(e) + '\\n')\n",
    "        log_file.flush()\n",
    "        sys.exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize metadata dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var that might need editing\n",
    "metadata = open('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/metadata_tagging/pnoc_wes_metadata.txt')\n",
    "project = 'kfdrc-harmonization/sd-m3dbxd12'\n",
    "run_pre = 'PNOC_WES_MUTECT2_SOMATIC'\n",
    "id_pre = 'BS_\\w+'\n",
    "norm_key = 'input_normal_name'\n",
    "# parse sample ID rnaseq style - with 7316 only (set to 1), or as-is in DS (set to 0)\n",
    "samp_flag = 0\n",
    "# if somatic, will grab normal id from task\n",
    "somatic_flag = 1\n",
    "log_file = open('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/metadata_tagging/pnoc_wes_tagging.log', 'a')\n",
    "rna_tblhead2sbg_dict = {'BS_ID':'Kids First Biospecimen ID', 'PT_ID': 'Kids First Participant ID',\n",
    "               'external_aliquot_id': 'aliquot_id', 'source_text_tissue_type': 'sample_type',\n",
    "                    'source_text_tumor_descriptor': 'Tumor Descriptor', 'composition': 'Composition', 'external_sample_id': 'sample_id',\n",
    "                   'external_id': 'case_id', 'gender': 'gender', 'ethnicity': 'ethnicity', 'race': 'race',\n",
    "                   'source_text_diagnosis': 'disease_type', 'source_text_tumor_location': 'primary_site',\n",
    "                   'age_at_event_days': 'age_at_diagnosis', 'platform': 'platform', 'experiment_strategy': 'experimental_strategy'}\n",
    "\n",
    "# SOMATIC CALLER MODE\n",
    "somatic_tblhead2sbg_dict = {'BS_ID':'Kids First Biospecimen ID Tumor', 'PT_ID': 'Kids First Participant ID',\n",
    "               'external_aliquot_id': 'aliquot_id', 'source_text_tissue_type': 'sample_type',\n",
    "                    'source_text_tumor_descriptor': 'Tumor Descriptor', 'composition': 'Composition', 'external_sample_id': 'sample_id',\n",
    "                   'external_id': 'case_id', 'gender': 'gender', 'ethnicity': 'ethnicity', 'race': 'race',\n",
    "                   'source_text_diagnosis': 'disease_type', 'source_text_tumor_location': 'primary_site',\n",
    "                   'age_at_event_days': 'age_at_diagnosis'}\n",
    "\n",
    "tblhead2sbg_dict = somatic_tblhead2sbg_dict\n",
    "\n",
    "r_dict = {}\n",
    "fixed_values = {'reference_genome': 'GRCh38', 'experimental_strategy': 'WGS', 'platform': 'Illumina' }\n",
    "head = next(metadata)\n",
    "header = head.rstrip('\\n').split('\\t')\n",
    "\n",
    "for line in metadata:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    bs_id = info[0] \n",
    "    r_dict[bs_id] = {}\n",
    "    for i in range(0, len(header)):\n",
    "        if header[i] in tblhead2sbg_dict:\n",
    "            try:\n",
    "                if header[i] == 'age_at_event_days':\n",
    "                    if info[i] == 'None' or info[i] == '':\n",
    "                        r_dict[bs_id][tblhead2sbg_dict[header[i]]] = None\n",
    "                    else:\n",
    "                        ages = info[i].split(';')\n",
    "                        for j in range(len(ages)):\n",
    "                            if ages[j] == 'None':\n",
    "                                del ages[j]\n",
    "                                break\n",
    "                        ages = list(map(int, ages))\n",
    "                        ages.sort()\n",
    "                        r_dict[bs_id][tblhead2sbg_dict[header[i]]] = ages[0]\n",
    "                elif header[i] == 'external_sample_id' and samp_flag == 1:\n",
    "                    samp_parts = info[i].split('-')\n",
    "                    r_dict[bs_id][tblhead2sbg_dict[header[i]]] = samp_parts[0] + '-' + samp_parts[1]\n",
    "                elif header[i] == 'source_text_diagnosis':\n",
    "                    info[i] = info[i].replace(\"'\", \"\")\n",
    "                    r_dict[bs_id][tblhead2sbg_dict[header[i]]] = info[i]\n",
    "                else:\n",
    "                    r_dict[bs_id][tblhead2sbg_dict[header[i]]] = info[i]\n",
    "            except Exception as e:\n",
    "                sys.stderr.write('Error processing metadata ' + str(e) + '\\n')\n",
    "                pdb.set_trace()\n",
    "                hold = 1\n",
    "        for fixed_value in fixed_values:\n",
    "            r_dict[bs_id][fixed_value] = fixed_values[fixed_value]\n",
    "\n",
    "tasks = api.tasks.query(project=project, status='COMPLETED').all()\n",
    "# quick_test\n",
    "# tasks = []\n",
    "# tasks.append(api.tasks.get(id='19b9b64d-6fc8-46b6-b9dc-5b0dfbedf4f2'))\n",
    "# tasks.append(api.tasks.get(id='612679ff-e6ba-425f-b0c7-8ef67ba09474'))\n",
    "# for task in tasks:\n",
    "#    process_task(api, r_dict, task, run_pre, id_pre, log_file)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(4) as executor:\n",
    "    results = {executor.submit(process_task, api, r_dict, task, run_pre, id_pre, log_file): task for task in tasks}\n",
    "log_file.write('Done!\\n')\n",
    "log_file.flush()\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clear out errant metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untag_file(fobj):\n",
    "    try:\n",
    "        for key in fobj.metadata:\n",
    "            fobj.metadata[key] = None\n",
    "    except Exception as e:\n",
    "        log_file.write('Could not tag ' + fobj.name + ', got error ' + str(e) + '\\n')\n",
    "        log_file.flush()\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_task(api, task, run_pre, id_pre, log_file):\n",
    "    try:\n",
    "        if re.search(run_pre, task.name) and re.search(id_pre, task.name):\n",
    "            id_parse = re.search(id_pre, task.name)\n",
    "            id_value = id_parse.group(0)\n",
    "            log_file.write('Untagging files from ' + task.id + ' ' + task.name + '\\n')\n",
    "            log_file.flush()\n",
    "            id_list = []\n",
    "            for output in task.outputs:\n",
    "                if task.outputs[output] is None:\n",
    "                    log_file.write('No file for key ' + output + ', skipping' + '\\n')\n",
    "                    next\n",
    "                elif type(task.outputs[output]) is list:\n",
    "                    for subfile in task.outputs[output]:\n",
    "                        id_list.append(subfile.id)\n",
    "                else:\n",
    "                    id_list.append(task.outputs[output].id)\n",
    "            task_files = api.files.bulk_get(id_list)\n",
    "            fobj_list = []\n",
    "            for task_file in task_files:\n",
    "                untag_file(task_file.resource)\n",
    "                fobj_list.append(task_file.resource)\n",
    "            api.files.bulk_update(fobj_list)\n",
    "    except Exception as e:\n",
    "        log_file.write('Error processing task ' + task.id + ' ' + task.name + ' with error: ' + str(e) + '\\n')\n",
    "        log_file.flush()\n",
    "        sys.exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YASS\n"
     ]
    }
   ],
   "source": [
    "check = input()\n",
    "if check != 'YASS':\n",
    "    raise SystemExit()\n",
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-08'\n",
    "#tasks = api.tasks.query(project=project, status='COMPLETED').all()\n",
    "# quick_test\n",
    "tasks = []\n",
    "tasks.append(api.tasks.get(id='089b5063-561c-46e2-82c4-21d0ed283720'))\n",
    "tasks.append(api.tasks.get(id='7c6e5751-2bd3-4f0d-ba77-57c7a8231b49'))\n",
    "run_pre = 'CBTTC_MUTECT2_SOMATIC_RPT'\n",
    "id_pre = 'BS_\\w+'\n",
    "log_file = open('/Users/brownm28/Documents/2019-Apr-9_mutect2_run/metadata_tagging/untag_log.txt', 'a')\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(deprocess_task, api, task, run_pre, id_pre, log_file): task for task in tasks}\n",
    "log_file.write('Done!\\n')\n",
    "log_file.flush()\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNAfusion-FQ_INPUT: BS_F0JB4EAK C021_0003\n",
      "RNAfusion-FQ_INPUT: BS_21ET39G7 C021_0006_progression\n",
      "RNAfusion-FQ_INPUT: BS_49CJNZ06 C021_0011\n",
      "RNAfusion-FQ_INPUT: BS_H97S5SQN C021_0032\n",
      "RNAfusion-FQ_INPUT: BS_NGSG2KB6 C021_0012\n",
      "RNAfusion-FQ_INPUT: BS_XM1AHBDJ C021_0017\n",
      "RNAfusion-FQ_INPUT: BS_JQVAWTTM C021_0001\n",
      "RNAfusion-FQ_INPUT: BS_7WM3MNZ0 C021_0029\n",
      "RNAfusion-FQ_INPUT: BS_R7NTZR4C C021_0009\n",
      "RNAfusion-FQ_INPUT: BS_W7MFJZ5A C021_0019\n",
      "RNAfusion-FQ_INPUT: BS_XGDPK33A C021_0035\n",
      "RNAfusion-FQ_INPUT: BS_QNNX91SM C021_0020\n",
      "RNAfusion-FQ_INPUT: BS_YDEVMD24 C021_0005\n",
      "RNAfusion-FQ_INPUT: BS_8ZY4GST0 C021_0004\n",
      "RNAfusion-FQ_INPUT: BS_X4DD4KSZ C021_0030\n",
      "RNAfusion-FQ_INPUT: BS_5VPM0F36 C021_0010\n",
      "RNAfusion-FQ_INPUT: BS_ZF6BSFNF C021_0022\n",
      "RNAfusion-FQ_INPUT: BS_2JP7RBMB C021_0027\n",
      "RNAfusion-FQ_INPUT: BS_0ZA67BBC C021_0016\n",
      "RNAfusion-FQ_INPUT: BS_1N7MQZGR C021_0005_progression\n",
      "RNAfusion-FQ_INPUT: BS_R9B92M75 C021_0036\n",
      "RNAfusion-FQ_INPUT: BS_NEVYM2FP C021_0031\n",
      "RNAfusion-FQ_INPUT: BS_JB43XBCQ C021_0013\n",
      "RNAfusion-FQ_INPUT: BS_Z3RCA1T9 C021_0025\n",
      "RNAfusion-FQ_INPUT: BS_6M2053M0 C021_0034\n",
      "RNAfusion-FQ_INPUT: BS_GWSJ4Z9H C021_0002\n",
      "RNAfusion-FQ_INPUT: BS_68KX6A42 C021_0033\n",
      "RNAfusion-FQ_INPUT: BS_G3NN392N C021_0007\n",
      "RNAfusion-FQ_INPUT: BS_NB9XXBW6 C021_0008\n",
      "RNAfusion-FQ_INPUT: BS_EZ3147MX C021_0026\n",
      "RNAfusion-FQ_INPUT: BS_FCDAH728 C021_0006\n",
      "RNAfusion-FQ_INPUT: BS_C83TK159 C021_0021\n"
     ]
    }
   ],
   "source": [
    "project='kfdrc-harmonization/sd-bhjxbdqk-11'\n",
    "tasks = api.tasks.query(project=project, status='COMPLETED')\n",
    "for task in tasks:\n",
    "    if re.search('RNAfusion-', task.name):\n",
    "        print (task.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tag PNOC 0008 outputs using table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_table = open('/Users/brownm28/Documents/2019-May-7_PNOC008/annotated_metadata.txt')\n",
    "head = next(meta_table)\n",
    "header = head.rstrip('\\n').split('\\t')\n",
    "i_start = 3\n",
    "id_list = []\n",
    "meta_dict = {}\n",
    "for line in meta_table:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    fid = info[0]\n",
    "    id_list.append(fid)\n",
    "    meta_dict[fid] = {}\n",
    "    for i in range(i_start, len(header), 1):\n",
    "        meta_dict[fid][header[i]] = info[i]\n",
    "file_bulk = api.files.bulk_get(id_list)\n",
    "\n",
    "f_objs = []\n",
    "for f_bulk in file_bulk:\n",
    "    cur_obj = f_bulk.resource\n",
    "    cur_id = cur_obj.id\n",
    "    for key in meta_dict[cur_id]:\n",
    "        cur_obj.metadata[key] = meta_dict[cur_id][key]\n",
    "    f_objs.append(cur_obj)\n",
    "update = api.files.bulk_update(f_objs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
