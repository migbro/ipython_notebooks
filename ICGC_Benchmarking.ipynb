{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sevenbridges as sbg\n",
    "from sevenbridges.errors import SbgError\n",
    "from sevenbridges.http.error_handlers import rate_limit_sleeper, maintenance_sleeper\n",
    "import sys\n",
    "import re\n",
    "import concurrent.futures\n",
    "import pdb\n",
    "config = sbg.Config(profile='turbo')\n",
    "api = sbg.Api(config=config, error_handlers=[rate_limit_sleeper, maintenance_sleeper])\n",
    "project = 'brownm28/kfdrc-benchmarking'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagged PCAWG.11d167fc-2ff3-42e0-b064-b11ad64d456f.bam\n",
      "Tagged PCAWG.20b85de1-8cc4-4a57-baa8-656cdde95fa9.bam\n",
      "Tagged PCAWG.222f5df2-cab8-4e0f-8e65-cfb1862779ca.bam\n",
      "Tagged PCAWG.29034096-d0af-4a86-b348-1c918253a9ef.bam\n",
      "Tagged PCAWG.3b8eb3f9-0ebb-4da8-bb18-7d1bf75ce527.bam\n",
      "Tagged PCAWG.47071d63-9223-4faf-9a50-3af9c6c9492e.bam\n",
      "Tagged PCAWG.67455c36-aa47-4cc4-8b6d-9a9012b616ed.bam\n",
      "Tagged PCAWG.80304de2-8f90-4d66-a991-f1102cfb3eb9.bam\n",
      "Tagged PCAWG.b75e14f5-11dd-4a0c-a072-304f9ea40885.bam\n"
     ]
    }
   ],
   "source": [
    "bam_manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/repository_1560614429.tsv')\n",
    "cav_file_list = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jun-20_set.csv')\n",
    "header_key = {\"ICGC Donor\": \"case_id\", \"Specimen ID\": \"aliquot_id\", \"Sample ID\": \"sample_id\", \"Project\": \"disease_type\"}\n",
    "head = next(bam_manifest)\n",
    "header = head.rstrip('\\n').split('\\t')\n",
    "meta_dict = {}\n",
    "for line in bam_manifest:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    fname = info[3]\n",
    "    info[9] = info[9].split('-')[0]\n",
    "    spec_type = info[6]\n",
    "    spec_type = spec_type.replace('tumour', 'tumor')\n",
    "    (sample_type, Composition) = spec_type.split(' - ')\n",
    "    meta_dict[fname] = {}\n",
    "    meta_dict[fname]['reference_genome'] = 'hg19'\n",
    "    for key in header_key:\n",
    "        try:\n",
    "            meta_dict[fname][header_key[key]] = info[header.index(key)]\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "            hold = 1\n",
    "    meta_dict[fname]['sample_type'] = sample_type\n",
    "    meta_dict[fname]['Composition'] = Composition\n",
    "    # pdb.set_trace()\n",
    "    # hold = 1\n",
    "\n",
    "head = next(cav_file_list)\n",
    "for line in cav_file_list:\n",
    "    fields = line.rstrip('\\n').split(',')\n",
    "    (fid, fname) = (fields[0], fields[1])\n",
    "    file_obj = api.files.get(fid)\n",
    "    \n",
    "    for key in meta_dict[fname]:\n",
    "        file_obj.metadata[key] = meta_dict[fname][key]\n",
    "    sys.stderr.write('Tagged ' + fname + '\\n')\n",
    "    file_obj.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index bams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cav_file_list = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jun-20_set.csv')\n",
    "head = next(cav_file_list)\n",
    "app_name = project + '/samtools-index'\n",
    "for line in cav_file_list:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    bam = api.files.get(info[0])\n",
    "    in_dict = {}\n",
    "    in_dict['input_reads'] = bam\n",
    "    in_dict['threads'] = 4\n",
    "    task_name = 'SAMTOOLS INDEX: ' + bam.metadata['sample_id']\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=True)\n",
    "    task.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Lancet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_refs(api, project):\n",
    "    ref_dict = {}\n",
    "    ref_dict['indexed_reference_fasta'] = api.files.query(project=project, names=['hs37d5.fa'])[0]\n",
    "    ref_dict['reference_dict'] = api.files.query(project=project, names=['hs37d5.dict'])[0]\n",
    "    ref_dict['wgs_calling_interval_list'] = api.files.query(project=project, names=['b37_wgs_calling_regions.bed'])[0]\n",
    "    # ref_dict['wgs_calling_interval_list'] = api.files.query(project=project, names=['PCAWG_super_merged_target.bed'])[0]\n",
    "    # ref_dict['exome_flag'] = 'Y'\n",
    "    ref_dict['exome_flag'] = 'N'\n",
    "    ref_dict['select_vars_mode'] = 'gatk'\n",
    "    # ref_dict['window'] = 600\n",
    "    ref_dict['window'] = 500\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/kfdrc-lancet-wf-benchmark'\n",
    "manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jul-12_big_run/all_wgs_bams.csv')\n",
    "ref_objs = get_refs(api, project)\n",
    "head = next(manifest)\n",
    "bam_dict = {}\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[-1]\n",
    "    sample_id = info[-3]\n",
    "    fid = info[0]\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    bam_dict[case_id][stype] = {}\n",
    "    bam_dict[case_id][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][stype]['file_obj'] = api.files.get(fid)\n",
    "for case_id in bam_dict:\n",
    "    in_dict = {}\n",
    "    for key in ref_objs:\n",
    "        in_dict[key] = ref_objs[key]\n",
    "    tumor = ''\n",
    "    normal = ''\n",
    "    for stype in bam_dict[case_id]:\n",
    "        if stype == 'Normal':\n",
    "            in_dict['input_normal_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            normal = bam_dict[case_id][stype]['sid']\n",
    "        else:\n",
    "            in_dict['input_tumor_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            tumor = bam_dict[case_id][stype]['sid']\n",
    "    # task_name = 'LANCET EXOME REGION: ' + case_id + ' ' + tumor + ' ' + normal\n",
    "    task_name = 'LANCET WGS BENCHMARK: ' + case_id + ' ' + tumor + ' ' + normal\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "    task.inputs['output_basename'] = task.id\n",
    "    task.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark mutect2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutect_refs(api, project):\n",
    "    ref_dict = {}\n",
    "    ref_dict['indexed_reference_fasta'] = api.files.query(project=project, names=['hs37d5.fa'])[0]\n",
    "    ref_dict['reference_dict'] = api.files.query(project=project, names=['hs37d5.dict'])[0]\n",
    "    ref_dict['wgs_calling_interval_list'] = api.files.query(project=project, names=['b37_wgs_calling_regions.bed'])[0]\n",
    "    ref_dict['af_only_gnomad_vcf'] = api.files.query(project=project, names=['af-only-gnomad.raw.sites.b37.vcf.gz'])[0]\n",
    "    ref_dict['exac_common_vcf'] = api.files.query(project=project, names=['small_exac_common_3_b37.vcf.gz'])[0]\n",
    "    ref_dict['exome_flag'] = 'N'\n",
    "    ref_dict['select_vars_mode'] = 'gatk'\n",
    "    return ref_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/kfdrc-mutect2-sans-vep'\n",
    "manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jul-12_big_run/all_wgs_bams.csv')\n",
    "ref_objs = get_mutect_refs(api, project)\n",
    "head = next(manifest)\n",
    "bam_dict = {}\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[-1]\n",
    "    sample_id = info[-3]\n",
    "    fid = info[0]\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    bam_dict[case_id][stype] = {}\n",
    "    bam_dict[case_id][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][stype]['file_obj'] = api.files.get(fid)\n",
    "for case_id in bam_dict:\n",
    "    in_dict = {}\n",
    "    for key in ref_objs:\n",
    "        in_dict[key] = ref_objs[key]\n",
    "    tumor = ''\n",
    "    normal = ''\n",
    "    for stype in bam_dict[case_id]:\n",
    "        if stype == 'Normal':\n",
    "            in_dict['input_normal_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            normal = bam_dict[case_id][stype]['sid']\n",
    "            in_dict['input_normal_name'] = normal\n",
    "        else:\n",
    "            in_dict['input_tumor_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            tumor = bam_dict[case_id][stype]['sid']\n",
    "            in_dict['input_tumor_name'] = tumor\n",
    "    task_name = 'MUTECT2 WGS BENCHMARK: ' + case_id + ' ' + tumor + ' ' + normal\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "    task.inputs['output_basename'] = task.id\n",
    "    task.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark strelka2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strelka2_refs(api, project):\n",
    "    ref_dict = {}\n",
    "    ref_dict['indexed_reference_fasta'] = api.files.query(project=project, names=['hs37d5.fa'])[0]\n",
    "    ref_dict['reference_dict'] = api.files.query(project=project, names=['hs37d5.dict'])[0]\n",
    "    ref_dict['hg38_strelka_bed'] = api.files.query(project=project, names=['hs37d5_strelka2_canonical.bed.gz'])[0]\n",
    "    ref_dict['exome_flag'] = 'N'\n",
    "    ref_dict['select_vars_mode'] = 'gatk'\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/kfdrc-strelka2-benchmark-wf'\n",
    "manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jul-12_big_run/all_but_GBM_bam_manifest.csv')\n",
    "ref_objs = get_strelka2_refs(api, project)\n",
    "head = next(manifest)\n",
    "bam_dict = {}\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[-1]\n",
    "    sample_id = info[-3]\n",
    "    fid = info[0]\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    bam_dict[case_id][stype] = {}\n",
    "    bam_dict[case_id][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][stype]['file_obj'] = api.files.get(fid)\n",
    "for case_id in bam_dict:\n",
    "    in_dict = {}\n",
    "    for key in ref_objs:\n",
    "        in_dict[key] = ref_objs[key]\n",
    "    tumor = ''\n",
    "    normal = ''\n",
    "    for stype in bam_dict[case_id]:\n",
    "        if stype == 'Normal':\n",
    "            in_dict['input_normal_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            normal = bam_dict[case_id][stype]['sid']\n",
    "            in_dict['input_normal_name'] = normal\n",
    "        else:\n",
    "            in_dict['input_tumor_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            tumor = bam_dict[case_id][stype]['sid']\n",
    "            in_dict['input_tumor_name'] = tumor\n",
    "    task_name = 'STRELKA2 WGS BENCHMARK: ' + case_id + ' ' + tumor + ' ' + normal\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "    task.inputs['output_basename'] = task.id\n",
    "    task.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Vardict Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vardict_refs(api, project):\n",
    "    ref_dict = {}\n",
    "    ref_dict['indexed_reference_fasta'] = api.files.query(project=project, names=['hs37d5.fa'])[0]\n",
    "    ref_dict['reference_dict'] = api.files.query(project=project, names=['hs37d5.dict'])[0]\n",
    "    ref_dict['wgs_calling_interval_list'] = api.files.query(project=project, names=['b37_wgs_calling_regions.bed'])[0]\n",
    "    ref_dict['exome_flag'] = 'N'\n",
    "    ref_dict['select_vars_mode'] = 'gatk'\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/kfdrc-vardict-benchmark'\n",
    "manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jul-12_big_run/all_wgs_bams.csv')\n",
    "ref_objs = get_vardict_refs(api, project)\n",
    "head = next(manifest)\n",
    "bam_dict = {}\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[-1]\n",
    "    sample_id = info[-3]\n",
    "    fid = info[0]\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    bam_dict[case_id][stype] = {}\n",
    "    bam_dict[case_id][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][stype]['file_obj'] = api.files.get(fid)\n",
    "for case_id in bam_dict:\n",
    "    in_dict = {}\n",
    "    for key in ref_objs:\n",
    "        in_dict[key] = ref_objs[key]\n",
    "    tumor = ''\n",
    "    normal = ''\n",
    "    for stype in bam_dict[case_id]:\n",
    "        if stype == 'Normal':\n",
    "            in_dict['input_normal_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            normal = bam_dict[case_id][stype]['sid']\n",
    "            in_dict['input_normal_name'] = normal\n",
    "        else:\n",
    "            in_dict['input_tumor_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            tumor = bam_dict[case_id][stype]['sid']\n",
    "            in_dict['input_tumor_name'] = tumor\n",
    "    task_name = 'VARDICT WGS BENCHMARK: ' + case_id + ' ' + tumor + ' ' + normal\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "    task.inputs['output_basename'] = task.id\n",
    "    task.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag benchmark outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid task found KFDRC CONSENSUS CALLER: DO8264\n"
     ]
    }
   ],
   "source": [
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "# task name search phrase\n",
    "phrase = \"KFDRC CONSENSUS CALLER: DO8264\"\n",
    "# modify this to set which input file to use to tag the outputs with, may need to modify code if an array element\n",
    "in_key = 'lancet_vcf'\n",
    "for task in tasks:\n",
    "    if re.search(phrase, task.name):\n",
    "        sys.stderr.write('Valid task found ' + task.name + '\\n')\n",
    "        metadata = task.inputs[in_key].metadata\n",
    "        for out_key in task.outputs:\n",
    "            try:\n",
    "                if type(task.outputs[out_key]) is not list:\n",
    "                    file_obj = api.files.get(task.outputs[out_key].id)\n",
    "                    for key in metadata:\n",
    "                        file_obj.metadata[key] = metadata[key]\n",
    "                    file_obj.save()\n",
    "                else:\n",
    "                    for output in task.outputs[out_key]:\n",
    "                        file_obj = api.files.get(output.id)\n",
    "                        for key in metadata:\n",
    "                            file_obj.metadata[key] = metadata[key]\n",
    "                        file_obj.save()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Skipping \" + task.name + \" due to error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag from nested inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid task found BCBIO ENSEMBLE CONSENSUS SNV MNV: PLUS VARDICT LANCET\n",
      "Valid task found BCBIO ENSEMBLE CONSENSUS INDEL: PLUS VARDICT LANCET\n",
      "Valid task found BCBIO ENSEMBLE CONSENSUS INDEL: PLUS VARDICT\n",
      "Valid task found BCBIO ENSEMBLE CONSENSUS SNV MNV: PLUS VARDICT\n",
      "Valid task found BCBIO ENSEMBLE CONSENSUS SNV MNV: PLUS LANCET\n",
      "Valid task found BCBIO ENSEMBLE CONSENSUS INDEL: PLUS LANCET\n"
     ]
    }
   ],
   "source": [
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "# task name search phrase\n",
    "phrase = \"BCBIO ENSEMBLE CONSENSUS\"\n",
    "# modify this to set which input file to use to tag the outputs with, may need to modify code if an array element\n",
    "in_key = 'input_vcfs'\n",
    "for task in tasks:\n",
    "    if re.search(phrase, task.name):\n",
    "        sys.stderr.write('Valid task found ' + task.name + '\\n')\n",
    "        fset = task.inputs[in_key]\n",
    "        for i in range(len(fset)):\n",
    "            metadata = fset[i][0].metadata\n",
    "            for out_key in task.outputs:\n",
    "                try:\n",
    "                    file_obj = api.files.get(task.outputs[out_key][i])\n",
    "                    for key in metadata:\n",
    "                        file_obj.metadata[key] = metadata[key]\n",
    "                    file_obj.save()\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\"Skipping \" + task.name + \" due to error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag batch outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: d42a3496-1367-4880-87ca-bdebb0624bf4.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 4181ddf3-2c95-4ac8-bee3-f04d2971efb2.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: ecf49c6e-2e82-49e5-88e6-3fb66f02d399.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 85c4023d-74a3-4beb-999b-87a14c8e7cee.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 4886c27f-fcdb-4993-bd08-f9c0a6d37806.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: fa419682-ad0f-4d4f-ad35-576804ce5cde.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 92fd1cc1-30c6-42da-9c4a-e9c246d23dbc.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: d83802a6-1976-4c6f-a638-f912cbe7f537.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 7c8cb026-27aa-4c0b-bbbb-2486b1468b90.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 89dbf691-70de-4145-ba54-f416e812924c.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 75da867e-f904-48e4-8ae1-48b636dd0480.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: d43e6832-a90b-409f-a14d-65acf4e6f76a.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 4698cbd8-4bfe-4a1e-828e-1eabcc2477aa.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 461a4136-117b-45d5-b307-2bff30d374b5.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: e8706949-0b03-43c5-80d7-1d6d067bf94e.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 6382aabb-6518-4505-a973-62362f2d8946.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 100ffed5-6271-4994-b411-66da4ddb5191.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 80419c69-111c-494a-ab01-06eee66e9814.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 36f88a44-031e-4f8c-a5f5-45af2451ad85.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 447cb6ff-2011-4f08-b0eb-b3ded8c85078.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: c6c1c833-a0d7-4486-b299-25f67a22a9e1.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 605d888b-45a9-47db-9bc6-0c68823777e9.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 94211127-c8bb-4f9b-be7e-96bed2ed027f.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 6ea6d4ce-d979-4ee4-abd8-498e80a87f47.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 4d9e5bef-4779-4310-afb0-ac7f98ff1890.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 0a3dfdc7-8805-4f5b-9a97-af41c7f0adf0.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 0fe0f041-f0f8-41d8-8268-fc92d40897aa.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: ec1717b8-c45e-458c-93ff-7f866a134142.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 81c23a12-ded7-439b-8e75-784c9bf57f31.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 01e511ff-89ee-48db-9596-2bf29b9d7884.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 2487333b-56ea-4118-8677-ad506eb36828.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: a24ad6bb-4ffd-4e4b-831b-524d525dc998.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: d05f4e13-a6d6-44af-a4fb-2b9775282ab4.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 1a8a7bec-654a-49ec-a153-3dd58fba91f0.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: d1a6d41a-6947-404f-bfe8-31834187b1a9.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: ee336514-2b0f-43ef-b5a4-e2e302d94b76.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: e7454108-c7c6-44d9-8dfc-cc83bf3eb4ae.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: d8711ff4-0304-47e3-ac6c-dc8902578870.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: e102438d-eba0-4f28-a472-d01c623c7796.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 51c5f8e7-4428-4642-9670-8af988742bb1.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 499e4398-befe-470f-95f6-7f259e2c7501.vardict.PASS.vcf.gz\n",
      "Valid task found BCFTOOLS NORM SPLIT: VARDICT RPT: file: 3f14a91b-de0b-481c-a9da-119e7bdf3937.vardict.PASS.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "batch_id = 'cc6f68cc-3aea-498b-ba08-70cce50a5477'\n",
    "batch_task = api.tasks.get(batch_id)\n",
    "for task in batch_task.get_batch_children():\n",
    "    # pdb.set_trace()\n",
    "    sys.stderr.write('Valid task found ' + task.name + '\\n')\n",
    "    metadata = task.inputs['input_vcf'].metadata\n",
    "    for out_key in task.outputs:\n",
    "        try:\n",
    "            file_obj = api.files.get(task.outputs[out_key].id)\n",
    "            for key in metadata:\n",
    "                file_obj.metadata[key] = metadata[key]\n",
    "            file_obj.save()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Skipping \" + task.name + \" due to error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add note to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "phrase = \"window 300 \"\n",
    "note = \"Run with non default 300bp window to test change in accuracy with increase of speed\"\n",
    "for task in tasks:\n",
    "    if re.search(phrase, task.name):\n",
    "        sys.stderr.write('Valid task found ' + task.name + '\\n')\n",
    "        for out_key in task.outputs:\n",
    "            file_obj = api.files.get(task.outputs[out_key].id)\n",
    "            file_obj.metadata['notes'] = note\n",
    "            file_obj.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark PINDEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pindel_refs(api, project):\n",
    "    ref_dict = {}\n",
    "    ref_dict['reference_fasta'] = api.files.query(project=project, names=['hs37d5.fa'])[0]\n",
    "    ref_dict['reference_dict'] = api.files.query(project=project, names=['hs37d5.dict'])[0]\n",
    "    ref_dict['wgs_calling_bed'] = api.files.query(project=project, names=['b37_wgs_calling_regions.bed'])[0]\n",
    "    ref_dict['exome_flag'] = 'N'\n",
    "    ref_dict['genome_assembly'] = 'hs37d5'\n",
    "    ref_dict['insert_length'] = 250\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/kfdrc-pindel-benchmark-wf'\n",
    "manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jul-12_big_run/all_but_GBM_bam_manifest.csv')\n",
    "ref_objs = get_pindel_refs(api, project)\n",
    "head = next(manifest)\n",
    "bam_dict = {}\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[-1]\n",
    "    sample_id = info[-3]\n",
    "    fid = info[0]\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    bam_dict[case_id][stype] = {}\n",
    "    bam_dict[case_id][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][stype]['file_obj'] = api.files.get(fid)\n",
    "for case_id in bam_dict:\n",
    "    in_dict = {}\n",
    "    for key in ref_objs:\n",
    "        in_dict[key] = ref_objs[key]\n",
    "    tumor = ''\n",
    "    normal = ''\n",
    "    for stype in bam_dict[case_id]:\n",
    "        if stype == 'Normal':\n",
    "            in_dict['input_normal_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            normal = bam_dict[case_id][stype]['sid']\n",
    "            in_dict['input_normal_name'] = normal\n",
    "        else:\n",
    "            in_dict['input_tumor_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            tumor = bam_dict[case_id][stype]['sid']\n",
    "            in_dict['input_tumor_name'] = tumor\n",
    "    task_name = 'PINDEL WGS BENCHMARK: ' + case_id + ' ' + tumor + ' ' + normal\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "    task.inputs['output_basename'] = task.id\n",
    "    task.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bcf filter pindel unfiltered outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/bcftools-filter-pindel'\n",
    "manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jul-12_big_run/pindel_re-filter/pindel_unfiltered-manifest.csv')\n",
    "tool_name = 'pindel'\n",
    "depth= 20\n",
    "vaf = 0.1\n",
    "head = next(manifest)\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[-1]\n",
    "    sample_id = info[-3]\n",
    "    fid = info[0]\n",
    "    in_dict = {}\n",
    "    in_dict['vaf'] = vaf\n",
    "    in_dict['depth'] = depth\n",
    "    in_dict['tool_name'] = tool_name\n",
    "    in_dict['input_vcf'] = api.files.get(fid)\n",
    "    task_name = 'BCFTOOLS PINDEL FILTER: ' + case_id + ' ' + sample_id\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "    task.inputs['output_basename'] = task.id\n",
    "    task.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BENCHMARK CAVEMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caveman_refs(api, project):\n",
    "    ref_dict = {}\n",
    "    ref_dict['bed_refs_tar'] = api.files.query(project=project, names=['caveman_hs37d5_bed_refs.merged.tar.gz'])[0]\n",
    "    ref_dict['blacklist'] = api.files.query(project=project, names=['hs37d5_blacklist.tsv'])[0]\n",
    "    ref_dict['flag_config'] = api.files.query(project=project, names=['caveman_flags_config.ini'])[0]\n",
    "    ref_dict['flag_convert'] = api.files.query(project=project, names=['caveman_flag_convert.ini'])[0]\n",
    "    ref_dict['indexed_reference_fasta'] = api.files.query(project=project, names=['hs37d5.fa'])[0]\n",
    "    ref_dict['reference_dict'] = api.files.query(project=project, names=['hs37d5.dict'])[0]\n",
    "    ref_dict['split_size'] = 128\n",
    "    ref_dict['assay_type'] = 'WGS'\n",
    "    ref_dict['species'] = 'Human'\n",
    "    ref_dict['threads'] = 48\n",
    "    ref_dict['genome_assembly'] = 'hs37d5'\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/kfdrc-caveman-snv-benchmark-wf'\n",
    "manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jul-12_big_run/all_but_GBM_bam_manifest.csv')\n",
    "ref_objs = get_caveman_refs(api, project)\n",
    "head = next(manifest)\n",
    "bam_dict = {}\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[-1]\n",
    "    sample_id = info[-3]\n",
    "    fid = info[0]\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    bam_dict[case_id][stype] = {}\n",
    "    bam_dict[case_id][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][stype]['file_obj'] = api.files.get(fid)\n",
    "for case_id in bam_dict:\n",
    "    in_dict = {}\n",
    "    for key in ref_objs:\n",
    "        in_dict[key] = ref_objs[key]\n",
    "    tumor = ''\n",
    "    normal = ''\n",
    "    for stype in bam_dict[case_id]:\n",
    "        if stype == 'Normal':\n",
    "            in_dict['input_normal_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            normal = bam_dict[case_id][stype]['sid']\n",
    "            in_dict['input_normal_name'] = normal\n",
    "        else:\n",
    "            in_dict['input_tumor_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            tumor = bam_dict[case_id][stype]['sid']\n",
    "            in_dict['input_tumor_name'] = tumor\n",
    "    task_name = 'CAVEMAN SNV WGS BENCHMARK: ' + case_id + ' ' + tumor + ' ' + normal\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "    task.inputs['output_basename'] = task.id\n",
    "    task.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCAWG Annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variant bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_varbam_refs(api):\n",
    "    refs = {}\n",
    "    refs['reference_fasta'] = api.files.get('5d0a7b64e4b07ea2bda1b7df')\n",
    "    return refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/PCAWG_TEST/bams-manifest.csv')\n",
    "snv_manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/PCAWG_TEST/snv_vcf-manifest.csv')\n",
    "indel_manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/PCAWG_TEST/indel_vcf-manifest.csv')\n",
    "\n",
    "app_name = project +\"/pcawg-variant-bam\"\n",
    "ref_objs = get_varbam_refs(api)\n",
    "\n",
    "head = next(bam_manifest)\n",
    "bam_dict = {}\n",
    "for line in bam_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[-1]\n",
    "    sample_id = info[-3]\n",
    "    fid = info[0]\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    bam_dict[case_id][stype] = {}\n",
    "    bam_dict[case_id][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][stype]['file_obj'] = api.files.get(fid)\n",
    "snv_dict = {}\n",
    "head = next(snv_manifest)\n",
    "for line in snv_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    fid = info[0]\n",
    "    cur = api.files.get(fid)\n",
    "    tool = cur.tags[0]\n",
    "    if case_id not in snv_dict:\n",
    "        snv_dict[case_id] = {}\n",
    "    snv_dict[case_id][tool] = cur\n",
    "indel_dict = {}\n",
    "tool_dict = {}\n",
    "head = next(indel_manifest)\n",
    "for line in indel_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    fid = info[0]\n",
    "    cur = api.files.get(fid)\n",
    "    tool = cur.tags[0]\n",
    "    tool_dict[tool] = 1\n",
    "    if case_id not in indel_dict:\n",
    "        indel_dict[case_id] = {}\n",
    "    indel_dict[case_id][tool] = cur\n",
    "    \n",
    "for case_id in bam_dict:\n",
    "    for tool in tool_dict:\n",
    "        for stype in bam_dict[case_id]:\n",
    "            in_dict = {}\n",
    "            in_dict['reference_fasta'] = ref_objs['reference_fasta']\n",
    "            in_dict['snv_vcf'] = snv_dict[case_id][tool]\n",
    "            in_dict['indel_vcf'] = indel_dict[case_id][tool]\n",
    "            in_dict['tool_name'] = tool\n",
    "            in_dict['input_bam_aligned'] = bam_dict[case_id][stype]['file_obj']\n",
    "            task_name = 'PCAWG VARIANT BAM: ' + case_id + \" \" + bam_dict[case_id][stype]['sid'] + \" \" + tool\n",
    "            task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "            task.save()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = api.tasks.query(project=project, status=\"DRAFT\")\n",
    "for task in tasks:\n",
    "   task.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annotate vcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annot_refs(api):\n",
    "    refs = {}\n",
    "    refs['bgzipped_reference_fasta'] = api.files.get('5d24fb80e4b07ea29a76e786')\n",
    "    return refs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### annotate snvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/PCAWG_TEST/variant_bams_only.csv')\n",
    "snv_manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/PCAWG_TEST/snv_vcf-manifest.csv')\n",
    "\n",
    "app_name = project + \"/pcawg-annot-snv\"\n",
    "ref_objs = get_annot_refs(api)\n",
    "\n",
    "head = next(bam_manifest)\n",
    "bam_dict = {}\n",
    "tool_list = ['LANCET', 'STRELKA2', 'MUTECT2', 'VARDICT', 'SANGER', 'CAVEMAN', 'PINDEL']\n",
    "for line in bam_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[-1]\n",
    "    sample_id = info[-3]\n",
    "    fid = info[0]\n",
    "    bam = api.files.get(fid)\n",
    "    tool = ''\n",
    "    for tag in bam.tags:\n",
    "        if tag in tool_list:\n",
    "            tool = tag\n",
    "            break\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    if tool not in bam_dict[case_id]:\n",
    "        bam_dict[case_id][tool] = {}\n",
    "    bam_dict[case_id][tool][stype] = {}\n",
    "    bam_dict[case_id][tool][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][tool][stype]['file_obj'] = bam\n",
    "snv_dict = {}\n",
    "tool_dict = {}\n",
    "head = next(snv_manifest)\n",
    "for line in snv_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    fid = info[0]\n",
    "    cur = api.files.get(fid)\n",
    "    tool = cur.tags[0]\n",
    "    if case_id not in snv_dict:\n",
    "        snv_dict[case_id] = {}\n",
    "    snv_dict[case_id][tool] = cur\n",
    "    tool_dict[tool] = 1\n",
    "    \n",
    "for case_id in bam_dict:\n",
    "    for tool in tool_dict:\n",
    "        in_dict = {}\n",
    "        in_dict['bgzipped_reference_fasta'] = ref_objs['bgzipped_reference_fasta']\n",
    "        in_dict['input_snv_vcf'] = snv_dict[case_id][tool]\n",
    "        for stype in bam_dict[case_id][tool]:\n",
    "            if stype == 'Normal':\n",
    "                in_dict['input_normal_variant_bam'] = bam_dict[case_id][tool][stype]['file_obj']\n",
    "                normal = bam_dict[case_id][tool][stype]['sid']\n",
    "            else:\n",
    "                in_dict['input_tumor_variant_bam'] = bam_dict[case_id][tool][stype]['file_obj']\n",
    "                tumor = bam_dict[case_id][tool][stype]['sid']\n",
    "        task_name = 'PCAWG ANNOT SNV RERUN: ' + case_id + \" \" + tumor + \" \" + normal + \" \" + tool\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "        task.save()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### annotate indels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/PCAWG_TEST/variant_bams_only.csv')\n",
    "indel_manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/PCAWG_TEST/indel_vcf-manifest.csv')\n",
    "\n",
    "app_name = project + \"/pcawg-annot-indel\"\n",
    "ref_objs = get_annot_refs(api)\n",
    "\n",
    "head = next(bam_manifest)\n",
    "bam_dict = {}\n",
    "tool_list = ['LANCET', 'STRELKA2', 'MUTECT2', 'VARDICT', 'SANGER', 'CAVEMAN', 'PINDEL']\n",
    "for line in bam_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[-1]\n",
    "    sample_id = info[-3]\n",
    "    fid = info[0]\n",
    "    bam = api.files.get(fid)\n",
    "    tool = ''\n",
    "    for tag in bam.tags:\n",
    "        if tag in tool_list:\n",
    "            tool = tag\n",
    "            break\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    if tool not in bam_dict[case_id]:\n",
    "        bam_dict[case_id][tool] = {}\n",
    "    bam_dict[case_id][tool][stype] = {}\n",
    "    bam_dict[case_id][tool][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][tool][stype]['file_obj'] = bam\n",
    "tool_dict = {}\n",
    "head = next(indel_manifest)\n",
    "for line in indel_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    fid = info[0]\n",
    "    cur = api.files.get(fid)\n",
    "    tool = cur.tags[0]\n",
    "    if case_id not in indel_dict:\n",
    "        indel_dict[case_id] = {}\n",
    "    indel_dict[case_id][tool] = cur\n",
    "    tool_dict[tool] = 1\n",
    "    \n",
    "for case_id in bam_dict:\n",
    "    for tool in tool_dict:\n",
    "        in_dict = {}\n",
    "        in_dict['bgzipped_reference_fasta'] = ref_objs['bgzipped_reference_fasta']\n",
    "        in_dict['input_indel_vcf'] = indel_dict[case_id][tool]\n",
    "        for stype in bam_dict[case_id][tool]:\n",
    "            if stype == 'Normal':\n",
    "                in_dict['input_normal_variant_bam'] = bam_dict[case_id][tool][stype]['file_obj']\n",
    "                normal = bam_dict[case_id][tool][stype]['sid']\n",
    "            else:\n",
    "                in_dict['input_tumor_variant_bam'] = bam_dict[case_id][tool][stype]['file_obj']\n",
    "                tumor = bam_dict[case_id][tool][stype]['sid']\n",
    "        task_name = 'PCAWG ANNOT INDEL RERUN: ' + case_id + \" \" + tumor + \" \" + normal + \" \" + tool\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "        task.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review failed mutect2 tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUTECT2 WGS BENCHMARK: DO10900 SA135301 SA135424\t9628f79f-3ab9-434d-996d-ad7793cb472b\t2019-06-19 17:41:02\tCommand /gatk Mutect2 --java-options \"-Xmx6000m\" -R /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/hg19.fa -I /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.bam -I /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.fa4fa49d-6d53-4ffa-9759-ffb884b28d17.bam -tumor SA135301 -normal SA135424 --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter -L /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/9628f79f-3ab9-434d-996d-ad7793cb472b/gatk_intervallisttools/temp_0041_of_44/scattered.interval_list.0041.bed --germline-resource /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/af-only-gnomad.raw.sites.hg19.vcf.gz --f1r2-tar-gz PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.scattered.interval_list.0041.f1r2_counts.tar.gz -O PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.scattered.interval_list.0041.Mutect2.vcf.gz failed with exit code 2.\n",
      "MUTECT2 WGS BENCHMARK: DO11441 SA154417 SA154272\t30a697a5-a138-4a4e-aff6-f24d19538e3b\t2019-06-19 17:41:02\tCommand /gatk Mutect2 --java-options \"-Xmx6000m\" -R /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/hg19.fa -I /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.bam -I /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.701ee04f-ee1c-42b4-9614-499d51cf4a0a.bam -tumor SA154417 -normal SA154272 --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter -L /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/30a697a5-a138-4a4e-aff6-f24d19538e3b/gatk_intervallisttools/temp_0017_of_44/scattered.interval_list.0017.bed --germline-resource /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/af-only-gnomad.raw.sites.hg19.vcf.gz --f1r2-tar-gz PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.scattered.interval_list.0017.f1r2_counts.tar.gz -O PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.scattered.interval_list.0017.Mutect2.vcf.gz failed with exit code 2.\n",
      "MUTECT2 WGS BENCHMARK: DO10900 SA135301 SA135424\td48a1804-6141-445c-9df9-fc8cd2a8ad46\t2019-06-19 18:15:57\tCommand /gatk Mutect2 --java-options \"-Xmx6000m\" -R /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/hs37d5.fa -I /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.bam -I /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.fa4fa49d-6d53-4ffa-9759-ffb884b28d17.bam -tumor SA135301 -normal SA135424 --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter -L /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/d48a1804-6141-445c-9df9-fc8cd2a8ad46/gatk_intervallisttools/temp_0005_of_44/scattered.interval_list.0005.bed --germline-resource /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/af-only-gnomad.raw.sites.b37.vcf.gz --f1r2-tar-gz PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.scattered.interval_list.0005.f1r2_counts.tar.gz -O PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.scattered.interval_list.0005.Mutect2.vcf.gz failed with exit code 2.\n",
      "MUTECT2 WGS BENCHMARK: DO11441 SA154417 SA154272\t8ebf473d-75ec-4e8c-9e8d-da8a4179bd47\t2019-06-19 18:15:58\tCommand /gatk Mutect2 --java-options \"-Xmx6000m\" -R /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/hs37d5.fa -I /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.bam -I /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.701ee04f-ee1c-42b4-9614-499d51cf4a0a.bam -tumor SA154417 -normal SA154272 --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter -L /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/8ebf473d-75ec-4e8c-9e8d-da8a4179bd47/gatk_intervallisttools/temp_0001_of_44/scattered.interval_list.0001.bed --germline-resource /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/af-only-gnomad.raw.sites.b37.vcf.gz --f1r2-tar-gz PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.scattered.interval_list.0001.f1r2_counts.tar.gz -O PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.scattered.interval_list.0001.Mutect2.vcf.gz failed with exit code 2.\n",
      "MUTECT2 WGS BENCHMARK: DO10900 SA135301 SA135424\t3421c6d6-8a78-4410-8f11-9fc9af1f0e1e\t2019-06-19 21:09:53\tCommand /bin/bash -c set -euxo pipefail\n",
      "samtools view -H /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.fa4fa49d-6d53-4ffa-9759-ffb884b28d17.bam | sed -E \"s/SM:\\S+/SM:SA135424/\" | samtools reaheader - /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.fa4fa49d-6d53-4ffa-9759-ffb884b28d17.bam > PCAWG.fa4fa49d-6d53-4ffa-9759-ffb884b28d17.bam\n",
      "cp /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.fa4fa49d-6d53-4ffa-9759-ffb884b28d17.bam.bai . failed with exit code 1.\n",
      "MUTECT2 WGS BENCHMARK: DO11441 SA154417 SA154272\ta6cf4ddf-9f77-4db7-a6d4-a3fd8662ad4e\t2019-06-19 21:09:54\tCommand /bin/bash -c set -euxo pipefail\n",
      "samtools view -H /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.701ee04f-ee1c-42b4-9614-499d51cf4a0a.bam | sed -E \"s/SM:\\S+/SM:SA154272/\" | samtools reaheader - /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.701ee04f-ee1c-42b4-9614-499d51cf4a0a.bam > PCAWG.701ee04f-ee1c-42b4-9614-499d51cf4a0a.bam\n",
      "cp /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.701ee04f-ee1c-42b4-9614-499d51cf4a0a.bam.bai . failed with exit code 1.\n",
      "MUTECT2 WGS BENCHMARK: DO10900 SA135301 SA135424\tf07a7ab7-240e-43a3-9ef5-6649c3ec1373\t2019-06-19 21:41:16\tCommand /gatk Mutect2 --java-options \"-Xmx6000m\" -R /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/hs37d5.fa -I /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/f07a7ab7-240e-43a3-9ef5-6649c3ec1373/samtools_reheader_tumor/PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.bam -I /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/f07a7ab7-240e-43a3-9ef5-6649c3ec1373/samtools_reheader_normal/PCAWG.fa4fa49d-6d53-4ffa-9759-ffb884b28d17.bam -tumor SA135301 -normal SA135424 --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter -L /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/f07a7ab7-240e-43a3-9ef5-6649c3ec1373/gatk_intervallisttools/temp_0010_of_44/scattered.interval_list.0010.bed --germline-resource /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/af-only-gnomad.raw.sites.b37.vcf.gz --f1r2-tar-gz PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.scattered.interval_list.0010.f1r2_counts.tar.gz -O PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.scattered.interval_list.0010.Mutect2.vcf.gz failed with exit code 3.\n",
      "MUTECT2 WGS BENCHMARK: DO10900 SA135301 SA135424\t95a0e5d3-705d-455f-9fee-bb197049c63b\t2019-06-19 22:54:24\tCommand /gatk Mutect2 --java-options \"-Xmx6000m\" -R /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/hs37d5.fa -I /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/95a0e5d3-705d-455f-9fee-bb197049c63b/samtools_reheader_tumor/PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.bam -I /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/95a0e5d3-705d-455f-9fee-bb197049c63b/samtools_reheader_normal/PCAWG.fa4fa49d-6d53-4ffa-9759-ffb884b28d17.bam -tumor SA135301 -normal SA135424 --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter -L /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/95a0e5d3-705d-455f-9fee-bb197049c63b/gatk_intervallisttools/temp_0011_of_44/scattered.interval_list.0011.bed --germline-resource /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/af-only-gnomad.raw.sites.b37.vcf.gz --f1r2-tar-gz PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.scattered.interval_list.0011.f1r2_counts.tar.gz -O PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.scattered.interval_list.0011.Mutect2.vcf.gz failed with exit code 2.\n",
      "MUTECT2 WGS BENCHMARK: DO11441 SA154417 SA154272\tae76a1fb-2206-4fa1-b9cf-ba9ba0ed2115\t2019-06-19 22:54:37\tCommand /gatk Mutect2 --java-options \"-Xmx6000m\" -R /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/hs37d5.fa -I /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/ae76a1fb-2206-4fa1-b9cf-ba9ba0ed2115/samtools_reheader_tumor/PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.bam -I /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/ae76a1fb-2206-4fa1-b9cf-ba9ba0ed2115/samtools_reheader_normal/PCAWG.701ee04f-ee1c-42b4-9614-499d51cf4a0a.bam -tumor SA154417 -normal SA154272 --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter -L /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/ae76a1fb-2206-4fa1-b9cf-ba9ba0ed2115/gatk_intervallisttools/temp_0032_of_44/scattered.interval_list.0032.bed --germline-resource /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/af-only-gnomad.raw.sites.b37.vcf.gz --f1r2-tar-gz PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.scattered.interval_list.0032.f1r2_counts.tar.gz -O PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.scattered.interval_list.0032.Mutect2.vcf.gz failed with exit code 2.\n",
      "MUTECT2 WGS BENCHMARK: DO11441 SA154417 SA154272\tc2a0ab96-c505-4e79-8642-1b2855345abf\t2019-06-20 02:35:25\tCommand /gatk GetPileupSummaries --java-options \"-Xmx2000m\" -I /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.bam -V /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/small_exac_common_3_b37.vcf.gz -L /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/c2a0ab96-c505-4e79-8642-1b2855345abf/gatk_intervallisttools/temp_0043_of_44/scattered.interval_list.0043.bed -R /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/hs37d5.fa -O PCAWG.d19dbf14-3293-4e09-a072-a746bb26376c.pileupsummary.table failed with exit code 2.\n",
      "MUTECT2 WGS BENCHMARK: DO10900 SA135301 SA135424\t141b7ace-85a8-4329-935e-44130f943551\t2019-06-20 02:35:50\tCommand /gatk GetPileupSummaries --java-options \"-Xmx2000m\" -I /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/BAM/PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.bam -V /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/small_exac_common_3_b37.vcf.gz -L /sbgenomics/workspaces/87fde798-4ab5-40e1-8ef9-7468e4a905de/tasks/141b7ace-85a8-4329-935e-44130f943551/gatk_intervallisttools/temp_0002_of_44/scattered.interval_list.0002.bed -R /sbgenomics/Projects/87fde798-4ab5-40e1-8ef9-7468e4a905de/hs37d5.fa -O PCAWG.64d83e97-f798-45d1-b9e6-efaa635b4abb.pileupsummary.table failed with exit code 2.\n",
      "MUTECT2 WGS BENCHMARK: DO29850 SA520122 SA518178\t0f213e91-c8f8-4b62-a458-b8b8db98ce0c\t2019-07-12 16:29:50\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.34. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO15911 SA201430 SA201501\t48189b77-f77c-434c-8798-006b4de5fcd7\t2019-07-12 16:29:51\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.1. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO8264 SA108597 SA108692\t3781f095-8a4c-4b25-ad5e-e3bf044415e6\t2019-07-12 16:29:52\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.28. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO26971 SA307536 SA307392\tddcb7657-4137-48a6-8f6f-01c4cd7a17cd\t2019-07-12 16:29:53\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.2. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO36881 SA421337 SA421377\t4435eabe-8369-4d48-b94e-ee9a67964d0c\t2019-07-12 16:29:57\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.32. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO44469 SA495048 SA495064\tba68b4df-287f-416d-991a-558e804b9a98\t2019-07-12 16:29:58\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.44. com.sbgenomics.vaporstore2.clientv2.exceptions.VSClientException: java.io.IOException: No space left on device. com.sbgenomics.vaporstore2.clientv2.exceptions.VSClientException: java.io.IOException: No space left on device.\n",
      "MUTECT2 WGS BENCHMARK: DO15870 SA200796 SA200741\ta678f6c3-0bbd-445e-9ec6-e9a192687219\t2019-07-12 16:29:59\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.11. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO2783 SA70525 SA70645\tacb139f3-b082-4d49-addd-e8d783b14ff9\t2019-07-12 16:30:00\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.40. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO23651 SA279872 SA279953\taa30c15f-91b3-4bb0-9210-bca6b7b5043a\t2019-07-12 16:30:00\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.40. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO44285 SA492657 SA492673\ta7ae4c28-7e6e-4cda-8fd4-cdf7377e88f6\t2019-07-12 16:30:02\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.30. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO19048 SA219639 SA219495\tfbccfae9-e852-4e1a-bc2f-b59513417266\t2019-07-12 16:30:03\tFailed to start root.mutect2_filter_support.gatk_learn_orientation_bias. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO43506 SA478344 SA478425\t1e88ad89-11c9-4593-ad58-025e10be8565\t2019-07-12 16:30:05\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.20. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO21115 SA258388 SA258400\t3a266fa4-6557-425a-8970-b74fee92b472\t2019-07-12 16:30:08\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.36. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO26769 SA300605 SA300568\tcd39c89a-72d1-4c66-97bd-5f57c9ec2990\t2019-07-12 16:30:08\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.6. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO52171 SA540506 SA540519\tde1f6dd0-e7c4-45e8-ac75-9c8f55dd11cd\t2019-07-12 16:30:11\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.37. java.io.IOException: No space left on device. java.io.IOException: No space left on device.\n",
      "MUTECT2 WGS BENCHMARK: DO49659 SA520782 SA520789\t86b57c45-426f-475c-90b6-0d4846b260ff\t2019-07-12 16:30:12\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.22. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO52172 SA540527 SA540539\t3543e7a0-5879-4dcd-adbf-215030a4e0c2\t2019-07-12 16:30:13\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.8. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO38871 SA444038 SA444062\t52dcb1c1-4357-4b3b-93e3-85ecfaca0341\t2019-07-12 16:30:14\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.17. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO220599 SA556937 SA556945\tcbd76c97-5f5c-4c1f-bdc6-4c42067b859c\t2019-07-12 16:30:15\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.35. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO15110 SA190261 SA190313\t5590699c-06d3-456a-b243-d41d42798bd5\t2019-07-12 16:30:18\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.39. java.io.IOException: No space left on device. java.io.IOException: No space left on device.\n",
      "MUTECT2 WGS BENCHMARK: DO4557 SA43144 SA43281\te7cf0c61-9370-498e-acbf-aeeedd244de2\t2019-07-12 16:30:19\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.10. java.io.IOException: No space left on device. java.io.IOException: No space left on device.\n",
      "MUTECT2 WGS BENCHMARK: DO48977 SA517453 SA517460\tc1ae89ba-02e8-4353-9b65-1446ebd1acab\t2019-07-12 16:30:21\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.36. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO38847 SA443714 SA443738\tbf545b3b-d346-4aaf-aa0e-c45bcb4dd5eb\t2019-07-12 16:30:22\tFailed to start root.mutect2_filter_support.gatk_get_tumor_pileup_summaries.16. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO26971 SA307536 SA307392\t875efa27-fa6f-4c6f-b876-c7245c40ba43\t2019-07-13 21:37:07\tFailed to start root.mutect2_filter_support.gatk_learn_orientation_bias. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO15911 SA201430 SA201501\t08b10793-3d77-4d4c-991f-7dabdb091d38\t2019-07-13 21:38:03\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.26. java.lang.RuntimeException: Error opening local file. java.lang.RuntimeException: Error opening local file.\n",
      "MUTECT2 WGS BENCHMARK: DO29850 SA520122 SA518178\tc014049e-3df2-4605-bf3a-fd6b16c9e83e\t2019-07-13 21:38:51\tFailed to start root.mutect2_filter_support.gatk_get_normal_pileup_summaries.2. java.io.IOException: No space left on device. java.io.IOException: No space left on device.\n"
     ]
    }
   ],
   "source": [
    "tasks = api.tasks.query(project=project, status=\"FAILED\").all()\n",
    "for task in tasks:\n",
    "    if re.search(\"MUTECT2 WGS\", task.name):\n",
    "        #pdb.set_trace()\n",
    "        print (task.name + \"\\t\" + task.id + \"\\t\" + str(task.created_time) + \"\\t\" + task.execution_status.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat failed tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/kfdrc-mutect2-sans-vep'\n",
    "for task_id in open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jul-12_big_run/mutect2_re-run/failed_tasks_to_rerun.txt'):\n",
    "    old_task = api.tasks.get(task_id.rstrip('\\n'))\n",
    "    new_task = api.tasks.create(name=old_task.name, project=project, app=app_name, inputs=old_task.inputs, run=False)\n",
    "    new_task.inputs['output_basename'] = new_task.id\n",
    "    new_task.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge pindel mnv, caveman snv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/2019-Jul-12_big_run/pindel_re-filter/updated_cave_pindel_merge.csv')\n",
    "head = next(manifest)\n",
    "pt_dict = {}\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    finfo = info[0:2]\n",
    "    # pdb.set_trace()\n",
    "    pt_id = info[8]\n",
    "    if pt_id not in pt_dict:\n",
    "        pt_dict[pt_id] = []\n",
    "    pt_dict[pt_id].append(finfo)\n",
    "manifest.close()\n",
    "dict_file = api.files.get('5d0a7b63e4b07ea2bda1b7da')\n",
    "tool_name = 'caveman_plus_pindel_mnv.bcfNorm'\n",
    "app_name = project + \"/gatk4-mergevcfs\"\n",
    "for pt_id in pt_dict:\n",
    "    in_dict = {}\n",
    "    \n",
    "    in_dict['input_vcfs'] = []\n",
    "    for finfo in pt_dict[pt_id]:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            in_dict['input_vcfs'].append(api.files.get(finfo[0]))\n",
    "        except Exception as e:\n",
    "            pdb.set_trace()\n",
    "            sys.stderr.write('Got error processing ' + finfo[1] + ' with ID ' + finfo[0] + '\\n')\n",
    "            sys.stderr.write(str(e) + '\\n')\n",
    "            exit(1)\n",
    "    in_dict['reference_dict'] = dict_file\n",
    "    in_dict['tool_name'] = tool_name\n",
    "    task_name = 'GATK MERGE CAVEMANsnv PINDELmnv UPDATED: ' + pt_id\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "    task.inputs['output_basename'] = task.id\n",
    "    task.save()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCBIO ensemble consensus call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = open('/Users/brownm28/Documents/2019-Jun-6_benchmarking/CONSENSUS_CALLS/vardict_filtering/indel_to_call.csv')\n",
    "tool_list = ('mutect2', 'strelka2', 'lancet', 'vardict_vaf10')\n",
    "short = 'vaf10_indel'\n",
    "task_name = 'BCBIO ENSEMBLE CONSENSUS INDEL: VAF10'\n",
    "reference = api.files.get('5d0a7b64e4b07ea2bda1b7df')\n",
    "head = next(manifest)\n",
    "vcf_dict = {}\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    fid = info[0]\n",
    "    fname = info[1]\n",
    "    case_id = info[-1]\n",
    "    sample_id = info[-2]\n",
    "    for i in range(len(tool_list)):\n",
    "        if re.search(tool_list[i], fname):\n",
    "            if case_id not in vcf_dict:\n",
    "                vcf_dict[case_id] = [None] * len(tool_list)\n",
    "            vcf_dict[case_id][i] = api.files.get(fid)\n",
    "            break\n",
    "tools_csv = \",\".join(tool_list)\n",
    "app_name = project + '/kfdrc-bcbio-consensus-wf'\n",
    "in_dict = {}\n",
    "in_dict['reference'] = reference\n",
    "in_dict['tool_name_csv'] = tools_csv\n",
    "in_dict['output_basename'] = []\n",
    "in_dict['input_vcfs'] = []\n",
    "for case_id in vcf_dict:\n",
    "    in_dict['output_basename'].append(case_id + '_' + short)\n",
    "    in_dict['input_vcfs'].append(vcf_dict[case_id])\n",
    "\n",
    "task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
