{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38cd7c05",
   "metadata": {},
   "source": [
    "# Create Sentieon Joint Genotyping \"Workflow\"\n",
    "This workflow consists of the following steps, mangaged in a more \"manual\" way using this notebook:\n",
    "1. Batch run sharding of gVCFs, in sets of N/12\n",
    "1. Move Sharded gVCFs into each of the subprojects(3)\n",
    "1. Run Senteion GVCFTyper tool on each set of sharded samples\n",
    "1. Copy/move results to main project\n",
    "1. Profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11fc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sevenbridges as sbg\n",
    "from sevenbridges.errors import SbgError\n",
    "from sevenbridges.http.error_handlers import rate_limit_sleeper, maintenance_sleeper\n",
    "import sys\n",
    "import re\n",
    "import pdb\n",
    "import concurrent.futures\n",
    "from requests import request\n",
    "import json\n",
    "config = sbg.Config(profile='turbo')\n",
    "api = sbg.Api(config=config, error_handlers=[rate_limit_sleeper, maintenance_sleeper])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1d9a0",
   "metadata": {},
   "source": [
    "## Patch metadata to files\n",
    "Example input:\n",
    "\n",
    "```text\n",
    "File Name\tData Type\tFile Format\tExperiment Strategy\tParticipants ID\tProband\tFamily Id\tSample External ID\tAliquot External ID\n",
    "ea542aa1-9ee9-499d-a1d9-8d51bc818c21.g.vcf.gz\tgVCF\tgvcf\tWGS\tPT_SGZCGWED\tYes\tFM_K8K528BS\tCG0034-9301\tCG0034-9301\n",
    "20046342-f24b-43a6-a79a-ed5687801a87.g.vcf.gz\tgVCF\tgVCF\tWGS\tPT_MJXDMGZC\tNo\tFM_C8TH0DP9\tCG0006-3366\t--\n",
    "57521e6e-0add-4793-a28f-6a3703c3b7dd.g.vcf.gz\tgVCF\tgvcf\tWGS\tPT_VXWFWHG3\tYes\tFM_ERZ72PM5\tCG0000-3398\tCG0000-3398\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465be126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_gvcf_metadata(line, meta_dict):\n",
    "    try:\n",
    "        info = line.rstrip('\\n').split('\\t')\n",
    "        gvcf = api.files.get(info[0])\n",
    "        gvcf.metadata = meta_dict[gvcf.name]\n",
    "        gvcf.save()\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1352fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = open('/Users/brownm28/Documents/2022-May-6_KF-CHD_joint_cohort_call/gvcf_metadata.tsv')\n",
    "gvcf_manifest = api.files.get('627535674d85bc2e028b5ff3').content().split('\\n')\n",
    "meta_dict = {}\n",
    "head = next(metadata_file)\n",
    "header = head.rstrip('\\n').split('\\t')\n",
    "meta_keys = { 'experiment_strategy': header.index(\"Experiment Strategy\"),\n",
    "            'case_id': header.index(\"Participants ID\"), 'Proband': header.index('Proband') }\n",
    "for line in metadata_file:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    meta_dict[info[0]] = {}\n",
    "    for key in meta_keys:\n",
    "        meta_dict[info[0]][key] = info[meta_keys[key]]\n",
    "# pdb.set_trace()\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(patch_gvcf_metadata, gvcf_manifest[i], meta_dict): gvcf_manifest[i] for i in range(1, len(gvcf_manifest), 1)}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0873a78d",
   "metadata": {},
   "source": [
    "## Batch run GVCF Shard\n",
    "Requires interval lists to have been created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd45b63",
   "metadata": {},
   "source": [
    "### Set up files and refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_refs(api, project):\n",
    "    ref_dict = {}\n",
    "    bed_files = api.files.query(project=project, metadata={\"data_type\": \"padded_bed\"})\n",
    "    ref_dict['shard_bed'] = bed_files\n",
    "    ref_dict['cores'] = 16\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab885c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project='kfdrc-harmonization/sd-preasa7s-cohort-joint-genotyping'\n",
    "app = project + '/shard_vcf'\n",
    "\n",
    "# read manifest directly into array\n",
    "gvcf_manifest = api.files.get('627535674d85bc2e028b5ff3').content().split('\\n')\n",
    "gvcf_set_list = []\n",
    "gvcf_set_list.append([])\n",
    "j=0\n",
    "x = 1\n",
    "n = 300\n",
    "# create batch tasks - 300 per batch\n",
    "for i in range(1, len(gvcf_manifest) - 1, 1):\n",
    "    # pdb.set_trace()\n",
    "    if x > n:\n",
    "        gvcf_set_list.append([])\n",
    "        j += 1\n",
    "        x=1\n",
    "        sys.stderr.write('Creating next set of 300\\n')\n",
    "    info = gvcf_manifest[i].split('\\t')\n",
    "    gvcf_set_list[j].append(api.files.get(info[0]))\n",
    "    x += 1\n",
    "ref_dict = get_batch_refs(api, project)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a37ad6",
   "metadata": {},
   "source": [
    "### Set up batch tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_by = {'type': 'item'}\n",
    "batch_input = 'input_vcf'\n",
    "\n",
    "for i in range(1, len(gvcf_set_list), 1):\n",
    "    task_name = \"Batch Shard Set \" + str(i)\n",
    "    in_dict = {}\n",
    "    for key in ref_dict:\n",
    "        in_dict[key] = ref_dict[key]\n",
    "    in_dict['input_vcf'] = gvcf_set_list[i]\n",
    "    try:\n",
    "        task = api.tasks.create(\n",
    "            name=task_name, project=project, app=app, inputs=in_dict,\n",
    "            batch_input=batch_input, batch_by=batch_by, run=False\n",
    "        )\n",
    "        task.save()\n",
    "    except SbError:\n",
    "        print('Could not create batch task: ' + task_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5126f68",
   "metadata": {},
   "source": [
    "### Capture missed batch?!?!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f98f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project='kfdrc-harmonization/sd-preasa7s-cohort-joint-genotyping'\n",
    "app = project + '/shard_vcf'\n",
    "missed_manifest = open('/Users/brownm28/Documents/2022-May-6_KF-CHD_joint_cohort_call/batch_missed.tsv')\n",
    "ref_dict = get_batch_refs(api, project)\n",
    "head = next(missed_manifest)\n",
    "input_vcf = []\n",
    "for line in missed_manifest:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    try:\n",
    "        input_vcf.append(api.files.get(info[0]))\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        print(\"Skipping file \" + info[0] + \" \" + info[1] + \" due to error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8905e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_by = {'type': 'item'}\n",
    "batch_input = 'input_vcf'\n",
    "\n",
    "task_name=\"MISSED SHARD SET\"\n",
    "in_dict = {}\n",
    "in_dict['input_vcf'] = input_vcf\n",
    "for key in ref_dict:\n",
    "    in_dict[key] = ref_dict[key]\n",
    "\n",
    "task = api.tasks.create(\n",
    "    name=task_name, project=project, app=app, inputs=in_dict,\n",
    "    batch_input=batch_input, batch_by=batch_by, run=False\n",
    ")\n",
    "task.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0b001",
   "metadata": {},
   "source": [
    "### Copy metadata for missed batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b03691",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_task = api.tasks.get(\"ee0c7576-1d32-458c-a018-b3f67c5157da\")\n",
    "for task in batch_task.get_batch_children().all():\n",
    "    metadata = task.inputs['input_vcf'].metadata\n",
    "    for output in task.outputs['sharded_vcf']:\n",
    "        vcf = api.files.get(output)\n",
    "        tbi = api.files.get(output.secondary_files[0])\n",
    "        for key in metadata:\n",
    "            vcf.metadata[key] = metadata[key]\n",
    "            tbi.metadata[key] = metadata[key]\n",
    "        shard = int(re.match('.*-(\\d+)\\.g\\.vcf\\.gz', vcf.name).group(1))\n",
    "        vcf.metadata['shard'] = shard\n",
    "        tbi.metadata['shard'] = shard\n",
    "        try:\n",
    "            vcf.save()\n",
    "            tbi.save()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    print(\"Processed child task: \" + task.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ec40d",
   "metadata": {},
   "source": [
    "### Copy metadata to outputs\n",
    "Note: Like, 70% worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_metadata(batch_task):\n",
    "    try:\n",
    "        print(\"Processing \" + batch_task.name)\n",
    "        for task in batch_task.get_batch_children().all():\n",
    "            if task.status==\"COMPLETED\":\n",
    "                metadata = task.inputs['input_vcf'].metadata\n",
    "                for output in task.outputs['sharded_vcf']:\n",
    "                    vcf = api.files.get(output)\n",
    "                    tbi = api.files.get(output.secondary_files[0])\n",
    "                    for key in metadata:\n",
    "                        vcf.metadata[key] = metadata[key]\n",
    "                        tbi.metadata[key] = metadata[key]\n",
    "                    shard = int(re.match('.*-(\\d+)\\.g\\.vcf\\.gz', vcf.name).group(1))\n",
    "                    vcf.metadata['shard'] = shard\n",
    "                    tbi.metadata['shard'] = shard\n",
    "                    try:\n",
    "                        vcf.save()\n",
    "                        tbi.save()\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "            else:\n",
    "                print (\"task had failed, skipping: \" + task.name)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Might be a single task, trying that\\n\")\n",
    "        try:\n",
    "            task=batch_task\n",
    "            metadata = task.inputs['input_vcf'].metadata\n",
    "            for output in task.outputs['sharded_vcf']:\n",
    "                vcf = api.files.get(output)\n",
    "                tbi = api.files.get(output.secondary_files[0])\n",
    "                for key in metadata:\n",
    "                    vcf.metadata[key] = metadata[key]\n",
    "                    tbi.metadata[key] = metadata[key]\n",
    "                shard = int(re.match('.*-(\\d+)\\.g\\.vcf\\.gz', vcf.name).group(1))\n",
    "                vcf.metadata['shard'] = shard\n",
    "                tbi.metadata['shard'] = shard\n",
    "                vcf.save()\n",
    "                tbi.save()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd62df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project='kfdrc-harmonization/sd-preasa7s-cohort-joint-genotyping'\n",
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "phrase = 'Batch Shard Set'\n",
    "batch_task_list = []\n",
    "for task in tasks:\n",
    "    if re.search(phrase, task.name):\n",
    "        batch_task_list.append(task)\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "#     results = {executor.submit(copy_metadata, batch_task): batch_task for batch_task in batch_task_list}\n",
    "for batch_task in batch_task_list:\n",
    "    copy_metadata(batch_task)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f454b4f",
   "metadata": {},
   "source": [
    "### Move files to sub-projects\n",
    "First copy, then remove from parent project.\n",
    "Note: Had weird duplicates after copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a76998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_files(shard_file, sp_cp):\n",
    "    try:\n",
    "        shard_file.copy(project=sp_cp, name=shard_file.name)\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c9d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_files(shard_file):\n",
    "    try:\n",
    "        shard_file.delete()\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_prj = 'kfdrc-harmonization/sd-preasa7s-cohort-joint-genotyping'\n",
    "\n",
    "num_shards = 12\n",
    "k = 1\n",
    "for i in range(0, num_shards, 4):\n",
    "    sp_cp = src_prj + \"-\" + str(k)\n",
    "    for j in range(i, i+4, 1):\n",
    "        shard_set = api.files.query(project=src_prj, metadata={'shard': j}).all()\n",
    "        with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "            results = {executor.submit(cp_files, shard_file, sp_cp): shard_file for shard_file in shard_set}\n",
    "        sys.stderr.write('Finished copying set ' + str(j) + '\\n')\n",
    "    k += 1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_prj = 'kfdrc-harmonization/sd-preasa7s-cohort-joint-genotyping'\n",
    "check = input(\"Type YASS if you are sure you want to delete files sharded files from \" + src_prj + \"\\n\")\n",
    "if check=='YASS':\n",
    "    num_shards = 12\n",
    "    for i in range(0, num_shards, 1):\n",
    "        shard_set = api.files.query(project=src_prj, metadata={'shard': j}).all()\n",
    "        with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "            results = {executor.submit(rm_files, shard_file): shard_file for shard_file in shard_set}\n",
    "        sys.stderr.write('Finished deleting set ' + str(i) + '\\n')\n",
    "else:\n",
    "    print (\"Invalid input, skipping delete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92000c5e",
   "metadata": {},
   "source": [
    "## Set up JG Calls\n",
    "VCFs MUST be given in the same sorted order to each shard job.\n",
    "Unfortunately, you may have to re-input gVCF in the GUI anyway, as every load I have tried (2,511 files) is incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb562aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jg_refs(api, project):\n",
    "    ref_dict = {}\n",
    "    ref_dict['reference'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.fasta'])[0]\n",
    "    ref_dict['dbSNP'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.dbsnp.vcf.gz'])[0]\n",
    "    ref_dict['cpu_per_job'] = 36\n",
    "    ref_dict['emit_mode'] = 'variant'\n",
    "    ref_dict['genotype_model'] = 'multinomial'\n",
    "    ref_dict['sentieon_license'] = '10.5.59.108:8990'\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06fb4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_dict = {\n",
    "    5: [\"chr1:1-248956422\", \"chr2:1-16145119\"],\n",
    "    6: [\"chr2:16146120-242193529\", \"chr3:1-90565295\"],\n",
    "    9: [\"chr3:90565296-198295559\", \"chr4:1-190123121\"],\n",
    "    4: [\"chr4:190173122-190214555\", \"chr5:1-181538259\",\"chr6:1-61370554\"],\n",
    "    10: [\"chr6:61370555-170805979\", \"chr7:1-62456779\"],\n",
    "    2: [\"chr7:62506780-159345973\", \"chr8:1-145138636\"],\n",
    "    3: [\"chr9:1-138394717\", \"chr10:1-124121200\"],\n",
    "    8: [\"chr10:124121201-133797422\", \"chr11:1-135086622\", \"chr12:1-132223362\"],\n",
    "    0: [\"chr12:132224363-133275309\", \"chr13:1-114364328\", \"chr14:1-107043718\", \"chr15:1-23226874\"],\n",
    "    1: [\"chr15:23276875-101991189\", \"chr16:1-90338345\", \"chr17:1-83257441\"],\n",
    "    7: [\"chr18:1-80373285\", \"chr19:1-58617616\", \"chr20:1-64444167\", \"chr21:1-46709983\", \"chr22:1-18659564\"],\n",
    "    11: [\"chr22:18709565-50818468\", \"chrX:1-156040895\", \"chrY:1-57227415\"]\n",
    "}\n",
    "\n",
    "src_prj = 'kfdrc-harmonization/sd-preasa7s-cohort-joint-genotyping'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d345b4b",
   "metadata": {},
   "source": [
    "### Set up Subproject 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ac0b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created task for shard 0\n",
      "Created task for shard 1\n",
      "Created task for shard 2\n",
      "Created task for shard 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,4,1):\n",
    "    cur = src_prj + \"-1\"\n",
    "    app_name = cur + \"/sentieon_gvcftyper\"\n",
    "    refs = get_jg_refs(api, cur)\n",
    "    task_name = \"Joint Call Shard Set: \" + str(i)\n",
    "    in_dict = {}\n",
    "    for key in refs:\n",
    "        in_dict[key] = refs[key]\n",
    "    shard_list = []\n",
    "    for shard in shard_dict[i]:\n",
    "        shard_list.append(\"--shard \" + shard)\n",
    "    in_dict['advanced_driver_options'] = \" \".join(shard_list)\n",
    "    vcf_collection=api.files.query(project=cur, metadata={\"shard\": i}).all()\n",
    "    vcf_list = list(vcf_collection)\n",
    "    vcf_list.sort(key=lambda x: x.name)\n",
    "    in_dict['input_vcfs'] = vcf_list\n",
    "    in_dict['output_file_name'] = \"KF-CHD_joint_genotyping_cohort_call-\" + str(i) + \".vcf.gz\"\n",
    "    task = api.tasks.create(app=app_name, name=task_name, inputs=in_dict, project=cur, run=False)\n",
    "    task.save()\n",
    "    print(\"Created task for shard \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_collection=api.files.query(project=cur, metadata={\"shard\": i}).all()\n",
    "vcf_list = list(vcf_collection)\n",
    "pdb.set_trace()\n",
    "hold=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90289c5a",
   "metadata": {},
   "source": [
    "### Set up Subproject 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09881a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created task for shard 4\n",
      "Created task for shard 5\n",
      "Created task for shard 6\n",
      "Created task for shard 7\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,8,1):\n",
    "    cur = src_prj + \"-2\"\n",
    "    app_name = cur + \"/sentieon_gvcftyper\"\n",
    "    refs = get_jg_refs(api, cur)\n",
    "    task_name = \"Joint Call Shard Set: \" + str(i)\n",
    "    in_dict = {}\n",
    "    for key in refs:\n",
    "        in_dict[key] = refs[key]\n",
    "    shard_list = []\n",
    "    for shard in shard_dict[i]:\n",
    "        shard_list.append(\"--shard \" + shard)\n",
    "    in_dict['advanced_driver_options'] = \" \".join(shard_list)\n",
    "    vcf_collection=api.files.query(project=cur, metadata={\"shard\": i}).all()\n",
    "    vcf_list = list(vcf_collection)\n",
    "    vcf_list.sort(key=lambda x: x.name)\n",
    "    in_dict['input_vcfs'] = vcf_list\n",
    "    in_dict['output_file_name'] = \"KF-CHD_joint_genotyping_cohort_call-\" + str(i) + \".vcf.gz\"\n",
    "    task = api.tasks.create(app=app_name, name=task_name, inputs=in_dict, project=cur, run=False)\n",
    "    task.save()\n",
    "    print(\"Created task for shard \" + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff85c2",
   "metadata": {},
   "source": [
    "### Set up Subproject 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d33029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created task for shard 8\n",
      "Created task for shard 9\n",
      "Created task for shard 10\n",
      "Created task for shard 11\n"
     ]
    }
   ],
   "source": [
    "for i in range(8,12,1):\n",
    "    cur = src_prj + \"-3\"\n",
    "    app_name = cur + \"/sentieon_gvcftyper\"\n",
    "    refs = get_jg_refs(api, cur)\n",
    "    task_name = \"Joint Call Shard Set: \" + str(i)\n",
    "    in_dict = {}\n",
    "    for key in refs:\n",
    "        in_dict[key] = refs[key]\n",
    "    shard_list = []\n",
    "    for shard in shard_dict[i]:\n",
    "        shard_list.append(\"--shard \" + shard)\n",
    "    in_dict['advanced_driver_options'] = \" \".join(shard_list)\n",
    "    vcf_collection=api.files.query(project=cur, metadata={\"shard\": i}).all()\n",
    "    vcf_list = list(vcf_collection)\n",
    "    vcf_list.sort(key=lambda x: x.name)\n",
    "    in_dict['input_vcfs'] = vcf_list\n",
    "    in_dict['output_file_name'] = \"KF-CHD_joint_genotyping_cohort_call-\" + str(i) + \".vcf.gz\"\n",
    "    task = api.tasks.create(app=app_name, name=task_name, inputs=in_dict, project=cur, run=False)\n",
    "    task.save()\n",
    "    print(\"Created task for shard \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b8062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
