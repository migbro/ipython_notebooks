{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sevenbridges as sbg\n",
    "from sevenbridges.errors import SbgError\n",
    "from sevenbridges.http.error_handlers import rate_limit_sleeper, maintenance_sleeper\n",
    "import sys\n",
    "import re\n",
    "import pdb\n",
    "import concurrent.futures\n",
    "from requests import request\n",
    "import datetime\n",
    "config = sbg.Config(profile='turbo')\n",
    "api = sbg.Api(config=config, error_handlers=[rate_limit_sleeper, maintenance_sleeper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_task(prefix, id_prefix, suffix, task):\n",
    "    # pdb.set_trace()\n",
    "    try:\n",
    "        if re.search(prefix, task.name):\n",
    "            # print (task.id + '\\t' + task.name + '\\t' + str(task.price.amount) + '\\n')\n",
    "            return task.id + '\\t' + task.name + '\\t' + str(task.price.amount) + '\\t' + task.app + '\\n'\n",
    "    except Exception as e:\n",
    "        sys.stderr.write('Could not process task ' + task.id + ' ' + task.name + ' got error ' + str(e) + '\\n')\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = 'RNAseq-BS_'\n",
    "id_pre = 'BS_'\n",
    "suffix = ''\n",
    "project = 'kids-first-drc/kids-first-drc-rnaseq-workflow'\n",
    "\n",
    "tasks = api.tasks.query(project=project, status='COMPLETED').all()\n",
    "#task = next(tasks)\n",
    "#parse_task(pre, id_pre, suffix, task)\n",
    "#pdb.set_trace()\n",
    "out_fh = open('/Users/brownm28/Documents/2022-Feb-24_gtex_gencode_compare/EXPORT/STAR_pipeline_cost.txt', 'w')\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(parse_task, pre, id_pre, suffix, task): task for task in tasks}\n",
    "    for cost_info in concurrent.futures.as_completed(results):\n",
    "        try:\n",
    "            if cost_info.result() is not None:\n",
    "                out_fh.write(cost_info.result())\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "out_fh.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get exact run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_sum_time_intervals(prefix, id_prefix, suffix, task):\n",
    "    data = []\n",
    "    if re.search(prefix, task.name):\n",
    "        for job in task.get_execution_details().jobs:\n",
    "            try:\n",
    "                pair = (job.start_time, job.end_time)\n",
    "                data.append(pair)\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                pdb.set_trace()\n",
    "                hold = 1\n",
    "        data = sorted(data, key=lambda x: x[0])\n",
    "\n",
    "\n",
    "        # from https://stackoverflow.com/questions/34797525/how-to-correctly-merge-overlapping-datetime-ranges-in-python\n",
    "        result = []\n",
    "        try:\n",
    "            t_old = data[0]\n",
    "            for t in data[1:]:\n",
    "                if t_old[1] >= t[0]:  #I assume that the data is sorted already\n",
    "                    t_old = ((min(t_old[0], t[0]), max(t_old[1], t[1])))\n",
    "                else:\n",
    "                    result.append(t_old)\n",
    "                    t_old = t\n",
    "\n",
    "            else:\n",
    "                result.append(t_old)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pdb.set_trace()\n",
    "            hold = 1\n",
    "        total_seconds = 0\n",
    "        for t_int in result:\n",
    "            total_seconds += (t_int[1] - t_int[0]).seconds\n",
    "        #print ('Task ran in ' + str(total_seconds) + ', which is ' + str(total_seconds/3600) + ' hours')\n",
    "        return task.id + '\\t' + task.name + '\\t' + str(total_seconds/3600) + '\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use task.get_execution_details().jobs - is a list that will giev you start and end time of each job, can use to create opverlapping tim e intervals, then bin and sum\n",
    "pre = 'RNAseq-BS_'\n",
    "id_pre = 'BS_'\n",
    "#suffix = 'INPUT'\n",
    "project = 'kids-first-drc/kids-first-drc-rnaseq-workflow'\n",
    "\n",
    "tasks = api.tasks.query(project=project, status='COMPLETED').all()\n",
    "# task = next(tasks)\n",
    "# merge_and_sum_time_intervals(task)\n",
    "out_fh = open('/Users/brownm28/Documents/2022-Feb-24_gtex_gencode_compare/EXPORT/star_run.txt', 'w')\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(merge_and_sum_time_intervals, pre, id_pre, suffix, task): task for task in tasks}\n",
    "    for time_info in concurrent.futures.as_completed(results):\n",
    "        try:\n",
    "            if time_info.result() is not None:\n",
    "                out_fh.write(time_info.result())\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "out_fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-41-0b9f4a6920ec>\u001b[0m(2)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aff86016-55b6-4c9b-8bed-6bf63cd526d6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 2 \u001b[0;31m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0mhold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> task.jobs\n",
      "*** AttributeError: 'Task' object has no attribute 'jobs'\n",
      "ipdb> dir(task)\n",
      "['_API', '_URL', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_api', '_data', '_dirty', '_fields', '_modified_data', '_old', '_query', '_serialize_execution_settings', '_serialize_inputs', '_set', '_to_api_file_format', '_update_read_only', 'abort', 'app', 'batch', 'batch_by', 'batch_group', 'batch_input', 'bulk_get', 'clone', 'create', 'created_by', 'created_time', 'deepcopy', 'delete', 'description', 'end_time', 'equals', 'errors', 'executed_by', 'execution_settings', 'execution_status', 'field', 'get', 'get_batch_children', 'get_execution_details', 'href', 'id', 'inputs', 'name', 'outputs', 'parent', 'price', 'project', 'query', 'reload', 'run', 'save', 'start_time', 'status', 'type', 'update_old', 'use_interruptible_instances', 'wait', 'warnings']\n",
      "ipdb> task.type\n",
      "'v2'\n",
      "ipdb> dir(task.get_execution_details().jobs)\n",
      "['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "ipdb> task.get_execution_details().jobs\n",
      "[<Job: name=gatk_intervallisttools_exome_plus, status=COMPLETED>, <Job: name=gatk_filter_germline, status=COMPLETED>, <Job: name=run_manta_rename_manta_samples, status=COMPLETED>, <Job: name=run_manta_gatk_selectvariants_manta, status=COMPLETED>, <Job: name=run_manta_manta, status=COMPLETED>, <Job: name=run_lancet_lancet_24_s, status=COMPLETED>, <Job: name=run_lancet_lancet_25_s, status=COMPLETED>, <Job: name=run_lancet_lancet_26_s, status=COMPLETED>, <Job: name=run_lancet_lancet_27_s, status=COMPLETED>, <Job: name=run_lancet_lancet_20_s, status=COMPLETED>, <Job: name=run_lancet_lancet_21_s, status=COMPLETED>, <Job: name=run_lancet_lancet_22_s, status=COMPLETED>, <Job: name=run_lancet_lancet_23_s, status=COMPLETED>, <Job: name=run_lancet_lancet_28_s, status=COMPLETED>, <Job: name=run_lancet_lancet_29_s, status=COMPLETED>, <Job: name=run_lancet_pickvalue_workaround, status=COMPLETED>, <Job: name=run_lancet_lancet_13_s, status=COMPLETED>, <Job: name=run_lancet_lancet_14_s, status=COMPLETED>, <Job: name=run_lancet_lancet_15_s, status=COMPLETED>, <Job: name=run_lancet_lancet_16_s, status=COMPLETED>, <Job: name=run_lancet_lancet_10_s, status=COMPLETED>, <Job: name=run_lancet_lancet_11_s, status=COMPLETED>, <Job: name=run_lancet_lancet_12_s, status=COMPLETED>, <Job: name=run_lancet_lancet_17_s, status=COMPLETED>, <Job: name=run_lancet_lancet_18_s, status=COMPLETED>, <Job: name=run_lancet_lancet_19_s, status=COMPLETED>, <Job: name=run_lancet_lancet_46_s, status=COMPLETED>, <Job: name=run_lancet_lancet_47_s, status=COMPLETED>, <Job: name=run_lancet_lancet_48_s, status=COMPLETED>, <Job: name=run_lancet_lancet_49_s, status=COMPLETED>, <Job: name=run_lancet_lancet_42_s, status=COMPLETED>, <Job: name=run_lancet_lancet_43_s, status=COMPLETED>, <Job: name=run_lancet_lancet_44_s, status=COMPLETED>, <Job: name=run_lancet_lancet_45_s, status=COMPLETED>, <Job: name=run_lancet_annotate_kfdrc_vcf2maf_public, status=COMPLETED>, <Job: name=run_lancet_lancet_40_s, status=COMPLETED>, <Job: name=run_lancet_lancet_41_s, status=COMPLETED>, <Job: name=run_lancet_lancet_35_s, status=COMPLETED>, <Job: name=run_lancet_lancet_36_s, status=COMPLETED>, <Job: name=run_lancet_lancet_37_s, status=COMPLETED>, <Job: name=run_lancet_lancet_38_s, status=COMPLETED>, <Job: name=run_lancet_lancet_31_s, status=COMPLETED>, <Job: name=run_lancet_lancet_32_s, status=COMPLETED>, <Job: name=run_lancet_lancet_33_s, status=COMPLETED>, <Job: name=run_lancet_lancet_34_s, status=COMPLETED>, <Job: name=run_lancet_lancet_39_s, status=COMPLETED>, <Job: name=run_lancet_lancet_7_s, status=COMPLETED>, <Job: name=run_lancet_lancet_6_s, status=COMPLETED>, <Job: name=run_lancet_lancet_9_s, status=COMPLETED>, <Job: name=run_lancet_lancet_8_s, status=COMPLETED>, <Job: name=run_lancet_annotate_vep_annotate_vcf, status=COMPLETED>, <Job: name=run_lancet_lancet_3_s, status=COMPLETED>, <Job: name=run_lancet_lancet_2_s, status=COMPLETED>, <Job: name=run_lancet_lancet_5_s, status=COMPLETED>, <Job: name=run_lancet_lancet_4_s, status=COMPLETED>, <Job: name=run_lancet_lancet_30_s, status=COMPLETED>, <Job: name=run_lancet_annotate_rename_protected, status=COMPLETED>, <Job: name=run_lancet_sort_merge_lancet_vcf, status=COMPLETED>, <Job: name=run_lancet_lancet_50_s, status=COMPLETED>, <Job: name=run_lancet_annotate_normalize_vcf, status=COMPLETED>, <Job: name=run_lancet_annotate_rename_public, status=COMPLETED>, <Job: name=run_lancet_annotate_hard_filter_vcf, status=COMPLETED>, <Job: name=run_lancet_annotate_bcftools_gnomad_annotate, status=COMPLETED>, <Job: name=run_lancet_lancet_1_s, status=COMPLETED>, <Job: name=run_lancet_annotate_hotspots_annotation, status=COMPLETED>, <Job: name=run_lancet_gatk_selectvariants_lancet, status=COMPLETED>, <Job: name=run_lancet_annotate_gatk_add_soft_filter, status=COMPLETED>, <Job: name=run_lancet_annotate_kfdrc_vcf2maf_protected, status=COMPLETED>, <Job: name=run_lancet_rename_vcf_samples, status=COMPLETED>, <Job: name=select_vardict_bed_interval, status=COMPLETED>, <Job: name=select_interval_list, status=COMPLETED>, <Job: name=expression_flatten_subclonal_results, status=COMPLETED>, <Job: name=select_mutect_bed_interval, status=COMPLETED>, <Job: name=run_vardict_annotate_vep_annotate_vcf, status=COMPLETED>, <Job: name=run_vardict_gatk_selectvariants_vardict, status=COMPLETED>, <Job: name=run_vardict_vardict_3_s, status=COMPLETED>, <Job: name=run_vardict_vardict_2_s, status=COMPLETED>, <Job: name=run_vardict_vardict_1_s, status=COMPLETED>, <Job: name=run_vardict_vardict_7_s, status=COMPLETED>, <Job: name=run_vardict_vardict_6_s, status=COMPLETED>, <Job: name=run_vardict_vardict_5_s, status=COMPLETED>, <Job: name=run_vardict_vardict_4_s, status=COMPLETED>, <Job: name=run_vardict_vardict_9_s, status=COMPLETED>, <Job: name=run_vardict_vardict_8_s, status=COMPLETED>, <Job: name=run_vardict_bcbio_filter_fp_somatic, status=COMPLETED>, <Job: name=run_vardict_annotate_normalize_vcf, status=COMPLETED>, <Job: name=run_vardict_annotate_hard_filter_vcf, status=COMPLETED>, <Job: name=run_vardict_annotate_rename_protected, status=COMPLETED>, <Job: name=run_vardict_rename_vcf_samples, status=COMPLETED>, <Job: name=run_vardict_annotate_kfdrc_vcf2maf_public, status=COMPLETED>, <Job: name=run_vardict_annotate_hotspots_annotation, status=COMPLETED>, <Job: name=run_vardict_vardict_30_s, status=COMPLETED>, <Job: name=run_vardict_vardict_32_s, status=COMPLETED>, <Job: name=run_vardict_vardict_31_s, status=COMPLETED>, <Job: name=run_vardict_vardict_34_s, status=COMPLETED>, <Job: name=run_vardict_vardict_33_s, status=COMPLETED>, <Job: name=run_vardict_vardict_36_s, status=COMPLETED>, <Job: name=run_vardict_vardict_35_s, status=COMPLETED>, <Job: name=run_vardict_vardict_38_s, status=COMPLETED>, <Job: name=run_vardict_vardict_37_s, status=COMPLETED>, <Job: name=run_vardict_vardict_39_s, status=COMPLETED>, <Job: name=run_vardict_vardict_19_s, status=COMPLETED>, <Job: name=run_vardict_vardict_21_s, status=COMPLETED>, <Job: name=run_vardict_vardict_20_s, status=COMPLETED>, <Job: name=run_vardict_vardict_23_s, status=COMPLETED>, <Job: name=run_vardict_vardict_22_s, status=COMPLETED>, <Job: name=run_vardict_sort_merge_vardict_vcf, status=COMPLETED>, <Job: name=run_vardict_vardict_25_s, status=COMPLETED>, <Job: name=run_vardict_vardict_24_s, status=COMPLETED>, <Job: name=run_vardict_vardict_27_s, status=COMPLETED>, <Job: name=run_vardict_vardict_26_s, status=COMPLETED>, <Job: name=run_vardict_vardict_29_s, status=COMPLETED>, <Job: name=run_vardict_vardict_28_s, status=COMPLETED>, <Job: name=run_vardict_pickvalue_workaround, status=COMPLETED>, <Job: name=run_vardict_vardict_50_s, status=COMPLETED>, <Job: name=run_vardict_vardict_52_s, status=COMPLETED>, <Job: name=run_vardict_vardict_51_s, status=COMPLETED>, <Job: name=run_vardict_vardict_54_s, status=COMPLETED>, <Job: name=run_vardict_vardict_53_s, status=COMPLETED>, <Job: name=run_vardict_vardict_56_s, status=COMPLETED>, <Job: name=run_vardict_vardict_55_s, status=COMPLETED>, <Job: name=run_vardict_annotate_gatk_add_soft_filter, status=COMPLETED>, <Job: name=run_vardict_vardict_41_s, status=COMPLETED>, <Job: name=run_vardict_annotate_kfdrc_vcf2maf_protected, status=COMPLETED>, <Job: name=run_vardict_vardict_40_s, status=COMPLETED>, <Job: name=run_vardict_vardict_43_s, status=COMPLETED>, <Job: name=run_vardict_vardict_42_s, status=COMPLETED>, <Job: name=run_vardict_vardict_45_s, status=COMPLETED>, <Job: name=run_vardict_vardict_44_s, status=COMPLETED>, <Job: name=run_vardict_annotate_rename_public, status=COMPLETED>, <Job: name=run_vardict_vardict_47_s, status=COMPLETED>, <Job: name=run_vardict_vardict_46_s, status=COMPLETED>, <Job: name=run_vardict_vardict_49_s, status=COMPLETED>, <Job: name=run_vardict_vardict_48_s, status=COMPLETED>, <Job: name=run_vardict_annotate_bcftools_gnomad_annotate, status=COMPLETED>, <Job: name=run_vardict_vardict_10_s, status=COMPLETED>, <Job: name=run_vardict_vardict_12_s, status=COMPLETED>, <Job: name=run_vardict_vardict_11_s, status=COMPLETED>, <Job: name=run_vardict_vardict_14_s, status=COMPLETED>, <Job: name=run_vardict_vardict_13_s, status=COMPLETED>, <Job: name=run_vardict_vardict_16_s, status=COMPLETED>, <Job: name=run_vardict_vardict_15_s, status=COMPLETED>, <Job: name=run_vardict_vardict_18_s, status=COMPLETED>, <Job: name=run_vardict_vardict_17_s, status=COMPLETED>, <Job: name=run_amplicon_architect_cns_to_aa_bed, status=COMPLETED>, <Job: name=run_amplicon_architect_untar_data_repo, status=COMPLETED>, <Job: name=run_amplicon_architect_prepare_aa, status=COMPLETED>, <Job: name=run_amplicon_architect_amplicon_architect, status=COMPLETED>, <Job: name=samtools_cram2bam_plus_calmd_normal, status=COMPLETED>, <Job: name=run_theta2_purity_cnvkit_import_theta2, status=COMPLETED>, <Job: name=run_theta2_purity_bcftools_filter_combined_vcf, status=COMPLETED>, <Job: name=run_theta2_purity_cnvkit_export_theta2, status=COMPLETED>, <Job: name=run_theta2_purity_run_theta2, status=COMPLETED>, <Job: name=bedtools_intersect_germline, status=FAILED>, <Job: name=bedtools_intersect_germline, status=COMPLETED>, <Job: name=index_bcftools_annot_vcf, status=COMPLETED>, <Job: name=run_gatk_cnv_call_copy_ratio_segments_tumor, status=COMPLETED>, <Job: name=run_gatk_cnv_plot_denoised_copy_ratios_normal, status=COMPLETED>, <Job: name=run_gatk_cnv_plot_modeled_segments_normal, status=COMPLETED>, <Job: name=run_gatk_cnv_model_segments_tumor, status=COMPLETED>, <Job: name=run_gatk_cnv_funcotate_segments, status=COMPLETED>, <Job: name=run_gatk_cnv_awk_min_seg_length_tumor, status=COMPLETED>, <Job: name=run_gatk_cnv_plot_modeled_segments_tumor, status=COMPLETED>, <Job: name=run_gatk_cnv_tar_outputs_normal, status=COMPLETED>, <Job: name=run_gatk_cnv_collect_allelic_counts_tumor, status=COMPLETED>, <Job: name=run_gatk_cnv_denoise_read_counts_tumor, status=COMPLETED>, <Job: name=run_gatk_cnv_model_segments_normal, status=COMPLETED>, <Job: name=run_gatk_cnv_collect_allelic_counts_normal, status=COMPLETED>, <Job: name=run_gatk_cnv_collect_read_counts_normal, status=COMPLETED>, <Job: name=run_gatk_cnv_preprocess_intervals, status=COMPLETED>, <Job: name=run_gatk_cnv_plot_denoised_copy_ratios_tumor, status=COMPLETED>, <Job: name=run_gatk_cnv_call_copy_ratio_segments_normal, status=COMPLETED>, <Job: name=run_gatk_cnv_collect_read_counts_tumor, status=COMPLETED>, <Job: name=run_gatk_cnv_tar_outputs_tumor, status=COMPLETED>, <Job: name=run_gatk_cnv_denoise_read_counts_normal, status=COMPLETED>, <Job: name=run_cnvkit_cnvkit, status=COMPLETED>, <Job: name=run_strelka2_annotate_rename_public, status=COMPLETED>, <Job: name=run_strelka2_gatk_selectvariants_strelka2, status=COMPLETED>, <Job: name=run_strelka2_annotate_rename_protected, status=COMPLETED>, <Job: name=run_strelka2_annotate_hard_filter_vcf, status=COMPLETED>, <Job: name=run_strelka2_annotate_vep_annotate_vcf, status=COMPLETED>, <Job: name=run_strelka2_strelka2, status=COMPLETED>, <Job: name=run_strelka2_merge_strelka2_vcf, status=COMPLETED>, <Job: name=run_strelka2_annotate_normalize_vcf, status=COMPLETED>, <Job: name=run_strelka2_annotate_kfdrc_vcf2maf_public, status=COMPLETED>, <Job: name=run_strelka2_annotate_hotspots_annotation, status=COMPLETED>, <Job: name=run_strelka2_annotate_kfdrc_vcf2maf_protected, status=COMPLETED>, <Job: name=run_strelka2_annotate_add_standard_fields, status=COMPLETED>, <Job: name=run_strelka2_annotate_gatk_add_soft_filter, status=COMPLETED>, <Job: name=run_strelka2_rename_strelka_samples, status=COMPLETED>, <Job: name=run_strelka2_annotate_bcftools_gnomad_annotate, status=COMPLETED>, <Job: name=python_vardict_interval_split, status=COMPLETED>, <Job: name=run_controlfreec_controlfreec_normal_mini_pileup, status=COMPLETED>, <Job: name=run_controlfreec_controlfreec_tumor_mini_pileup, status=COMPLETED>, <Job: name=run_controlfreec_rename_outputs, status=COMPLETED>, <Job: name=run_controlfreec_control_free_c, status=COMPLETED>, <Job: name=run_controlfreec_convert_ratio_to_seg, status=COMPLETED>, <Job: name=index_b_allele, status=COMPLETED>, <Job: name=prepare_reference_picard_create_sequence_dictionary, status=COMPLETED>, <Job: name=prepare_reference_bundle_secondaries, status=COMPLETED>, <Job: name=prepare_reference_bundle_secondaries, status=FAILED>, <Job: name=prepare_reference_bwa_index, status=COMPLETED>, <Job: name=prepare_reference_samtools_faidx, status=COMPLETED>, <Job: name=run_annotsv, status=COMPLETED>, <Job: name=bedops_gen_lancet_intervals, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_17_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_18_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_19_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_41_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_40_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_39_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_24_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_32_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_25_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_31_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_26_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_34_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_27_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_33_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_20_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_36_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_21_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_35_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_22_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_38_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_23_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_37_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_1_s, status=COMPLETED>, <Job: name=run_mutect2_annotate_hard_filter_vcf, status=COMPLETED>, <Job: name=run_mutect2_mutect2_30_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_9_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_8_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_7_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_6_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_5_s, status=COMPLETED>, <Job: name=run_mutect2_annotate_bcftools_gnomad_annotate, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_4_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_3_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_2_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_29_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_28_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_13_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_21_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_14_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_20_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_15_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_23_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_16_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_22_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_25_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_10_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_24_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_gather_normal_pileup_summaries, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_11_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_27_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_12_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_26_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_39_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_18_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_17_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_41_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_40_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_40_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_41_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_19_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_43_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_42_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_45_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_44_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_46_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_10_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_46_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_12_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_11_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_42_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_14_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_43_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_13_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_44_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_16_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_45_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_15_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_28_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_29_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_30_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_30_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_32_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_31_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_34_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_33_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_35_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_36_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_35_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_36_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_37_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_38_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_38_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_37_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_31_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_32_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_39_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_33_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_tumor_pileup_summaries_34_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_21_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_20_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_23_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_22_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_25_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_24_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_27_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_26_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_29_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_28_s, status=COMPLETED>, <Job: name=run_mutect2_annotate_gatk_add_soft_filter, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_8_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_9_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_6_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_7_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_10_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_12_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_11_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_14_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_13_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_16_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_15_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_18_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_17_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_19_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_4_s, status=COMPLETED>, <Job: name=run_mutect2_merge_mutect2_stats, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_5_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_2_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_3_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_get_normal_pileup_summaries_1_s, status=COMPLETED>, <Job: name=run_mutect2_annotate_kfdrc_vcf2maf_protected, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_learn_orientation_bias, status=COMPLETED>, <Job: name=run_mutect2_mutect2_43_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_42_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_45_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_44_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_46_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_1_s, status=COMPLETED>, <Job: name=run_mutect2_merge_mutect2_vcf, status=COMPLETED>, <Job: name=run_mutect2_mutect2_5_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_4_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_3_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_2_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_9_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_8_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_7_s, status=COMPLETED>, <Job: name=run_mutect2_mutect2_6_s, status=COMPLETED>, <Job: name=run_mutect2_annotate_normalize_vcf, status=COMPLETED>, <Job: name=run_mutect2_gatk_selectvariants_mutect2, status=COMPLETED>, <Job: name=run_mutect2_annotate_vep_annotate_vcf, status=COMPLETED>, <Job: name=run_mutect2_filter_mutect2_vcf, status=COMPLETED>, <Job: name=run_mutect2_annotate_kfdrc_vcf2maf_public, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_calculate_contamination, status=COMPLETED>, <Job: name=run_mutect2_annotate_rename_public, status=COMPLETED>, <Job: name=run_mutect2_annotate_hotspots_annotation, status=COMPLETED>, <Job: name=run_mutect2_annotate_rename_protected, status=COMPLETED>, <Job: name=run_mutect2_mutect2_filter_support_gatk_gather_tumor_pileup_summaries, status=COMPLETED>, <Job: name=run_mutect2_rename_vcf_samples, status=COMPLETED>, <Job: name=run_mutect2_pickvalue_workaround, status=COMPLETED>, <Job: name=index_mutect_exac, status=COMPLETED>, <Job: name=gatk_intervallisttools, status=COMPLETED>, <Job: name=select_lancet_bed_inteval, status=COMPLETED>, <Job: name=samtools_cram2bam_plus_calmd_tumor, status=COMPLETED>, <Job: name=index_strelka_bed, status=COMPLETED>, <Job: name=choose_defaults, status=COMPLETED>, <Job: name=index_mutect_gnomad, status=FAILED>, <Job: name=index_mutect_gnomad, status=COMPLETED>, <Job: name=expression_run_aa_if_wgs, status=COMPLETED>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> task.get_execution_details().jobs[10]\n",
      "<Job: name=run_lancet_lancet_21_s, status=COMPLETED>\n",
      "ipdb> dir(task.get_execution_details().jobs[10])\n",
      "['_API', '_URL', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_api', '_data', '_dirty', '_fields', '_modified_data', '_old', '_query', '_set', '_update_read_only', 'command_line', 'deepcopy', 'delete', 'docker', 'end_time', 'equals', 'field', 'get', 'instance', 'logs', 'name', 'reload', 'retried', 'start_time', 'status', 'update_old']\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0b9f4a6920ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aff86016-55b6-4c9b-8bed-6bf63cd526d6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/bdb.py\u001b[0m in \u001b[0;36mdispatch_return\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;31m# The user issued a 'next' or 'until' command.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoplineno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "task = api.tasks.get('aff86016-55b6-4c9b-8bed-6bf63cd526d6')\n",
    "pdb.set_trace()\n",
    "hold=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Per-job-per-task run time and instance time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_run_times(task):\n",
    "    print(\"Processing task \" + task.name)\n",
    "    data = {}\n",
    "    vm_types = {}\n",
    "    for job in task.get_execution_details().jobs:\n",
    "        if job.status == \"COMPLETED\" and job.instance.type != 'precomputed':\n",
    "            try:\n",
    "                # print (job.name + \"\\t\" + str((job.end_time - job.start_time).seconds/3600))\n",
    "                # sys.stderr.write(job.name + '\\n')\n",
    "                vm = job.instance.id\n",
    "                if vm not in data:\n",
    "                    data[vm] = []\n",
    "                    vm_types[vm] = job.instance.type\n",
    "                pair = (job.start_time, job.end_time)\n",
    "                data[vm].append(pair)\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                pdb.set_trace()\n",
    "                hold = 1\n",
    "    total_hrs = 0\n",
    "    total_spot_cost = 0\n",
    "    total_direct_cost = 0\n",
    "    machine_hrs = {}\n",
    "#     c5_9_spot = 0.5164\n",
    "#     c5_9_direct = 1.53\n",
    "#     m4_10_spot = 0.412\n",
    "#     m4_10_direct = 2\n",
    "#     spot_rate = c5_9_spot\n",
    "#     direct_rate = c5_9_direct\n",
    "    print(\"Processing vm data\")\n",
    "    for vm in data:\n",
    "        data[vm] = sorted(data[vm], key=lambda x: x[0])\n",
    "        result = []\n",
    "        try:\n",
    "            t_old = data[vm][0]\n",
    "            for t in data[vm][1:]:\n",
    "                if t_old[1] >= t[0]:  #I assume that the data is sorted already\n",
    "                    t_old = ((min(t_old[0], t[0]), max(t_old[1], t[1])))\n",
    "                else:\n",
    "                    result.append(t_old)\n",
    "                    t_old = t\n",
    "\n",
    "            else:\n",
    "                result.append(t_old)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pdb.set_trace()\n",
    "            hold = 1\n",
    "        total_seconds = 0\n",
    "        for t_int in result:\n",
    "            total_seconds += (t_int[1] - t_int[0]).seconds\n",
    "        #print ('Task ran in ' + str(total_seconds) + ', which is ' + str(total_seconds/3600) + ' hours')\n",
    "        # print(vm + '\\t' + '\\t' + str(total_seconds/3600))\n",
    "        run_hrs = total_seconds/3600\n",
    "        vm_type = vm_types[vm]\n",
    "        if vm_type not in machine_hrs:\n",
    "            machine_hrs[vm_type] = 0\n",
    "        spot_cost = run_hrs * spot_instance[vm_type]\n",
    "        direct_cost = run_hrs * on_demand_instance[vm_type]\n",
    "        out_fh.write(\"\\t\".join([task.name, task.id, vm_type, vm, str(run_hrs), str(spot_cost), str(direct_cost)]) + \"\\n\")\n",
    "        total_hrs += run_hrs\n",
    "        machine_hrs[vm_type] += run_hrs\n",
    "        total_spot_cost += spot_cost \n",
    "        total_direct_cost += direct_cost\n",
    "    \n",
    "    summary.write(\"\\t\".join([task.name, task.id, str(task.price.amount), str(total_spot_cost), str(total_direct_cost)]) + '\\n')\n",
    "    for vm_type in machine_hrs:\n",
    "        machine_hrs_fh.write(\"\\t\".join([task.name, task.id,vm_type, str(machine_hrs[vm_type])]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_420TZWST -vs- BS_EZA1EYWV\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_DM0358AQ -vs- BS_86TFE982\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_KVC8X5BX -vs- BS_2DAN8S59\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_B5T9CFX0 -vs- BS_8CBDRARJ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_5357BVCQ -vs- BS_3VMWCBV7\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_FXWGAQQ1 -vs- BS_8CBDRARJ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_BYNGYA6A -vs- BS_3VMWCBV7\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_HGE47RGT -vs- BS_YZZ7FDBP\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_6FVT4ZZJ -vs- BS_B69YME43\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_ZGSTZCYN -vs- BS_GXJ70WTA\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_B94PF9E1 -vs- BS_GXJ70WTA\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_4YE9CKC6 -vs- BS_GXJ70WTA\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_4ZG27R47 -vs- BS_Y1HPE7KA\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_CHFJZQWR -vs- BS_04G6D4W2\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_E1GFZBG3 -vs- BS_ZQH1NC54\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_GV24KB8P -vs- BS_3WYSRM29\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_E4C16ZWG -vs- BS_T0MECPMN\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_Y9ZBD2KA -vs- BS_RTM1YZWM\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_V7VQP1QM -vs- BS_8Q89SMAP\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_B5V3KSQY -vs- BS_RZN71A5Z\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_XWYBVJ4R -vs- BS_EPRR8MCX\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_W37YKD6X -vs- BS_RM9HDDVZ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_7JZZDDHC -vs- BS_SP1SNZZ2\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_70AW1WH4 -vs- BS_N6D427GB\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_BF2MCS03 -vs- BS_04G6D4W2\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_J0Y3MAPC -vs- BS_3VMWCBV7\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_DD08M2NA -vs- BS_2V2QAAX5\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_GNXGGWFN -vs- BS_RM9HDDVZ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_209RV8H2 -vs- BS_RM9HDDVZ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_7NFEBJ9X -vs- BS_3VMWCBV7\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_00GG0R70 -vs- BS_6S4F9542\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_DWSKVGZ9 -vs- BS_SQ3JEW5T\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_H8JZ6CZR -vs- BS_RM9HDDVZ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_F2MTFYFR -vs- BS_RM9HDDVZ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_1VC0YAGC -vs- BS_N6D427GB\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_CJ2G78ZZ -vs- BS_RM9HDDVZ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_E3N4JN0X -vs- BS_04G6D4W2\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_F0JN3TFM -vs- BS_TJW2Z7AB\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_8TRGVZ3F -vs- BS_N6D427GB\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_PRRX1BK8 -vs- BS_MTPSXQPW\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_3KD309X6 -vs- BS_22N5N72T\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_Q03MVGN6 -vs- BS_RM9HDDVZ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_PZEB1PFD -vs- BS_BC25G7NN\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_4FKXNJHW -vs- BS_RZJ9YNST\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_HAG8H8N1 -vs- BS_SKQNH1YD\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_GH6PH611 -vs- BS_22N5N72T\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_YBZ2DNSK -vs- BS_0MGSQ9WS\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_T45AJSTV -vs- BS_S18M3M8M\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_8A2786RZ -vs- BS_G5A9M5BS\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_4NFFJ9XE -vs- BS_CPHMDT93\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_PS00F8DA -vs- BS_46K0RP9Z\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_PYEB0KYG -vs- BS_39PND0JF\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_NK9XQ95W -vs- BS_9C6W872V\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_0E8WBZBF -vs- BS_9PXN1TH6\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_AH252MTC -vs- BS_22N5N72T\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_AFPZ71DG -vs- BS_JJNJ7KP3\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_4HRYS7JY -vs- BS_MASK5Y10\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_P3NDA9Z7 -vs- BS_C6SAG495\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_FZ8D57HJ -vs- BS_22N5N72T\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_KG4S1KES -vs- BS_CPSYDZTY\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_9T43YEPA -vs- BS_1VD6C04K\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_5Y3RMFEZ -vs- BS_BJHKB2M1\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_8GN2X2RB -vs- BS_EFYEMMEQ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_70CGW2TP -vs- BS_QD39WFDP\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_STW7TF1J -vs- BS_R7V1J98Q\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_MD2R88X3 -vs- BS_EFMKK48P\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_ZMV0AF4H -vs- BS_1KB9QGGE\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_6DC7GEYT -vs- BS_V1HD4M79\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_6G19QBAY -vs- BS_A42RJCPM\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_5VD3BNNV -vs- BS_2J6FFWRB\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_110K2FF7 -vs- BS_SPGHGA9C\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_S4CG60MW -vs- BS_PAAVMR28\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_FJRZJ4RS -vs- BS_P9P6B2MA\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_HHNG2JZT -vs- BS_YJ6Z96VQ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_Z9YAGQYA -vs- BS_BPDEWRSY\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_92K4T45D -vs- BS_N45WV87Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_9E2FF9ZP -vs- BS_B4JS5CB6\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_1KP6JADZ -vs- BS_1X3JQ424\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_44ANHKWM -vs- BS_FY5KW796\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_1GFA9NF0 -vs- BS_2PVZE2AG\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_537YFJ06 -vs- BS_04G6D4W2\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_1AMAP96X -vs- BS_E79GK5SS\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_97M1BPNE -vs- BS_Q1JQ16CZ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_G3B24JW8 -vs- BS_BDBTPH49\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_QE6NEYTV -vs- BS_02MN8B6F\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_YG6FYM9A -vs- BS_WX1XR5S2\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_T0G1JWZV -vs- BS_5RTSS5DW\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_X2VRDBVG -vs- BS_K0QQJ205\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_ANFZNMQ4 -vs- BS_YZSMRGNK\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_VBADSQPW -vs- BS_8RTC36WH\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_2T4EJ6KN -vs- BS_04G6D4W2\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_4T994QT4 -vs- BS_TTXW2GPQ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_G6YHGFF2 -vs- BS_FR931X7X\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_MT7ZHBK4 -vs- BS_AVAP4RXQ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_9GDM4FG4 -vs- BS_GJ1260FS\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_YQQ4Q13Y -vs- BS_1QJZNS57\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_WJ7BS3HN -vs- BS_Q3QTZCT0\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_3DGPSEH2 -vs- BS_GV35HW7N\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_57ZNS4K5 -vs- BS_BFV6SJ95\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_9XQVJS03 -vs- BS_TTXW2GPQ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_WN6EX9EK -vs- BS_GYVQCAQZ\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_GZ5QQYZ7 -vs- BS_TZ5YARH0\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_P2GA1245 -vs- BS_PEMY24Z2\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_SR0TJ11R -vs- BS_2D1FDNX3\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_P9P1N48D -vs- BS_BXJYB2PX\n",
      "Processing vm data\n",
      "Processing task Kids First DRC Somatic Variant Workflow run - BS_X6NW8R6K -vs- BS_A385FF70\n",
      "Processing vm data\n"
     ]
    }
   ],
   "source": [
    "pre = 'Kids First DRC Somatic Variant Workflow'\n",
    "#suffix = 'INPUT'\n",
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-x01-somatic-mutations-wgs-tumor'\n",
    "# bs_ids = ['BS_SR0TJ11R','BS_P9P1N48D','BS_X6NW8R6K']\n",
    "bs_ids = []\n",
    "spot_instance= { 'r5.large': 0.0227, 'r5.4xlarge': 0.1867,'c4.2xlarge': 0.1896, 'c5.4xlarge': 0.2901, 'c5.9xlarge': 0.6689, 'c4.8xlarge': 0.5653, 'r5.2xlarge': 0.1795, 'c5.2xlarge': 0.1684, 'm5.2xlarge': 0.1405,'m5.xlarge': 0.0686, 'r5.xlarge': 0.0718}\n",
    "on_demand_instance = { 'r5.large': 0.126,'r5.4xlarge': 1.008, 'c4.2xlarge': 0.398, 'c5.4xlarge': 0.68, 'c5.9xlarge': 1.53, 'c4.8xlarge': 1.591, 'r5.2xlarge': 0.504, 'c5.2xlarge': 0.34, 'm5.2xlarge': 0.384, 'm5.xlarge': 0.192, 'r5.xlarge': 0.252}\n",
    "\n",
    "tasks = api.tasks.query(project=project, status='COMPLETED').all()\n",
    "# task = next(tasks)\n",
    "# merge_and_sum_time_intervals(task)\n",
    "out_fh = open('/Users/brownm28/Documents/playground/somatic_cost_estimates/to_date_wf_est.txt', 'w')\n",
    "out_fh.write('task_name\\ttask_id\\tinstance_type\\tinstance_id\\ttotal_run_time\\tspot_cost\\tdirect_cost\\n')\n",
    "summary = open('/Users/brownm28/Documents/playground/somatic_cost_estimates/to_date_wf_summary_est.txt', 'w')\n",
    "summary.write('task_name\\ttask_id\\tactual_cost\\tpure_spot_cost\\tpure_direct_cost\\n')\n",
    "machine_hrs_fh = open('/Users/brownm28/Documents/playground/somatic_cost_estimates/to_date_wf_machine_hrs.txt', 'w')\n",
    "machine_hrs_fh.write('task_name\\ttask_id\\tmachine_type\\ttotal_run_hrs\\n')\n",
    "for task in tasks:\n",
    "#     task_split = task.name.split(' - ')\n",
    "    if re.search(pre, task.name):\n",
    "        if bs_ids:\n",
    "            bs_id = re.match('.*(BS_\\w+) -vs-.*', task.name)\n",
    "            if bs_id is not None and bs_id.group(1) in bs_ids:\n",
    "                get_instance_run_times(task)\n",
    "        else:\n",
    "            get_instance_run_times(task)\n",
    "out_fh.close()\n",
    "summary.close()\n",
    "machine_hrs_fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_run_time(data):\n",
    "    data = sorted(data, key=lambda x: x[0])\n",
    "\n",
    "\n",
    "    # from https://stackoverflow.com/questions/34797525/how-to-correctly-merge-overlapping-datetime-ranges-in-python\n",
    "    result = []\n",
    "    try:\n",
    "        t_old = data[0]\n",
    "        for t in data[1:]:\n",
    "            if t_old[1] >= t[0]:  #I assume that the data is sorted already\n",
    "                t_old = ((min(t_old[0], t[0]), max(t_old[1], t[1])))\n",
    "            else:\n",
    "                result.append(t_old)\n",
    "                t_old = t\n",
    "\n",
    "        else:\n",
    "            result.append(t_old)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pdb.set_trace()\n",
    "        hold = 1\n",
    "    total_seconds = 0\n",
    "    for t_int in result:\n",
    "        total_seconds += (t_int[1] - t_int[0]).seconds\n",
    "    return total_seconds/3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_blacklist = ['generate_gvcf', 'gatk_haplotypecaller', 'picard_collectgvcfcallingmetrics', 'checkcontamination', 'picard_mergevcfs']\n",
    "job_blacklist = []\n",
    "spot_instance= { 'c4.2xlarge': 0.1896, 'c5.4xlarge': 0.2901, 'c5.9xlarge': 0.6689, 'c4.8xlarge': 0.5653, 'r5.2xlarge': 0.1795, 'c5.2xlarge': 0.1684, 'm5.2xlarge': 0.1405,'m5.xlarge': 0.0686, 'r5.xlarge': 0.0718}\n",
    "on_demand_instance = { 'c4.2xlarge': 0.398, 'c5.4xlarge': 0.68, 'c5.9xlarge': 1.53, 'c4.8xlarge': 1.591, 'r5.2xlarge': 0.504, 'c5.2xlarge': 0.34, 'm5.2xlarge': 0.384, 'm5.xlarge': 0.192, 'r5.xlarge': 0.252}\n",
    "#sentieon = '/Users/brownm28/Documents/2022-Feb-24_gtex_gencode_compare/EXPORT/sentieon_estimates.txt'\n",
    "#fy17 = '/Users/brownm28/Documents/2022-Feb-24_gtex_gencode_compare/EXPORT/fy17_sobreira_estimates.txt'\n",
    "#process_file(sentieon, '/Users/brownm28/Documents/2022-Feb-24_gtex_gencode_compare/EXPORT/sentieon_summary.txt', job_blacklist, spot_instance, on_demand_instance)\n",
    "#process_file(fy17, '/Users/brownm28/Documents/2022-Feb-24_gtex_gencode_compare/EXPORT/fy17_sobreira_summary.txt', job_blacklist, spot_instance, on_demand_instance)\n",
    "somatic_subset = '/Users/brownm28/Documents/playground/somatic_cost_estimates/subset.txt'\n",
    "process_file(somatic_subset, '/Users/brownm28/Documents/playground/somatic_cost_estimates/subset_summary.txt', job_blacklist, spot_instance, on_demand_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get task log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = '575f8184-f6b1-4191-b119-1672b75d8d61'\n",
    "project = 'zhangb1/kf-somatic-tools-test'\n",
    "task = api.tasks.get(tid)\n",
    "for job in task.get_execution_details().jobs:\n",
    "    if re.search('seg', job.name):\n",
    "        print (job.logs['cmd.log'].content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get job run times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = api.tasks.get(\"7174d826-422d-4577-a288-3c6adc1f6f5a\")\n",
    "phrase = \"vardict\"\n",
    "for job in task.get_execution_details().jobs:\n",
    "    if job.status == \"COMPLETED\" and re.search(phrase, job.name):\n",
    "        # pdb.set_trace()\n",
    "        try:\n",
    "            print (job.name + \"\\t\" + str((job.end_time - job.start_time).seconds/3600))\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            pdb.set_trace()\n",
    "#hold=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get instance run times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = api.tasks.get(\"8acc7912-5380-4db0-8edc-a21ed93833d0\")\n",
    "phrase = \"vardict_\\d+\"\n",
    "data = {}\n",
    "for job in task.get_execution_details().jobs:\n",
    "    if job.status == \"COMPLETED\" and re.search(phrase, job.name):\n",
    "        try:\n",
    "            # print (job.name + \"\\t\" + str((job.end_time - job.start_time).seconds/3600))\n",
    "            sys.stderr.write(job.name + '\\n')\n",
    "            vm = job.instance.id\n",
    "            if vm not in data:\n",
    "                data[vm] = []\n",
    "            pair = (job.start_time, job.end_time)\n",
    "            data[vm].append(pair)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            pdb.set_trace()\n",
    "            hold = 1\n",
    "total_hrs = 0\n",
    "c5_9_spot = 0.5164\n",
    "c5_9_direct = 1.53\n",
    "m4_10_spot = 0.412\n",
    "m4_10_direct = 2\n",
    "spot_rate = c5_9_spot\n",
    "direct_rate = c5_9_direct\n",
    "for vm in data:\n",
    "    data[vm] = sorted(data[vm], key=lambda x: x[0])\n",
    "    result = []\n",
    "    try:\n",
    "        t_old = data[vm][0]\n",
    "        for t in data[vm][1:]:\n",
    "            if t_old[1] >= t[0]:  #I assume that the data is sorted already\n",
    "                t_old = ((min(t_old[0], t[0]), max(t_old[1], t[1])))\n",
    "            else:\n",
    "                result.append(t_old)\n",
    "                t_old = t\n",
    "\n",
    "        else:\n",
    "            result.append(t_old)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pdb.set_trace()\n",
    "        hold = 1\n",
    "    total_seconds = 0\n",
    "    for t_int in result:\n",
    "        total_seconds += (t_int[1] - t_int[0]).seconds\n",
    "    #print ('Task ran in ' + str(total_seconds) + ', which is ' + str(total_seconds/3600) + ' hours')\n",
    "    print(vm + '\\t' + '\\t' + str(total_seconds/3600))\n",
    "    total_hrs += total_seconds/3600\n",
    "print (\"All spot\\t\" + str(total_hrs * spot_rate) + \"\\t\" + str(total_hrs))\n",
    "print (\"All direct\\t\" + str(total_hrs * direct_rate))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get task input file IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"kfdrc-combined-CNV\"\n",
    "project= \"kfdrc-harmonization/sd-bhjxbdqk-08\"\n",
    "in_keys = [\"b_allele\", \"input_normal_aligned\", \"input_tumor_aligned\"]\n",
    "out = open(\"/Users/brownm28/Documents/playground/cbttc_task_check.txt\", \"w\")\n",
    "out.write(\"Task ID\\tTask name\\tTask status\\tb allele bs id\\tb allele pt id\\tnormal bs id\\tnormal pt id\\ttumor bs id\\ttumor pt id\\tpaired vcf N bs id\\tpaired vcf T bs id\\tpaired vcf pt id\\n\")\n",
    "for task in api.tasks.query(project=project).all():\n",
    "    if re.search(phrase, task.name) and (task.status == \"COMPLETED\" or task.status == \"FAILED\"):\n",
    "        info = []\n",
    "        try:\n",
    "            for key in in_keys:\n",
    "                info.append(task.inputs[key].metadata['Kids First Biospecimen ID'])\n",
    "                info.append(task.inputs[key].metadata['Kids First Participant ID'])\n",
    "            info.append(task.inputs['paired_vcf'].metadata['Kids First Biospecimen ID Normal'])\n",
    "            info.append(task.inputs['paired_vcf'].metadata['Kids First Biospecimen ID Tumor'])\n",
    "            info.append(task.inputs['paired_vcf'].metadata['Kids First Participant ID'])\n",
    "            out.write(task.id + \"\\t\" + task.name + \"\\t\" + task.status + \"\\t\" + \"\\t\".join(info) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            pdb.set_trace()\n",
    "            print(task.name + \"\\t\" + task.id + \"\\tstatus: \" + task.status + \" failed parsing. skipping!\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Task Job err log info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_info(task):\n",
    "    if re.search(phrase, task.name):\n",
    "        tname = task.name\n",
    "        tstatus = task.status\n",
    "        key = task.id + \"\\t\" + tname + \"\\t\" + tstatus\n",
    "        task_list.append(key)\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-p445achv-02'\n",
    "phrase = \"Vardict-Somatic\"\n",
    "pwd = \"/Users/brownm28/Documents/2019-Nov-4_job_err_log_audit/\"\n",
    "out_fn = 'boyd_vardict_task_info.txt'\n",
    "print (str(api.remaining) + \" remaining tasks\")\n",
    "out = open(pwd + out_fn, 'w')\n",
    "tasks = api.tasks.query(project=project).all()\n",
    "task_list = []\n",
    "valid = 1\n",
    "n = 50\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(get_task_info, task): task for task in tasks}\n",
    "    for task_info in concurrent.futures.as_completed(results):\n",
    "        if (valid % n) == 0:\n",
    "            sys.stderr.write(\"Processed \" + str(valid) + \" valid tasks\\n\")\n",
    "            print (api.remaining)\n",
    "        if task_info.result() == 0:\n",
    "            valid += 1\n",
    "# for task in tasks:\n",
    "#     parse_job_info(task)\n",
    "\n",
    "out.write(\"Task ID\\tTask Name\\tTask Status\\n\")\n",
    "for info in task_list:\n",
    "    out.write(info + \"\\n\")\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bulk_info(task):\n",
    "    cur_task = task.resource\n",
    "    tid = cur_task.id\n",
    "    job_dict[tid] = []\n",
    "    jphrase = 'vardict_\\d+_s'\n",
    "    for job in cur_task.get_execution_details().jobs:\n",
    "        if re.search(jphrase, job.name):\n",
    "            # pdb.set_trace()\n",
    "            job_dict[tid].append([job.name, job.status, job.logs['job.err.log'].id, str(job.logs['job.err.log'].size)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = \"/Users/brownm28/Documents/2019-Nov-4_job_err_log_audit/\"\n",
    "manifest_fn = 'boyd_vardict_task_info.txt'\n",
    "task_manifest = open(pwd + manifest_fn)\n",
    "head = next(task_manifest)\n",
    "task_ids = []\n",
    "for line in task_manifest:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    task_ids.append(info[0])\n",
    "task_manifest.close()\n",
    "task_bulk = []\n",
    "x = 1\n",
    "max_j = 50\n",
    "total = len(task_ids)\n",
    "for i in range(0, total, max_j):\n",
    "    uset = i + max_j\n",
    "    if uset > total:\n",
    "        uset = total\n",
    "    task_bulk.extend(api.tasks.bulk_get(tasks=task_ids[i:uset]))\n",
    "project = 'kfdrc-harmonization/sd-p445achv-02'\n",
    "phrase = \"Vardict-Somatic\"\n",
    "\n",
    "out_fn = 'boyd_vardict_job_info.txt'\n",
    "out = open(pwd + out_fn, 'w')\n",
    "out.write(\"Task ID\\tJob Name\\tJob Status\\tError log ID\\tError log size\\n\")\n",
    "set_n = 1\n",
    "for i in range(0, total, max_j):\n",
    "    uset = i + max_j\n",
    "    if uset > total:\n",
    "        uset = total\n",
    "    job_dict = {}\n",
    "    sys.stderr.write(\"Processing set \" + str(set_n) + \", api calls remaining: \" + str(api.remaining) + \"\\n\")\n",
    "#     for task in task_bulk[i:uset]:\n",
    "#         parse_bulk_info(task)\n",
    "    with concurrent.futures.ThreadPoolExecutor(8) as executor:\n",
    "        results = {executor.submit(parse_bulk_info, task): task for task in task_bulk[i:uset]}\n",
    "    try:\n",
    "        for tid in job_dict:\n",
    "            for job in job_dict[tid]:\n",
    "                out.write(tid + \"\\t\" + \"\\t\".join(job) + \"\\n\")\n",
    "        out.flush()\n",
    "        sys.stderr.write(\"Finished with set \" + str(set_n) + \", api calls remaining: \" + str(api.remaining) + '\\n')\n",
    "        set_n += 1\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\n\")\n",
    "        pdb.set_trace()\n",
    "        hold = 1\n",
    "\n",
    "out.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = ['72e5103a-4491-4073-a615-cd830ec63690', 'fe5aeb6d-a72d-4319-b8de-12083684376e']\n",
    "task_bulk = api.tasks.bulk_get(tasks=task_list)\n",
    "pdb.set_trace()\n",
    "pause = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get wf used in task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = \"/Users/brownm28/Documents/2019-Nov-4_job_err_log_audit/to_check/\"\n",
    "manifest_fn = 'pbta.txt'\n",
    "task_manifest = open(pwd + manifest_fn)\n",
    "out_fn = 'pbta_vardict_app.txt'\n",
    "out = open(pwd + out_fn, 'w')\n",
    "head = next(task_manifest)\n",
    "for line in task_manifest:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    task = api.tasks.get(info[0])\n",
    "    out.write(task.id + \"\\t\" + task.app + \"\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix swapped inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fix_swap(task):\n",
    "    try:\n",
    "        if re.search('LANCET_TCGA', task.name):\n",
    "            if not re.search('-10A-', task.inputs['input_normal_aligned'].name):\n",
    "                sys.stderr.write('Inputs swapped, re-tasking ' + task.name + '\\n')\n",
    "                task_name = 'LANCET: ' + task.inputs['input_tumor_name'] + \" \" + task.inputs['input_normal_name']\n",
    "                in_dict = {}\n",
    "                for key in task.inputs:\n",
    "                    in_dict[key] = task.inputs[key]\n",
    "                in_dict['input_tumor_aligned'] = task.inputs['input_normal_aligned']\n",
    "                in_dict['input_normal_aligned'] = task.inputs['input_tumor_aligned']\n",
    "                task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "                task.inputs['output_basename'] = task.id\n",
    "                task.save()\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nProcessing \" + task.name + \" failed\\n\")\n",
    "        #pdb.set_trace()\n",
    "        hold = 1\n",
    "        sys.exit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'cavatica/openpbta-tcga'\n",
    "app_name = project + \"/kfdrc-lancet-wf-baminput\"\n",
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "i = 1\n",
    "n = 50\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(8) as executor:\n",
    "    results = {executor.submit(check_fix_swap, task): task for task in tasks}\n",
    "    for result in concurrent.futures.as_completed(results):\n",
    "        if i % n == 0:\n",
    "            sys.stderr.write(str(i) + ' tasks set up\\n')\n",
    "        i += 1\n",
    "# for task in tasks:\n",
    "#     check_fix_swap(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-draft failed task in another project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_task = '416aea5b-0722-45db-9b40-8a58ed685769'\n",
    "old_task_info = api.tasks.get(old_task)\n",
    "project = 'zhangb1/kf-somatic-tools-test'\n",
    "app_name = project + \"/kfdrc-combined-somatic-wgs-cnv-wf\"\n",
    "\n",
    "in_dict = {}\n",
    "for key in old_task_info.inputs:\n",
    "    in_dict[key] = old_task_info.inputs[key]\n",
    "    try:\n",
    "        in_dict[key].copy(project=project)\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\n\")\n",
    "in_dict['output_basename'] = 'theta2_fail_catch_test'\n",
    "task_name = \"Theta2 Fail Catch Test\"\n",
    "task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "task.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = 'fa9f548e-5dfb-4562-a940-8c81cb5a428b'\n",
    "task_info = api.tasks.get(task_id)\n",
    "pdb.set_trace()\n",
    "hold=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stupid folder del because sbg won't help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project= 'd3b-bixu/kf-amplicon-architect-dev'\n",
    "files = api.files.query(project=project).all()\n",
    "dir_list = []\n",
    "for file in files:\n",
    "    if file.is_folder() and re.search('_hg38_ref_cache', file.name):\n",
    "        dir_list.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_folder_contents(dir_obj):\n",
    "    for item in dir_obj.list_files().all():\n",
    "        if item.is_folder():\n",
    "            dir_lvl.append(item)\n",
    "            delete_folder_contents(item)\n",
    "        else:\n",
    "            item.delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting _11_hg38_ref_cache\n",
      "Deleting _12_hg38_ref_cache\n",
      "Deleting _15_hg38_ref_cache\n",
      "Deleting _17_hg38_ref_cache\n",
      "Deleting _18_hg38_ref_cache\n",
      "Deleting _19_hg38_ref_cache\n",
      "Deleting _1_hg38_ref_cache\n",
      "Deleting _21_hg38_ref_cache\n",
      "Deleting _22_hg38_ref_cache\n",
      "Deleting _23_hg38_ref_cache\n",
      "Deleting _24_hg38_ref_cache\n",
      "Deleting _25_hg38_ref_cache\n",
      "Deleting _26_hg38_ref_cache\n",
      "Deleting _27_hg38_ref_cache\n",
      "Deleting _28_hg38_ref_cache\n",
      "Deleting _29_hg38_ref_cache\n",
      "Deleting _2_hg38_ref_cache\n",
      "Deleting _30_hg38_ref_cache\n",
      "Deleting _31_hg38_ref_cache\n",
      "Deleting _32_hg38_ref_cache\n",
      "Deleting _33_hg38_ref_cache\n",
      "Deleting _34_hg38_ref_cache\n",
      "Deleting _35_hg38_ref_cache\n",
      "Deleting _36_hg38_ref_cache\n",
      "Deleting _37_hg38_ref_cache\n",
      "Deleting _38_hg38_ref_cache\n",
      "Deleting _39_hg38_ref_cache\n",
      "Deleting _3_hg38_ref_cache\n",
      "Deleting _40_hg38_ref_cache\n",
      "Deleting _41_hg38_ref_cache\n",
      "Deleting _42_hg38_ref_cache\n",
      "Deleting _43_hg38_ref_cache\n",
      "Deleting _44_hg38_ref_cache\n",
      "Deleting _45_hg38_ref_cache\n",
      "Deleting _46_hg38_ref_cache\n",
      "Deleting _47_hg38_ref_cache\n",
      "Deleting _48_hg38_ref_cache\n",
      "Deleting _49_hg38_ref_cache\n",
      "Deleting _4_hg38_ref_cache\n",
      "Deleting _50_hg38_ref_cache\n",
      "Deleting _51_hg38_ref_cache\n",
      "Deleting _52_hg38_ref_cache\n",
      "Deleting _53_hg38_ref_cache\n",
      "Deleting _54_hg38_ref_cache\n",
      "Deleting _55_hg38_ref_cache\n",
      "Deleting _56_hg38_ref_cache\n",
      "Deleting _57_hg38_ref_cache\n",
      "Deleting _5_hg38_ref_cache\n",
      "Deleting _6_hg38_ref_cache\n",
      "Deleting _7_hg38_ref_cache\n",
      "Deleting _8_hg38_ref_cache\n",
      "Deleting _9_hg38_ref_cache\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dir_list)):\n",
    "    print(\"Deleting \" + dir_list[i].name)\n",
    "    dir_lvl = []\n",
    "    delete_folder_contents(dir_list[i])\n",
    "    for item in dir_lvl[::-1]:\n",
    "        item.delete()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get job mem usage\n",
    "Niche use case to parse log output file and collate usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_task(task):\n",
    "    # edit this to get what job name you want info on\n",
    "    phrase = \".*model_segments.*\"\n",
    "\n",
    "    for job in task.get_execution_details().jobs:\n",
    "        if job.status == \"COMPLETED\" and re.search(phrase, job.name):\n",
    "            if job.name not in mem_dict:\n",
    "                mem_dict[job.name] = []\n",
    "            log_data = job.logs['stderr'].content()\n",
    "            mem_info = re.findall(\"Runtime.totalMemory\\(\\)=(\\d+)\", log_data)\n",
    "            # convert to GB\n",
    "            mem_in_gb = round(int(mem_info[0])/(1024*1024*1024))\n",
    "            mem_dict[job.name].append(mem_in_gb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"kfdrc-harmonization/sd-bhjxbdqk-x01-somatic-mutations-wgs-tumor\"\n",
    "t_phrase = \"Kids First DRC Somatic Variant Workflow\"\n",
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "mem_dict = {}\n",
    "for task in tasks:\n",
    "    if re.search(t_phrase, task.name):\n",
    "        parse_task(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = open(\"/Users/brownm28/Documents/playground/gatk_cnv_model_mem_usage.txt\", \"w\")\n",
    "results.write(\"job_name\\tmem_usage_GB\\n\")\n",
    "for job in mem_dict:\n",
    "    for size in mem_dict[job]:\n",
    "        results.write(job + \"\\t\" + str(size) + \"\\n\")\n",
    "results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
