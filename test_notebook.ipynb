{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sevenbridges as sbg\n",
    "import re\n",
    "import sys\n",
    "import requests\n",
    "import pdb\n",
    "import concurrent.futures\n",
    "from sevenbridges.http.error_handlers import rate_limit_sleeper, maintenance_sleeper\n",
    "config = sbg.Config(profile='turbo')\n",
    "api = sbg.Api(config=config, error_handlers=[rate_limit_sleeper, maintenance_sleeper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get project task input file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uname = 'kfdrc-harmonization/sd-ygva0e1c-01'\n",
    "pname = 'schiffman_fy15'\n",
    "outdir = '/Users/brownm28/Documents/2019-Jan-23_fq_split_troubleshoot/project_inputs/'\n",
    "tasks = api.tasks.query(project=uname)\n",
    "\n",
    "out = open(outdir + pname + '_task_inputs.txt', 'w')\n",
    "out.write('Task_ID\\tgVCF 1\\tgVCF 2\\tgVCF 3\\n')\n",
    "for task in tasks:\n",
    "    if task.status = 'COMPLETE' and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inititialize API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = sbg.Config(profile='cavatica')\n",
    "api = sbg.Api(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get bs id info"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bs_file = '/Users/brownm28/Documents/2018-Sep-10_proteomics_update/add_aliquot_ids/bs_ids.txt'\n",
    "\n",
    "# print (bs_list[0])\n",
    "attr_list = ['external_aliquot_id']\n",
    "kf_bs_url = 'https://kf-api-dataservice.kidsfirstdrc.org/biospecimens/'\n",
    "\n",
    "for bs_id in open(bs_file):\n",
    "    bs_id = bs_id.rstrip('\\n')\n",
    "    # sys.stderr.write(bs_id)\n",
    "    cur = kf_bs_url + bs_id\n",
    "    # sys.stderr.write(cur)\n",
    "    bs_obj = requests.request('GET', cur)\n",
    "    \n",
    "    for attr in attr_list:\n",
    "        try:\n",
    "            print(attr + '\\t' + bs_id + '\\t'+ bs_obj.json()['results'][attr])\n",
    "        except:\n",
    "            print(bs_obj.json()['_status'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get study info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://localhost:1080'\n",
    "study_url = url + '/studies'\n",
    "study_info = requests.request('GET', study_url)\n",
    "# dir(study_info)\n",
    "print(study_info.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://localhost:1080'\n",
    "phen_url = url + '/phenotypes'\n",
    "phen_info = requests.request('GET', phen_url)\n",
    "# dir(phen_info)\n",
    "print(phen_info.json())\n",
    "test = phen_info.next\n",
    "dir(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search participants in study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "url = 'http://localhost:1080'\n",
    "field = 'external_id'\n",
    "search = '7316-1110'\n",
    "study = 'SD_BHJXBDQK'\n",
    "part_url = url + '/participants?study_id=' + study\n",
    "part_info = requests.request('GET', part_url)\n",
    "# edit what field you want to try\n",
    "\n",
    "next_link = url + part_info.json()['_links']['next']\n",
    "# print (json.dumps(part_info.json()['results'][0][field], indent=4, sort_keys=True))\n",
    "f = 0\n",
    "x = 1\n",
    "while f == 0:\n",
    "    for res in part_info.json()['results']:\n",
    "        if re.match(pattern=search, string=res['external_id']):\n",
    "            print (res['kf_id'])\n",
    "            f = 1\n",
    "    print ('not in set ' + str(x) + ' getting next 10\\n')\n",
    "    x += 1\n",
    "    part_info = requests.request('GET', next_link)\n",
    "    try:\n",
    "        next_link = url + part_info.json()['_links']['next']\n",
    "    except:\n",
    "        print ('all done.  you probably didn\\'t find it\\n')\n",
    "        f = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search biospecimen external id in a certain study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "url = 'http://localhost:1080'\n",
    "field = 'external_sample_id'\n",
    "search = '7316-1110'\n",
    "study = 'SD_BHJXBDQK'\n",
    "part_url = url + '/participants?study_id=' + study\n",
    "# part_url = url + '/participants'\n",
    "part_info = requests.request('GET', part_url)\n",
    "# edit what field you want to try\n",
    "\n",
    "next_link = url + part_info.json()['_links']['next']\n",
    "# print (json.dumps(part_info.json()['results'][0][field], indent=4, sort_keys=True))\n",
    "# http://localhost:1080/biospecimens?participant_id=PT_7MQFGW6D\n",
    "f = 0\n",
    "x = 1\n",
    "while f == 0:\n",
    "    for res in part_info.json()['results']:\n",
    "        biospec_url = url + res['_links']['biospecimens']\n",
    "        # print biospec_url\n",
    "        check_bio = requests.request('GET', biospec_url)\n",
    "        for bio_res in check_bio.json()['results']:\n",
    "            if re.match(pattern=search, string=bio_res[field]):\n",
    "                print (bio_res['kf_id'])\n",
    "                f = 1\n",
    "    print ('not in set ' + str(x) + ' getting next 10\\n')\n",
    "    x += 1\n",
    "    part_info = requests.request('GET', next_link)\n",
    "    try:\n",
    "        next_link = url + part_info.json()['_links']['next']\n",
    "    except:\n",
    "        print ('all done.  you probably didn\\'t find what you were looking for\\n')\n",
    "        f = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get input vcf file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'brownm28/kf-genotype-refinement-workflow'\n",
    "tag_search = 'Trio Joint Genotyping'\n",
    "files = api.files.query(project=project)\n",
    "sys.stderr.write('Getting files for ' + project + '\\n')\n",
    "#dir(files)\n",
    "vcf_list = []\n",
    "for file_obj in files:\n",
    "    for tag in file_obj.tags:\n",
    "        if tag == tag_search:\n",
    "            vcf_list.append(file_obj)\n",
    "            sys.stderr.write('Found relevant file ' + file_obj.name + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for files in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-9pyzahhe-01'\n",
    "files = api.files.query(project=project)\n",
    "flist = {'BS_WAY3FE6T.cram': 0,\n",
    "'BS_EWYT24R8.cram': 0,\n",
    "'BS_SB172XRA.cram': 0,\n",
    "'BS_33EDFD7C.cram': 0,\n",
    "'BS_EKCXX5H6.cram': 0,\n",
    "'BS_BSXP5B6Q.cram': 0,\n",
    "'BS_ZTBX0WB6.cram': 0,\n",
    "'BS_V5952JDS.cram': 0,\n",
    "'BS_02CC3HBK.cram': 0,\n",
    "'BS_PEBS6CTY.cram': 0,\n",
    "'BS_VKKFYXTX.cram': 0,\n",
    "'BS_B3ZZB1V4.cram': 0,\n",
    "'BS_2684E5FS.cram': 0,\n",
    "'BS_P9YNFP0C.cram': 0,\n",
    "'BS_TJ8N7NFH.cram': 0,\n",
    "'BS_ZMHQ4KK6.cram': 0,\n",
    "'BS_YHJFG3JV.cram': 0,\n",
    "'BS_NAFEB2M7.cram': 0,\n",
    "'BS_8AG5E38C.cram': 0,\n",
    "'BS_Z40X3HA0.cram': 0,\n",
    "'BS_KFH8Q61Z.cram': 0,\n",
    "'BS_2PWHWB6B.cram': 0,\n",
    "'BS_R66JVDBS.cram': 0,\n",
    "'BS_HKQYYQZX.cram': 0,\n",
    "'BS_NJP1E2G1.cram': 0,\n",
    "'BS_EWBA2VEK.cram': 0,\n",
    "'BS_YZKT40NN.cram': 0,\n",
    "'BS_E3NB86WM.cram': 0}\n",
    "for file_obj in files.all():\n",
    "    if file_obj.name in flist:\n",
    "        flist[file_obj.name] = 1\n",
    "        print (file_obj.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print files[0].name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (files[8].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import sevenbridges as sbg\n",
    "import sys\n",
    "#from requests import request\n",
    "\n",
    "#token = sys.argv[2]\n",
    "config = sbg.Config(profile='cavatica')\n",
    "api = sbg.Api(config=config)\n",
    "# api = sbg.Api(url='https://cavatica-api.sbgenomics.com/v2', token=token)\n",
    "\n",
    "task_list = '/Users/brownm28/Documents/2018-Aug-15_cbttc_launch/task_build/final_run/task_details/test.txt'\n",
    "task_dict = {}\n",
    "for line in open(task_list):\n",
    "    task_dict[line.rstrip('\\n')] = 0\n",
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-07'\n",
    "proj_tasks = api.tasks.query(project=project)\n",
    "#proj_tasks = api.tasks.get(id='91974cd2-43a2-4510-9513-f317f3aa6c34')\n",
    "#print(dir(proj_tasks.get_execution_details()))\n",
    "#proj_tasks.get_execution_details().jobs\n",
    "for task in proj_tasks:\n",
    "    if task.id in task_dict:\n",
    "        # print(dir(task.get_execution_details()))\n",
    "        print ('\\t'.join((task.name, task.id, str(task.price.amount))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get diagnosis by biospecimen id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diag(url, bs_id, out):\n",
    "    bs_url = url + '/biospecimens/' + bs_id\n",
    "    try:\n",
    "        bs_info = requests.request('GET', bs_url)\n",
    "        pt_link = bs_info.json()['_links']['participant']\n",
    "        pt = pt_link.split('/')\n",
    "\n",
    "        diag_link = url + '/diagnoses?participant_id=' + pt[2]\n",
    "        diag_info = requests.request('GET', diag_link)\n",
    "        i = 0\n",
    "        n = 10\n",
    "        kf_id_list = []\n",
    "        source_text = []\n",
    "        source_loc = []\n",
    "        for diag in diag_info.json()['results']:\n",
    "            kf_id_list.append(diag['kf_id'])\n",
    "            source_text.append(diag['source_text_diagnosis'])\n",
    "            source_loc.append(diag['source_text_tumor_location'])\n",
    "            i += 1\n",
    "        if i > n:\n",
    "            sys.stderr.write('WARNING: ' + bs_id + ' had more than ' + str(10) + ' diagnoses, results truncated')\n",
    "        out.write(bs_id + '\\t' + ','.join(kf_id_list) + '\\t' + ','.join(source_text) + '\\t' + ','.join(source_loc) + '\\t' + str(i) + '\\n')\n",
    "    except:\n",
    "        out.write(bs_id + '\\tNA\\tNA\\tNA\\tNA\\n')\n",
    "        sys.stderr.write('WARNING: ' + bs_id + ' has no dx info!\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_file = '/Users/brownm28/Documents/2018-Aug-15_cbttc_launch/dx_list/test.txt'\n",
    "out = open('/Users/brownm28/Documents/2018-Aug-15_cbttc_launch/dx_list/dx_table.txt', 'w')\n",
    "out.write('BS_ID\\tdx kf_ids\\tdx text\\tdx source\\tnum dx\\n')\n",
    "x = 1\n",
    "m = 10\n",
    "for bs_id in open(id_file):\n",
    "    bs_id = bs_id.rstrip('\\n')\n",
    "    # sys.stderr.write('Processing bs_id ' + bs_id + '\\n')\n",
    "    if x % m == 0:\n",
    "        sys.stderr.write('Processing the ' + str(x) + 'th bs_id ' + bs_id + '\\n')\n",
    "    x += 1\n",
    "    url = 'https://kf-api-dataservice.kidsfirstdrc.org'\n",
    "    get_diag(url, bs_id, out)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://kf-api-dataservice.kidsfirstdrc.org/biospecimens/BS_K049HVGR'\n",
    "test = requests.request('GET', url)\n",
    "null_item = test.json()['results']['shipment_date']\n",
    "if null_item is None:\n",
    "print (null_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search task by project, filter by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-02'\n",
    "\n",
    "tasks = api.tasks.query(project=project, order_by='created_time').all()\n",
    "in_keys = ['input_reads']\n",
    "out_fn = '/Users/brownm28/Documents/2018-Sep-10_proteomics_update/other_nantomics_file_update/dna_tasks.txt'\n",
    "date_int = 20180904\n",
    "out = open(out_fn, 'w')\n",
    "out.write('\\t'.join(['Task name', 'Date created', 'Created by', 'ID']) + '\\t' + '\\t'.join(in_keys) + '\\n')\n",
    "for task_obj in tasks:\n",
    "    day = str(task_obj.created_time.day)\n",
    "    if int(day) < 10:\n",
    "        day = '0' + day\n",
    "    month = str(task_obj.created_time.month)\n",
    "    if int(month) < 10:\n",
    "        month = '0' + month\n",
    "    create_date = str(task_obj.created_time.year) + month + day\n",
    "    create_date_int = int(create_date)\n",
    "    \n",
    "    if date_int <= create_date_int and task_obj.status == 'COMPLETED':\n",
    "        sys.stderr.write(str(date_int) + '\\t' + str(create_date_int) + '\\n')\n",
    "        out.write('\\t'.join((task_obj.name, create_date, task_obj.created_by, task_obj.id)))\n",
    "        in_fn = {}\n",
    "        for in_key in in_keys:\n",
    "            if in_key not in in_fn:\n",
    "                in_fn[in_key] = []\n",
    "            # assume file array input first, then try as a single file object\n",
    "            try:\n",
    "                for f_obj in task_obj.inputs[in_key]:\n",
    "                    in_fn[in_key].append(f_obj.name)\n",
    "            except:\n",
    "                try:\n",
    "                    in_fn[in_key].append(task_obj.inputs[in_key].name)\n",
    "                except:\n",
    "                    for i in range(0, len(in_keys), 1):\n",
    "                        out.write('\\t')\n",
    "                    out.write('\\n')\n",
    "                    sys.stderr.write('Missing input files for ' + task_obj.name + '\\t' + task_obj.id + '\\n')\n",
    "        for in_key in in_keys:\n",
    "            out.write('\\t' + ','.join(in_fn[in_key]))\n",
    "        out.write('\\n')\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-m3dbxd12'\n",
    "tasks = api.tasks.query(project=project).all()\n",
    "atype = 'DNA'\n",
    "cna_flag = 0\n",
    "for task in tasks:\n",
    "    #print (task.name)\n",
    "    #print (task.status)\n",
    "    task_name = task.name.rstrip('\\n')\n",
    "    task_id = task.id\n",
    "    if atype == 'DNA' and 'vep_annotated_maf' in task.outputs and task.status == 'COMPLETED':\n",
    "        pdb.set_trace()\n",
    "        parts = task_name.split('-')\n",
    "        parts2 = parts[3].split('_')\n",
    "        tum_bs_id = 'BS_' + parts2[1]\n",
    "        norm_bs_id = 'BS_' + parts2[3]\n",
    "        outs = task.outputs['vep_annotated_maf'].name\n",
    "        if cna_flag == 1:\n",
    "            outs += ',' + task.outputs['cnv_result'].name\n",
    "        \n",
    "        print ('\\t'.join((tum_bs_id, norm_bs_id, task_name, task_id, atype, outs, project)) + '\\n')\n",
    "# print (dir(task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check refinement draft task inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-6fpyjqbr-02'\n",
    "tasks = api.tasks.query(project=project, status='DRAFT').all()\n",
    "out_fh = open('/Users/brownm28/Documents/2018-Oct-9_genotype_refinement_bonanza/VILAIN/rpt/r2_3_fm_task_check.txt', 'w')\n",
    "out_fh.write('task id\\ttask fm id\\tped file fm id\\tvcf task fm\\tmatch\\trun status\\n')\n",
    "for task in tasks:\n",
    "    parts = task.name.split('-')\n",
    "    if parts[0] == 'kf_genotype_refinement_vep':\n",
    "        task_fm = parts[1]\n",
    "        in_ped = task.inputs['ped'].name\n",
    "        ped_parts = in_ped.split('.')\n",
    "        match = 'Y'\n",
    "        orig_vcf_task = api.tasks.get(id= task.inputs['vqsr_vcf'].origin.task)\n",
    "        orig_parts = orig_vcf_task.name.split('-')\n",
    "        if task_fm != ped_parts[0] or task_fm != orig_parts[1]:\n",
    "            match = 'N'\n",
    "        out_fh.write(task.id + '\\t' + task_fm + '\\t' + ped_parts[0] + '\\t' + orig_parts[1] + '\\t' + match + '\\t' + task.status + '\\n')\n",
    "out_fh.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abort stuck tasks based on a completion of a run step and time it has been executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-6fpyjqbr-02'\n",
    "tasks = api.tasks.query(project=project, status='RUNNING').all()\n",
    "ct = 0\n",
    "abort = 0\n",
    "for task in tasks:\n",
    "    run_in_minutes = task.execution_status.duration/60000\n",
    "    print(task.name + '\\t' + task.id + '\\t' + str(task.execution_status.steps_completed) + '\\t' + str(run_in_minutes))\n",
    "    #pdb.set_trace()\n",
    "    \n",
    "    limit = 15\n",
    "    if task.execution_status.steps_completed == 0 and run_in_minutes > limit:\n",
    "        ct += 1\n",
    "        if abort:\n",
    "            sys.stderr.write(task.name + ' stuck at step 0 after ' + str(run_in_minutes) + ', aborting task\\n')\n",
    "            task.abort()\n",
    "        else:\n",
    "            sys.stderr.write('WARN: ' + task.name + ' stuck at step 0 after ' + str(run_in_minutes) + '\\n')\n",
    "sys.stderr.write(str(ct) + ' stuck tasks\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-08'\n",
    "task_id = '7bee3c27-ad17-4d13-baf0-ff57c53a20bf'\n",
    "check = api.tasks.get(task_id)\n",
    "pdb.set_trace()\n",
    "hold=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get T/N bams from tasks\n",
    "prefix = \"PNOC_WES_MUTECT2_SOMATIC\"\n",
    "project = \"kfdrc-harmonization/sd-m3dbxd12\"\n",
    "# the .all() is important, otherwise, it just gets the first 50\n",
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "out_fh = open(\"T-N_bam_pairs.txt\", 'w')\n",
    "out_fh.write(\"Tumor bam ID\\tT bam name\\tNormal bam id\\tN bam name\\n\")\n",
    "for task in tasks:\n",
    "    if re.search(prefix, task.name):\n",
    "        out_fh.write(task.inputs['input_tumor_aligned'].id + \"\\t\" + task.inputs['input_tumor_aligned'].name + \"\\t\" + task.inputs['input_normal_aligned'].id + \"\\t\" + task.inputs['input_normal_aligned'].name + \"\\n\")\n",
    "out_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"cavatica/sd-bhjxbdqk\"\n",
    "test = api.datasets.get(project)\n",
    "files = api.files.query(dataset=test)\n",
    "flist = files[0].list_files()\n",
    "sub_list = list(flist[1].list_files().all())\n",
    "\n",
    "#check = api.files.get('5c9015ede4b0359d0b01c7a2')\n",
    "pdb.set_trace()\n",
    "hold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_bs_url = 'https://kf-api-dataservice.kidsfirstdrc.org/biospecimens/'\n",
    "bs_url = kf_bs_url + 'BS_SSEAT56Z'\n",
    "test = requests.request('GET', bs_url)\n",
    "if test.json()['results']['visible']:\n",
    "    sys.stderr.write('OK\\n')\n",
    "else:\n",
    "    sys.stderr.write('Hide\\n')\n",
    "pdb.set_trace()\n",
    "hold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = []\n",
    "info.append(\"BS_GRS3T427\")\n",
    "project = \"kfdrc-harmonization/sd-bhjxbdqk-12\"\n",
    "tumor_files = api.files.query(project=project, metadata={'Kids First Biospecimen ID': info[0]}).all()\n",
    "for f in tumor_files:\n",
    "    if  not re.search('crai', f.name):\n",
    "        print (f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get KF fam from Maris sample IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_fam_url=\"https://kf-api-dataservice.kidsfirstdrc.org/families?external_id=\"\n",
    "slist = open(\"/Users/brownm28/Documents/playground/maris_peddy_compare/sample_list.txt\")\n",
    "for samp in slist:\n",
    "    ext_id = samp[0:14]\n",
    "    fm_url = kf_fam_url + ext_id\n",
    "    data = requests.request('GET', fm_url)\n",
    "    #pdb.set_trace()\n",
    "    print (ext_id + \"\\t\" + data.json()['results'][0]['kf_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = open('/Users/brownm28/Documents/playground/data-1614217302189.csv')\n",
    "skip = next(in_file)\n",
    "bs_list = []\n",
    "dna_project = \"kfdrc-harmonization/sd-bhjxbdqk-08\"\n",
    "rna_project = \"kfdrc-harmonization/sd-bhjxbdqk-06\"\n",
    "pnoc_cbio = \"zhangb1/pnoc008-cbio-data\"\n",
    "field = \"Kids First Biospecimen ID\"\n",
    "project=pnoc_cbio\n",
    "out = open(\"/Users/brownm28/Documents/playground/pnoc_tumor_related_files.tsv\", \"w\")\n",
    "i = 0\n",
    "for line in in_file:\n",
    "    data = line.rstrip('\\n').split(',')\n",
    "    bs_id = data[0].rstrip(\"\\\"\").lstrip(\"\\\"\")\n",
    "    try:\n",
    "        files = api.files.query(project=project, metadata={field: bs_id})\n",
    "        if len(files) > 0:\n",
    "            for obj in files:\n",
    "                out.write(\"\\t\".join([bs_id, obj.id, obj.name]) + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pdb.set_trace()\n",
    "        hold = 1\n",
    "    i += 1\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all files with name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mt_query_project(project):\n",
    "    try:\n",
    "        current = api.files.query(project=project, names=fname_list)\n",
    "        if len(current) > 0:\n",
    "            print (project.name)\n",
    "            file_list.append(current)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\n",
      "Boutros-OpenPBTA-mtDNA\n",
      "GH-PNOC003 Somatic Mutation WGS Cellline\n",
      "openPBTA-TCGA\n",
      "demo\n",
      "PNOC008 Harmonization\n",
      "PPTC-PDX-Genomics  project\n",
      "PBTA Internal Project\n",
      "Children's National Medical Center\n",
      "Processed 10 projects\n",
      "Processed 20 projects\n",
      "Processed 30 projects\n",
      "Processed 40 projects\n",
      "Processed 50 projects\n",
      "Processed 60 projects\n",
      "Processed 70 projects\n",
      "Processed 80 projects\n",
      "Processed 90 projects\n",
      "Processed 100 projects\n",
      "Processed 110 projects\n",
      "Processed 120 projects\n",
      "Processed 130 projects\n",
      "Processed 140 projects\n",
      "Processed 150 projects\n",
      "Processed 160 projects\n",
      "22q11 Deletion Syndrome Study\n"
     ]
    }
   ],
   "source": [
    "project_list = api.projects.query().all()\n",
    "fname_file = open('/Users/brownm28/Documents/2023-Jan-31_REF_EXPORT/platform_rm/search_and_destroy.tsv')\n",
    "head = next(fname_file)\n",
    "fname_list = []\n",
    "for data in fname_file:\n",
    "    fname = data.split('\\t')\n",
    "    fname_list.append(fname[1])\n",
    "file_list = []\n",
    "x = 1\n",
    "n = 10\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(mt_query_project, project): project for project in project_list}\n",
    "    for query in concurrent.futures.as_completed(results):\n",
    "        if x % n == 0:\n",
    "            print(\"Processed \" + str(x) + \" projects\")\n",
    "        x += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('/Users/brownm28/Documents/2023-Jan-31_REF_EXPORT/platform_rm/cavatica_to_check_for_deletion.tsv', 'w')\n",
    "out.write(\"Project\\tFile name\\tFile id\\tStorage Type\\tStorage Volume\\n\")\n",
    "for batch in file_list:\n",
    "    for file in batch:\n",
    "        # pdb.set_trace()\n",
    "        out.write(file.project + '\\t' + file.name + '\\t' + file.id + '\\t' + file.storage.type + '\\t' + str(file.storage.volume) + '\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove PLATFORM Files\n",
    "Uses a manifest and a blacklist to remove files stored on platform that I have already exported to a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting file delete process\n",
      "Processing 100 set\n",
      "825 calls left\n",
      "Files deleted!"
     ]
    }
   ],
   "source": [
    "blacklist_file = open('/Users/brownm28/Documents/2023-Jan-31_REF_EXPORT/platform_rm/notify_first.tsv')\n",
    "blacklist = []\n",
    "# get list of projects to avoid removing from for now\n",
    "for project in blacklist_file:\n",
    "    blacklist.append(project.rstrip('\\n'))\n",
    "rm_file = open('/Users/brownm28/Documents/2023-Jan-31_REF_EXPORT/platform_rm/cavatica_to_check_for_deletion.tsv')\n",
    "head = next(rm_file)\n",
    "header = head.rstrip('\\n').split('\\t')\n",
    "\n",
    "p_idx = header.index('Project')\n",
    "s_idx = header.index('Storage Type')\n",
    "i_idx = header.index('File id')\n",
    "\n",
    "bulk_in = []\n",
    "for entry in rm_file:\n",
    "    info = entry.rstrip('\\n').split('\\t')\n",
    "    if info[p_idx] not in blacklist and info[s_idx] == 'PLATFORM':\n",
    "        bulk_in.append(info[i_idx])\n",
    "sys.stderr.write('Starting file delete process\\n')\n",
    "max_j = 100\n",
    "total = len(bulk_in)\n",
    "\n",
    "for i in range(0, total, max_j):\n",
    "    uset = i + max_j\n",
    "    sys.stderr.write('Processing ' + str(uset) + ' set\\n')\n",
    "    if uset > total:\n",
    "        uset = total\n",
    "    # subset = api.files.bulk_get(files=bulk_in[i:uset])\n",
    "    rm_set = api.files.bulk_delete(files=bulk_in[i:uset])\n",
    "    sys.stderr.write(str(api.remaining) + ' calls left\\n')\n",
    "sys.stderr.write('Files deleted!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
