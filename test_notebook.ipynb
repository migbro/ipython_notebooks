{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sevenbridges as sbg\n",
    "import sys\n",
    "import requests\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inititialize API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = sbg.Config(profile='cavatica')\n",
    "api = sbg.Api(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get bs id info"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bs_file = '/Users/brownm28/Documents/2018-Sep-10_proteomics_update/add_aliquot_ids/bs_ids.txt'\n",
    "\n",
    "# print (bs_list[0])\n",
    "attr_list = ['external_aliquot_id']\n",
    "kf_bs_url = 'https://kf-api-dataservice.kidsfirstdrc.org/biospecimens/'\n",
    "\n",
    "for bs_id in open(bs_file):\n",
    "    bs_id = bs_id.rstrip('\\n')\n",
    "    # sys.stderr.write(bs_id)\n",
    "    cur = kf_bs_url + bs_id\n",
    "    # sys.stderr.write(cur)\n",
    "    bs_obj = requests.request('GET', cur)\n",
    "    \n",
    "    for attr in attr_list:\n",
    "        try:\n",
    "            print(attr + '\\t' + bs_id + '\\t'+ bs_obj.json()['results'][attr])\n",
    "        except:\n",
    "            print(bs_obj.json()['_status'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get study info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'limit': 10, u'_status': {u'message': u'success', u'code': 200}, u'total': 11, u'_links': {u'self': u'/studies', u'next': u'/studies?after=1529089066.003078'}, u'results': [{u'attribution': u'https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs001168.v1.p1', u'name': u'Genomic Studies of Orofacial Cleft Birth Defects', u'data_access_authority': u'dbGaP', u'release_status': u'Pending', u'created_at': u'2018-05-22T21:12:42.999818+00:00', u'modified_at': u'2018-05-22T21:12:42.999823+00:00', u'version': u'v1.p1', u'_links': {u'study_files': u'/study-files?study_id=SD_9PYZAHHE', u'participants': u'/participants?study_id=SD_9PYZAHHE', u'self': u'/studies/SD_9PYZAHHE', u'collection': u'/studies', u'investigator': u'/investigators/IG_JBKNYBM3'}, u'kf_id': u'SD_9PYZAHHE', u'external_id': u'phs001168', u'short_name': u'Orofacial Cleft: European Ancestry'}, {u'attribution': None, u'name': u'Genetic Basis of Neuroblastoma Initiation and Progression', u'data_access_authority': u'dbGaP', u'release_status': None, u'created_at': u'2018-06-11T13:26:50.673622+00:00', u'modified_at': u'2018-06-11T13:26:50.673629+00:00', u'version': None, u'_links': {u'study_files': u'/study-files?study_id=SD_DYPMEHHF', u'participants': u'/participants?study_id=SD_DYPMEHHF', u'self': u'/studies/SD_DYPMEHHF', u'collection': u'/studies', u'investigator': None}, u'kf_id': u'SD_DYPMEHHF', u'external_id': u'Maris', u'short_name': u'Neuroblastoma Initiation and Progression'}, {u'attribution': u'Reported Unknown', u'name': u'Kids First: Genomics of Orofacial Cleft Birth Defects in Latin American Families', u'data_access_authority': u'dbGaP', u'release_status': u'Pending', u'created_at': u'2018-06-11T13:28:52.845270+00:00', u'modified_at': u'2018-07-07T19:53:59.039103+00:00', u'version': u'v1.p1', u'_links': {u'study_files': u'/study-files?study_id=SD_R0EPRSGS', u'participants': u'/participants?study_id=SD_R0EPRSGS', u'self': u'/studies/SD_R0EPRSGS', u'collection': u'/studies', u'investigator': u'/investigators/IG_YG75HXKS'}, u'kf_id': u'SD_R0EPRSGS', u'external_id': u'phs001420', u'short_name': u'Orofacial Cleft: Latin American'}, {u'attribution': None, u'name': u'Genetic Basis of Disorders/Differences of Sex Development (DSD)', u'data_access_authority': u'dbGaP', u'release_status': None, u'created_at': u'2018-06-11T13:30:02.718002+00:00', u'modified_at': u'2018-06-11T13:30:02.718008+00:00', u'version': None, u'_links': {u'study_files': u'/study-files?study_id=SD_6FPYJQBR', u'participants': u'/participants?study_id=SD_6FPYJQBR', u'self': u'/studies/SD_6FPYJQBR', u'collection': u'/studies', u'investigator': None}, u'kf_id': u'SD_6FPYJQBR', u'external_id': u'Vilain', u'short_name': u'Disorders of Sex Development'}, {u'attribution': None, u'name': u'Genomics of Orthopaedic Disease Program', u'data_access_authority': u'dbGaP', u'release_status': None, u'created_at': u'2018-06-11T13:30:48.635964+00:00', u'modified_at': u'2018-06-11T13:30:48.635971+00:00', u'version': None, u'_links': {u'study_files': u'/study-files?study_id=SD_RM8AFW0R', u'participants': u'/participants?study_id=SD_RM8AFW0R', u'self': u'/studies/SD_RM8AFW0R', u'collection': u'/studies', u'investigator': None}, u'kf_id': u'SD_RM8AFW0R', u'external_id': u'Rios and Wise', u'short_name': u'Adolescent Idiopathic Scoliosis'}, {u'attribution': u'https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs001138.v1.p2', u'name': u'National Heart, Lung, and Blood Institute (NHLBI) Bench to Bassinet Program: The Gabriella Miller Kids First Pediatric Research Program of the Pediatric Cardiac Genetics Consortium (PCGC)', u'data_access_authority': u'dbGaP', u'release_status': u'Pending', u'created_at': u'2018-06-11T16:09:07.053162+00:00', u'modified_at': u'2018-06-12T14:42:23.705218+00:00', u'version': u'v1.p2', u'_links': {u'study_files': u'/study-files?study_id=SD_PREASA7S', u'participants': u'/participants?study_id=SD_PREASA7S', u'self': u'/studies/SD_PREASA7S', u'collection': u'/studies', u'investigator': u'/investigators/IG_8ZSMFJ19'}, u'kf_id': u'SD_PREASA7S', u'external_id': u'phs001138', u'short_name': u'Congenital Heart Defects'}, {u'attribution': None, u'name': u\"Pediatric Brain Tumor Atlas - Children's Brain Tumor Tissue Consortium\", u'data_access_authority': u'CBTTC DAC', u'release_status': u'Pending', u'created_at': u'2018-06-11T16:15:56.810343+00:00', u'modified_at': u'2018-06-11T16:15:56.810348+00:00', u'version': None, u'_links': {u'study_files': u'/study-files?study_id=SD_BHJXBDQK', u'participants': u'/participants?study_id=SD_BHJXBDQK', u'self': u'/studies/SD_BHJXBDQK', u'collection': u'/studies', u'investigator': None}, u'kf_id': u'SD_BHJXBDQK', u'external_id': u'SD_BHJXBDQK', u'short_name': u'Pediatric Brain Tumors: CBTTC'}, {u'attribution': None, u'name': u'Expanded Ewing sarcoma cohort for tumor genomics and association with DNA repair deficiences, clinical presentation, and outcome', u'data_access_authority': u'dbGaP', u'release_status': u'Pending', u'created_at': u'2018-06-12T15:03:33.997344+00:00', u'modified_at': u'2018-06-12T15:03:33.997350+00:00', u'version': u'v1.p2', u'_links': {u'study_files': u'/study-files?study_id=SD_YGVA0E1C', u'participants': u'/participants?study_id=SD_YGVA0E1C', u'self': u'/studies/SD_YGVA0E1C', u'collection': u'/studies', u'investigator': u'/investigators/IG_D43G5D6T'}, u'kf_id': u'SD_YGVA0E1C', u'external_id': u'phs001228', u'short_name': u'Ewing Sarcoma: Genetic Risk'}, {u'attribution': None, u'name': u'Genomic Analysis of Congenital Diaphragmatic Hernia and Associated Congenital Anomalies', u'data_access_authority': u'dbGaP', u'release_status': u'Pending', u'created_at': u'2018-06-12T20:24:59.243137+00:00', u'modified_at': u'2018-06-12T20:35:09.476399+00:00', u'version': u'v2.p1', u'_links': {u'study_files': u'/study-files?study_id=SD_46SK55A3', u'participants': u'/participants?study_id=SD_46SK55A3', u'self': u'/studies/SD_46SK55A3', u'collection': u'/studies', u'investigator': u'/investigators/IG_YNJ9S7G7'}, u'kf_id': u'SD_46SK55A3', u'external_id': u'phs001110', u'short_name': u'Congenital Diaphragmatic Hernia'}, {u'attribution': None, u'name': u'Cat Pics', u'data_access_authority': u'dbGaP', u'release_status': None, u'created_at': u'2018-06-15T18:57:46.003078+00:00', u'modified_at': u'2018-06-15T18:57:46.003086+00:00', u'version': None, u'_links': {u'study_files': u'/study-files?study_id=SD_ME0WME0W', u'participants': u'/participants?study_id=SD_ME0WME0W', u'self': u'/studies/SD_ME0WME0W', u'collection': u'/studies', u'investigator': None}, u'kf_id': u'SD_ME0WME0W', u'external_id': u'ICANHAZ', u'short_name': None}]}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://localhost:1080'\n",
    "study_url = url + '/studies'\n",
    "study_info = requests.request('GET', study_url)\n",
    "# dir(study_info)\n",
    "print(study_info.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'limit': 10, u'_status': {u'message': u'success', u'code': 200}, u'total': 121970, u'_links': {u'self': u'/phenotypes', u'next': u'/phenotypes?after=1528815077.633429'}, u'results': [{u'kf_id': u'PH_TGMY25KK', u'hpo_id_phenotype': u'HP:0011620', u'created_at': u'2018-06-12T14:51:16.521147+00:00', u'modified_at': u'2018-06-12T18:37:20.953305+00:00', u'observed': u'Negative', u'_links': {u'self': u'/phenotypes/PH_TGMY25KK', u'participant': u'/participants/PT_9A61PCYB', u'collection': u'/phenotypes'}, u'source_text_phenotype': u'Abnormal Abdominal Situs', u'external_id': None, u'age_at_event_days': 82, u'snomed_id_phenotype': u'No Match'}, {u'kf_id': u'PH_8AK0TSYF', u'hpo_id_phenotype': u'HP:0004307', u'created_at': u'2018-06-12T14:51:17.225789+00:00', u'modified_at': u'2018-06-12T18:37:21.364589+00:00', u'observed': u'Negative', u'_links': {u'self': u'/phenotypes/PH_8AK0TSYF', u'participant': u'/participants/PT_9A61PCYB', u'collection': u'/phenotypes'}, u'source_text_phenotype': u'Abnormal Cardiac Situs', u'external_id': None, u'age_at_event_days': 82, u'snomed_id_phenotype': u'No Match'}, {u'kf_id': u'PH_G94E3P93', u'hpo_id_phenotype': u'HP:0006707', u'created_at': u'2018-06-12T14:51:17.278399+00:00', u'modified_at': u'2018-06-12T14:51:17.278405+00:00', u'observed': u'Reported Unknown', u'_links': {u'self': u'/phenotypes/PH_G94E3P93', u'participant': u'/participants/PT_9A61PCYB', u'collection': u'/phenotypes'}, u'source_text_phenotype': u'Abnormal Hepatic Vein', u'external_id': None, u'age_at_event_days': 82, u'snomed_id_phenotype': u'SNOMEDCT:448281007'}, {u'kf_id': u'PH_XVMSFGDM', u'hpo_id_phenotype': u'HP:0005345', u'created_at': u'2018-06-12T14:51:17.287948+00:00', u'modified_at': u'2018-06-12T14:51:17.287955+00:00', u'observed': u'Positive', u'_links': {u'self': u'/phenotypes/PH_XVMSFGDM', u'participant': u'/participants/PT_9A61PCYB', u'collection': u'/phenotypes'}, u'source_text_phenotype': u'Abnormal Systemic Vein', u'external_id': None, u'age_at_event_days': 82, u'snomed_id_phenotype': u'SNOMEDCT:448157006'}, {u'kf_id': u'PH_DVFYNFMM', u'hpo_id_phenotype': u'HP:0030968', u'created_at': u'2018-06-12T14:51:17.415496+00:00', u'modified_at': u'2018-06-12T14:51:17.415503+00:00', u'observed': u'Reported Unknown', u'_links': {u'self': u'/phenotypes/PH_DVFYNFMM', u'participant': u'/participants/PT_9A61PCYB', u'collection': u'/phenotypes'}, u'source_text_phenotype': u'Abnormal Pulmonary Vein', u'external_id': None, u'age_at_event_days': 82, u'snomed_id_phenotype': u'SNOMEDCT:111322000'}, {u'kf_id': u'PH_YYWXCWPF', u'hpo_id_phenotype': u'HP:0025579', u'created_at': u'2018-06-12T14:51:17.567353+00:00', u'modified_at': u'2018-06-12T14:51:17.567360+00:00', u'observed': u'Negative', u'_links': {u'self': u'/phenotypes/PH_YYWXCWPF', u'participant': u'/participants/PT_9A61PCYB', u'collection': u'/phenotypes'}, u'source_text_phenotype': u'Abnormal Left Atrium', u'external_id': None, u'age_at_event_days': 82, u'snomed_id_phenotype': u'SNOMEDCT:447824005'}, {u'kf_id': u'PH_S4F2BS2W', u'hpo_id_phenotype': u'HP:0011994', u'created_at': u'2018-06-12T14:51:17.589837+00:00', u'modified_at': u'2018-06-12T14:51:17.589843+00:00', u'observed': u'Positive', u'_links': {u'self': u'/phenotypes/PH_S4F2BS2W', u'participant': u'/participants/PT_9A61PCYB', u'collection': u'/phenotypes'}, u'source_text_phenotype': u'Abnormal Atrial Septum', u'external_id': None, u'age_at_event_days': 82, u'snomed_id_phenotype': u'SNOMEDCT:253363004'}, {u'kf_id': u'PH_Q305RZCM', u'hpo_id_phenotype': u'HP:0001702', u'created_at': u'2018-06-12T14:51:17.591137+00:00', u'modified_at': u'2018-06-12T14:51:17.591143+00:00', u'observed': u'Positive', u'_links': {u'self': u'/phenotypes/PH_Q305RZCM', u'participant': u'/participants/PT_9A61PCYB', u'collection': u'/phenotypes'}, u'source_text_phenotype': u'Abnormal Tricuspid Valve', u'external_id': None, u'age_at_event_days': 82, u'snomed_id_phenotype': u'SNOMEDCT:4374004'}, {u'kf_id': u'PH_E9RPYDGD', u'hpo_id_phenotype': u'HP:0025580', u'created_at': u'2018-06-12T14:51:17.623121+00:00', u'modified_at': u'2018-06-12T14:51:17.623128+00:00', u'observed': u'Negative', u'_links': {u'self': u'/phenotypes/PH_E9RPYDGD', u'participant': u'/participants/PT_9A61PCYB', u'collection': u'/phenotypes'}, u'source_text_phenotype': u'Abnormal Right Atrium', u'external_id': None, u'age_at_event_days': 82, u'snomed_id_phenotype': u'SNOMEDCT:448064005'}, {u'kf_id': u'PH_MHMJC1EZ', u'hpo_id_phenotype': u'HP:0001707', u'created_at': u'2018-06-12T14:51:17.633429+00:00', u'modified_at': u'2018-06-12T14:51:17.633435+00:00', u'observed': u'Positive', u'_links': {u'self': u'/phenotypes/PH_MHMJC1EZ', u'participant': u'/participants/PT_9A61PCYB', u'collection': u'/phenotypes'}, u'source_text_phenotype': u'Abnormal Right Ventricle', u'external_id': None, u'age_at_event_days': 82, u'snomed_id_phenotype': u'SNOMEDCT:253516002'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://localhost:1080'\n",
    "phen_url = url + '/phenotypes'\n",
    "phen_info = requests.request('GET', phen_url)\n",
    "# dir(phen_info)\n",
    "print(phen_info.json())\n",
    "test = phen_info.next\n",
    "dir(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search participants in study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in set 1 getting next 10\n",
      "\n",
      "not in set 2 getting next 10\n",
      "\n",
      "not in set 3 getting next 10\n",
      "\n",
      "not in set 4 getting next 10\n",
      "\n",
      "not in set 5 getting next 10\n",
      "\n",
      "not in set 6 getting next 10\n",
      "\n",
      "not in set 7 getting next 10\n",
      "\n",
      "not in set 8 getting next 10\n",
      "\n",
      "not in set 9 getting next 10\n",
      "\n",
      "not in set 10 getting next 10\n",
      "\n",
      "not in set 11 getting next 10\n",
      "\n",
      "not in set 12 getting next 10\n",
      "\n",
      "not in set 13 getting next 10\n",
      "\n",
      "not in set 14 getting next 10\n",
      "\n",
      "not in set 15 getting next 10\n",
      "\n",
      "not in set 16 getting next 10\n",
      "\n",
      "not in set 17 getting next 10\n",
      "\n",
      "not in set 18 getting next 10\n",
      "\n",
      "not in set 19 getting next 10\n",
      "\n",
      "not in set 20 getting next 10\n",
      "\n",
      "not in set 21 getting next 10\n",
      "\n",
      "not in set 22 getting next 10\n",
      "\n",
      "not in set 23 getting next 10\n",
      "\n",
      "not in set 24 getting next 10\n",
      "\n",
      "not in set 25 getting next 10\n",
      "\n",
      "not in set 26 getting next 10\n",
      "\n",
      "not in set 27 getting next 10\n",
      "\n",
      "not in set 28 getting next 10\n",
      "\n",
      "not in set 29 getting next 10\n",
      "\n",
      "not in set 30 getting next 10\n",
      "\n",
      "not in set 31 getting next 10\n",
      "\n",
      "not in set 32 getting next 10\n",
      "\n",
      "not in set 33 getting next 10\n",
      "\n",
      "not in set 34 getting next 10\n",
      "\n",
      "not in set 35 getting next 10\n",
      "\n",
      "not in set 36 getting next 10\n",
      "\n",
      "not in set 37 getting next 10\n",
      "\n",
      "not in set 38 getting next 10\n",
      "\n",
      "not in set 39 getting next 10\n",
      "\n",
      "not in set 40 getting next 10\n",
      "\n",
      "not in set 41 getting next 10\n",
      "\n",
      "not in set 42 getting next 10\n",
      "\n",
      "not in set 43 getting next 10\n",
      "\n",
      "not in set 44 getting next 10\n",
      "\n",
      "not in set 45 getting next 10\n",
      "\n",
      "not in set 46 getting next 10\n",
      "\n",
      "not in set 47 getting next 10\n",
      "\n",
      "not in set 48 getting next 10\n",
      "\n",
      "not in set 49 getting next 10\n",
      "\n",
      "not in set 50 getting next 10\n",
      "\n",
      "not in set 51 getting next 10\n",
      "\n",
      "not in set 52 getting next 10\n",
      "\n",
      "not in set 53 getting next 10\n",
      "\n",
      "not in set 54 getting next 10\n",
      "\n",
      "not in set 55 getting next 10\n",
      "\n",
      "not in set 56 getting next 10\n",
      "\n",
      "not in set 57 getting next 10\n",
      "\n",
      "not in set 58 getting next 10\n",
      "\n",
      "not in set 59 getting next 10\n",
      "\n",
      "not in set 60 getting next 10\n",
      "\n",
      "not in set 61 getting next 10\n",
      "\n",
      "not in set 62 getting next 10\n",
      "\n",
      "not in set 63 getting next 10\n",
      "\n",
      "not in set 64 getting next 10\n",
      "\n",
      "not in set 65 getting next 10\n",
      "\n",
      "not in set 66 getting next 10\n",
      "\n",
      "not in set 67 getting next 10\n",
      "\n",
      "not in set 68 getting next 10\n",
      "\n",
      "not in set 69 getting next 10\n",
      "\n",
      "not in set 70 getting next 10\n",
      "\n",
      "not in set 71 getting next 10\n",
      "\n",
      "not in set 72 getting next 10\n",
      "\n",
      "not in set 73 getting next 10\n",
      "\n",
      "not in set 74 getting next 10\n",
      "\n",
      "not in set 75 getting next 10\n",
      "\n",
      "not in set 76 getting next 10\n",
      "\n",
      "not in set 77 getting next 10\n",
      "\n",
      "not in set 78 getting next 10\n",
      "\n",
      "not in set 79 getting next 10\n",
      "\n",
      "not in set 80 getting next 10\n",
      "\n",
      "not in set 81 getting next 10\n",
      "\n",
      "not in set 82 getting next 10\n",
      "\n",
      "not in set 83 getting next 10\n",
      "\n",
      "not in set 84 getting next 10\n",
      "\n",
      "not in set 85 getting next 10\n",
      "\n",
      "not in set 86 getting next 10\n",
      "\n",
      "not in set 87 getting next 10\n",
      "\n",
      "not in set 88 getting next 10\n",
      "\n",
      "not in set 89 getting next 10\n",
      "\n",
      "not in set 90 getting next 10\n",
      "\n",
      "not in set 91 getting next 10\n",
      "\n",
      "not in set 92 getting next 10\n",
      "\n",
      "not in set 93 getting next 10\n",
      "\n",
      "not in set 94 getting next 10\n",
      "\n",
      "not in set 95 getting next 10\n",
      "\n",
      "not in set 96 getting next 10\n",
      "\n",
      "not in set 97 getting next 10\n",
      "\n",
      "not in set 98 getting next 10\n",
      "\n",
      "not in set 99 getting next 10\n",
      "\n",
      "not in set 100 getting next 10\n",
      "\n",
      "not in set 101 getting next 10\n",
      "\n",
      "not in set 102 getting next 10\n",
      "\n",
      "not in set 103 getting next 10\n",
      "\n",
      "not in set 104 getting next 10\n",
      "\n",
      "not in set 105 getting next 10\n",
      "\n",
      "not in set 106 getting next 10\n",
      "\n",
      "not in set 107 getting next 10\n",
      "\n",
      "not in set 108 getting next 10\n",
      "\n",
      "not in set 109 getting next 10\n",
      "\n",
      "not in set 110 getting next 10\n",
      "\n",
      "not in set 111 getting next 10\n",
      "\n",
      "not in set 112 getting next 10\n",
      "\n",
      "not in set 113 getting next 10\n",
      "\n",
      "not in set 114 getting next 10\n",
      "\n",
      "not in set 115 getting next 10\n",
      "\n",
      "not in set 116 getting next 10\n",
      "\n",
      "not in set 117 getting next 10\n",
      "\n",
      "not in set 118 getting next 10\n",
      "\n",
      "not in set 119 getting next 10\n",
      "\n",
      "not in set 120 getting next 10\n",
      "\n",
      "not in set 121 getting next 10\n",
      "\n",
      "not in set 122 getting next 10\n",
      "\n",
      "not in set 123 getting next 10\n",
      "\n",
      "not in set 124 getting next 10\n",
      "\n",
      "not in set 125 getting next 10\n",
      "\n",
      "not in set 126 getting next 10\n",
      "\n",
      "not in set 127 getting next 10\n",
      "\n",
      "not in set 128 getting next 10\n",
      "\n",
      "not in set 129 getting next 10\n",
      "\n",
      "not in set 130 getting next 10\n",
      "\n",
      "not in set 131 getting next 10\n",
      "\n",
      "not in set 132 getting next 10\n",
      "\n",
      "not in set 133 getting next 10\n",
      "\n",
      "not in set 134 getting next 10\n",
      "\n",
      "not in set 135 getting next 10\n",
      "\n",
      "not in set 136 getting next 10\n",
      "\n",
      "not in set 137 getting next 10\n",
      "\n",
      "not in set 138 getting next 10\n",
      "\n",
      "not in set 139 getting next 10\n",
      "\n",
      "not in set 140 getting next 10\n",
      "\n",
      "not in set 141 getting next 10\n",
      "\n",
      "not in set 142 getting next 10\n",
      "\n",
      "not in set 143 getting next 10\n",
      "\n",
      "not in set 144 getting next 10\n",
      "\n",
      "not in set 145 getting next 10\n",
      "\n",
      "not in set 146 getting next 10\n",
      "\n",
      "not in set 147 getting next 10\n",
      "\n",
      "not in set 148 getting next 10\n",
      "\n",
      "not in set 149 getting next 10\n",
      "\n",
      "not in set 150 getting next 10\n",
      "\n",
      "not in set 151 getting next 10\n",
      "\n",
      "not in set 152 getting next 10\n",
      "\n",
      "not in set 153 getting next 10\n",
      "\n",
      "not in set 154 getting next 10\n",
      "\n",
      "not in set 155 getting next 10\n",
      "\n",
      "not in set 156 getting next 10\n",
      "\n",
      "not in set 157 getting next 10\n",
      "\n",
      "not in set 158 getting next 10\n",
      "\n",
      "not in set 159 getting next 10\n",
      "\n",
      "not in set 160 getting next 10\n",
      "\n",
      "not in set 161 getting next 10\n",
      "\n",
      "not in set 162 getting next 10\n",
      "\n",
      "not in set 163 getting next 10\n",
      "\n",
      "not in set 164 getting next 10\n",
      "\n",
      "not in set 165 getting next 10\n",
      "\n",
      "not in set 166 getting next 10\n",
      "\n",
      "not in set 167 getting next 10\n",
      "\n",
      "not in set 168 getting next 10\n",
      "\n",
      "not in set 169 getting next 10\n",
      "\n",
      "not in set 170 getting next 10\n",
      "\n",
      "not in set 171 getting next 10\n",
      "\n",
      "not in set 172 getting next 10\n",
      "\n",
      "not in set 173 getting next 10\n",
      "\n",
      "not in set 174 getting next 10\n",
      "\n",
      "not in set 175 getting next 10\n",
      "\n",
      "not in set 176 getting next 10\n",
      "\n",
      "not in set 177 getting next 10\n",
      "\n",
      "not in set 178 getting next 10\n",
      "\n",
      "not in set 179 getting next 10\n",
      "\n",
      "not in set 180 getting next 10\n",
      "\n",
      "not in set 181 getting next 10\n",
      "\n",
      "not in set 182 getting next 10\n",
      "\n",
      "not in set 183 getting next 10\n",
      "\n",
      "not in set 184 getting next 10\n",
      "\n",
      "not in set 185 getting next 10\n",
      "\n",
      "not in set 186 getting next 10\n",
      "\n",
      "not in set 187 getting next 10\n",
      "\n",
      "not in set 188 getting next 10\n",
      "\n",
      "not in set 189 getting next 10\n",
      "\n",
      "not in set 190 getting next 10\n",
      "\n",
      "not in set 191 getting next 10\n",
      "\n",
      "not in set 192 getting next 10\n",
      "\n",
      "not in set 193 getting next 10\n",
      "\n",
      "not in set 194 getting next 10\n",
      "\n",
      "not in set 195 getting next 10\n",
      "\n",
      "not in set 196 getting next 10\n",
      "\n",
      "not in set 197 getting next 10\n",
      "\n",
      "not in set 198 getting next 10\n",
      "\n",
      "not in set 199 getting next 10\n",
      "\n",
      "not in set 200 getting next 10\n",
      "\n",
      "not in set 201 getting next 10\n",
      "\n",
      "not in set 202 getting next 10\n",
      "\n",
      "not in set 203 getting next 10\n",
      "\n",
      "not in set 204 getting next 10\n",
      "\n",
      "not in set 205 getting next 10\n",
      "\n",
      "not in set 206 getting next 10\n",
      "\n",
      "not in set 207 getting next 10\n",
      "\n",
      "not in set 208 getting next 10\n",
      "\n",
      "not in set 209 getting next 10\n",
      "\n",
      "not in set 210 getting next 10\n",
      "\n",
      "not in set 211 getting next 10\n",
      "\n",
      "not in set 212 getting next 10\n",
      "\n",
      "not in set 213 getting next 10\n",
      "\n",
      "not in set 214 getting next 10\n",
      "\n",
      "not in set 215 getting next 10\n",
      "\n",
      "not in set 216 getting next 10\n",
      "\n",
      "not in set 217 getting next 10\n",
      "\n",
      "not in set 218 getting next 10\n",
      "\n",
      "not in set 219 getting next 10\n",
      "\n",
      "not in set 220 getting next 10\n",
      "\n",
      "not in set 221 getting next 10\n",
      "\n",
      "not in set 222 getting next 10\n",
      "\n",
      "not in set 223 getting next 10\n",
      "\n",
      "not in set 224 getting next 10\n",
      "\n",
      "not in set 225 getting next 10\n",
      "\n",
      "not in set 226 getting next 10\n",
      "\n",
      "not in set 227 getting next 10\n",
      "\n",
      "not in set 228 getting next 10\n",
      "\n",
      "not in set 229 getting next 10\n",
      "\n",
      "not in set 230 getting next 10\n",
      "\n",
      "not in set 231 getting next 10\n",
      "\n",
      "not in set 232 getting next 10\n",
      "\n",
      "not in set 233 getting next 10\n",
      "\n",
      "not in set 234 getting next 10\n",
      "\n",
      "not in set 235 getting next 10\n",
      "\n",
      "not in set 236 getting next 10\n",
      "\n",
      "not in set 237 getting next 10\n",
      "\n",
      "not in set 238 getting next 10\n",
      "\n",
      "not in set 239 getting next 10\n",
      "\n",
      "not in set 240 getting next 10\n",
      "\n",
      "not in set 241 getting next 10\n",
      "\n",
      "not in set 242 getting next 10\n",
      "\n",
      "not in set 243 getting next 10\n",
      "\n",
      "not in set 244 getting next 10\n",
      "\n",
      "not in set 245 getting next 10\n",
      "\n",
      "not in set 246 getting next 10\n",
      "\n",
      "not in set 247 getting next 10\n",
      "\n",
      "all done.  you probably didn't find it\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "url = 'http://localhost:1080'\n",
    "field = 'external_id'\n",
    "search = '7316-1110'\n",
    "study = 'SD_BHJXBDQK'\n",
    "part_url = url + '/participants?study_id=' + study\n",
    "part_info = requests.request('GET', part_url)\n",
    "# edit what field you want to try\n",
    "\n",
    "next_link = url + part_info.json()['_links']['next']\n",
    "# print (json.dumps(part_info.json()['results'][0][field], indent=4, sort_keys=True))\n",
    "f = 0\n",
    "x = 1\n",
    "while f == 0:\n",
    "    for res in part_info.json()['results']:\n",
    "        if re.match(pattern=search, string=res['external_id']):\n",
    "            print (res['kf_id'])\n",
    "            f = 1\n",
    "    print ('not in set ' + str(x) + ' getting next 10\\n')\n",
    "    x += 1\n",
    "    part_info = requests.request('GET', next_link)\n",
    "    try:\n",
    "        next_link = url + part_info.json()['_links']['next']\n",
    "    except:\n",
    "        print ('all done.  you probably didn\\'t find it\\n')\n",
    "        f = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search biospecimen external id in a certain study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in set 1 getting next 10\n",
      "\n",
      "not in set 2 getting next 10\n",
      "\n",
      "not in set 3 getting next 10\n",
      "\n",
      "not in set 4 getting next 10\n",
      "\n",
      "not in set 5 getting next 10\n",
      "\n",
      "not in set 6 getting next 10\n",
      "\n",
      "not in set 7 getting next 10\n",
      "\n",
      "not in set 8 getting next 10\n",
      "\n",
      "not in set 9 getting next 10\n",
      "\n",
      "not in set 10 getting next 10\n",
      "\n",
      "not in set 11 getting next 10\n",
      "\n",
      "not in set 12 getting next 10\n",
      "\n",
      "not in set 13 getting next 10\n",
      "\n",
      "not in set 14 getting next 10\n",
      "\n",
      "not in set 15 getting next 10\n",
      "\n",
      "not in set 16 getting next 10\n",
      "\n",
      "not in set 17 getting next 10\n",
      "\n",
      "not in set 18 getting next 10\n",
      "\n",
      "not in set 19 getting next 10\n",
      "\n",
      "not in set 20 getting next 10\n",
      "\n",
      "not in set 21 getting next 10\n",
      "\n",
      "not in set 22 getting next 10\n",
      "\n",
      "not in set 23 getting next 10\n",
      "\n",
      "not in set 24 getting next 10\n",
      "\n",
      "not in set 25 getting next 10\n",
      "\n",
      "not in set 26 getting next 10\n",
      "\n",
      "not in set 27 getting next 10\n",
      "\n",
      "not in set 28 getting next 10\n",
      "\n",
      "not in set 29 getting next 10\n",
      "\n",
      "not in set 30 getting next 10\n",
      "\n",
      "not in set 31 getting next 10\n",
      "\n",
      "not in set 32 getting next 10\n",
      "\n",
      "not in set 33 getting next 10\n",
      "\n",
      "not in set 34 getting next 10\n",
      "\n",
      "not in set 35 getting next 10\n",
      "\n",
      "not in set 36 getting next 10\n",
      "\n",
      "not in set 37 getting next 10\n",
      "\n",
      "not in set 38 getting next 10\n",
      "\n",
      "not in set 39 getting next 10\n",
      "\n",
      "not in set 40 getting next 10\n",
      "\n",
      "not in set 41 getting next 10\n",
      "\n",
      "not in set 42 getting next 10\n",
      "\n",
      "not in set 43 getting next 10\n",
      "\n",
      "not in set 44 getting next 10\n",
      "\n",
      "not in set 45 getting next 10\n",
      "\n",
      "not in set 46 getting next 10\n",
      "\n",
      "not in set 47 getting next 10\n",
      "\n",
      "not in set 48 getting next 10\n",
      "\n",
      "not in set 49 getting next 10\n",
      "\n",
      "not in set 50 getting next 10\n",
      "\n",
      "not in set 51 getting next 10\n",
      "\n",
      "not in set 52 getting next 10\n",
      "\n",
      "not in set 53 getting next 10\n",
      "\n",
      "not in set 54 getting next 10\n",
      "\n",
      "not in set 55 getting next 10\n",
      "\n",
      "not in set 56 getting next 10\n",
      "\n",
      "not in set 57 getting next 10\n",
      "\n",
      "not in set 58 getting next 10\n",
      "\n",
      "not in set 59 getting next 10\n",
      "\n",
      "not in set 60 getting next 10\n",
      "\n",
      "not in set 61 getting next 10\n",
      "\n",
      "not in set 62 getting next 10\n",
      "\n",
      "not in set 63 getting next 10\n",
      "\n",
      "not in set 64 getting next 10\n",
      "\n",
      "not in set 65 getting next 10\n",
      "\n",
      "not in set 66 getting next 10\n",
      "\n",
      "not in set 67 getting next 10\n",
      "\n",
      "not in set 68 getting next 10\n",
      "\n",
      "not in set 69 getting next 10\n",
      "\n",
      "not in set 70 getting next 10\n",
      "\n",
      "not in set 71 getting next 10\n",
      "\n",
      "not in set 72 getting next 10\n",
      "\n",
      "not in set 73 getting next 10\n",
      "\n",
      "not in set 74 getting next 10\n",
      "\n",
      "not in set 75 getting next 10\n",
      "\n",
      "not in set 76 getting next 10\n",
      "\n",
      "not in set 77 getting next 10\n",
      "\n",
      "not in set 78 getting next 10\n",
      "\n",
      "not in set 79 getting next 10\n",
      "\n",
      "not in set 80 getting next 10\n",
      "\n",
      "not in set 81 getting next 10\n",
      "\n",
      "not in set 82 getting next 10\n",
      "\n",
      "not in set 83 getting next 10\n",
      "\n",
      "not in set 84 getting next 10\n",
      "\n",
      "not in set 85 getting next 10\n",
      "\n",
      "not in set 86 getting next 10\n",
      "\n",
      "not in set 87 getting next 10\n",
      "\n",
      "not in set 88 getting next 10\n",
      "\n",
      "not in set 89 getting next 10\n",
      "\n",
      "not in set 90 getting next 10\n",
      "\n",
      "not in set 91 getting next 10\n",
      "\n",
      "not in set 92 getting next 10\n",
      "\n",
      "not in set 93 getting next 10\n",
      "\n",
      "not in set 94 getting next 10\n",
      "\n",
      "not in set 95 getting next 10\n",
      "\n",
      "not in set 96 getting next 10\n",
      "\n",
      "not in set 97 getting next 10\n",
      "\n",
      "not in set 98 getting next 10\n",
      "\n",
      "not in set 99 getting next 10\n",
      "\n",
      "not in set 100 getting next 10\n",
      "\n",
      "not in set 101 getting next 10\n",
      "\n",
      "not in set 102 getting next 10\n",
      "\n",
      "not in set 103 getting next 10\n",
      "\n",
      "not in set 104 getting next 10\n",
      "\n",
      "not in set 105 getting next 10\n",
      "\n",
      "not in set 106 getting next 10\n",
      "\n",
      "BS_MAVJ6TK3\n",
      "BS_EGQ5S0MP\n",
      "BS_V95BZPQE\n",
      "not in set 107 getting next 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "url = 'http://localhost:1080'\n",
    "field = 'external_sample_id'\n",
    "search = '7316-1110'\n",
    "study = 'SD_BHJXBDQK'\n",
    "part_url = url + '/participants?study_id=' + study\n",
    "# part_url = url + '/participants'\n",
    "part_info = requests.request('GET', part_url)\n",
    "# edit what field you want to try\n",
    "\n",
    "next_link = url + part_info.json()['_links']['next']\n",
    "# print (json.dumps(part_info.json()['results'][0][field], indent=4, sort_keys=True))\n",
    "# http://localhost:1080/biospecimens?participant_id=PT_7MQFGW6D\n",
    "f = 0\n",
    "x = 1\n",
    "while f == 0:\n",
    "    for res in part_info.json()['results']:\n",
    "        biospec_url = url + res['_links']['biospecimens']\n",
    "        # print biospec_url\n",
    "        check_bio = requests.request('GET', biospec_url)\n",
    "        for bio_res in check_bio.json()['results']:\n",
    "            if re.match(pattern=search, string=bio_res[field]):\n",
    "                print (bio_res['kf_id'])\n",
    "                f = 1\n",
    "    print ('not in set ' + str(x) + ' getting next 10\\n')\n",
    "    x += 1\n",
    "    part_info = requests.request('GET', next_link)\n",
    "    try:\n",
    "        next_link = url + part_info.json()['_links']['next']\n",
    "    except:\n",
    "        print ('all done.  you probably didn\\'t find what you were looking for\\n')\n",
    "        f = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get input vcf file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting files for brownm28/kf-genotype-refinement-workflow\n",
      "Found relevant file 5077c39a-d456-437c-89ac-f3854d2575d4.vcf.gzFound relevant file 5077c39a-d456-437c-89ac-f3854d2575d4.vcf.gz.tbiFound relevant file fc46610e-f873-4998-805c-b2cd76e56c00.vcf.gzFound relevant file fc46610e-f873-4998-805c-b2cd76e56c00.vcf.gz.tbiFound relevant file fcc6436b-5874-43d8-98a7-973c421ea96c.vcf.gzFound relevant file fcc6436b-5874-43d8-98a7-973c421ea96c.vcf.gz.tbiFound relevant file fcd0830b-3fd9-4220-a83e-47d2659605eb.vcf.gzFound relevant file fcd0830b-3fd9-4220-a83e-47d2659605eb.vcf.gz.tbiFound relevant file fceead3c-2b03-46ee-b958-bd5648d1979a.vcf.gzFound relevant file fceead3c-2b03-46ee-b958-bd5648d1979a.vcf.gz.tbiFound relevant file fe6cb487-f7de-43ba-8090-f68ae0d1fba0.vcf.gzFound relevant file fe6cb487-f7de-43ba-8090-f68ae0d1fba0.vcf.gz.tbi"
     ]
    }
   ],
   "source": [
    "project = 'brownm28/kf-genotype-refinement-workflow'\n",
    "tag_search = 'Trio Joint Genotyping'\n",
    "files = api.files.query(project=project)\n",
    "sys.stderr.write('Getting files for ' + project + '\\n')\n",
    "#dir(files)\n",
    "vcf_list = []\n",
    "for file_obj in files:\n",
    "    for tag in file_obj.tags:\n",
    "        if tag == tag_search:\n",
    "            vcf_list.append(file_obj)\n",
    "            sys.stderr.write('Found relevant file ' + file_obj.name + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for files in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BS_2PWHWB6B.cram\n",
      "BS_33EDFD7C.cram\n",
      "BS_HKQYYQZX.cram\n",
      "BS_R66JVDBS.cram\n",
      "BS_SB172XRA.cram\n"
     ]
    }
   ],
   "source": [
    "project = 'kfdrc-harmonization/sd-9pyzahhe-01'\n",
    "files = api.files.query(project=project)\n",
    "flist = {'BS_WAY3FE6T.cram': 0,\n",
    "'BS_EWYT24R8.cram': 0,\n",
    "'BS_SB172XRA.cram': 0,\n",
    "'BS_33EDFD7C.cram': 0,\n",
    "'BS_EKCXX5H6.cram': 0,\n",
    "'BS_BSXP5B6Q.cram': 0,\n",
    "'BS_ZTBX0WB6.cram': 0,\n",
    "'BS_V5952JDS.cram': 0,\n",
    "'BS_02CC3HBK.cram': 0,\n",
    "'BS_PEBS6CTY.cram': 0,\n",
    "'BS_VKKFYXTX.cram': 0,\n",
    "'BS_B3ZZB1V4.cram': 0,\n",
    "'BS_2684E5FS.cram': 0,\n",
    "'BS_P9YNFP0C.cram': 0,\n",
    "'BS_TJ8N7NFH.cram': 0,\n",
    "'BS_ZMHQ4KK6.cram': 0,\n",
    "'BS_YHJFG3JV.cram': 0,\n",
    "'BS_NAFEB2M7.cram': 0,\n",
    "'BS_8AG5E38C.cram': 0,\n",
    "'BS_Z40X3HA0.cram': 0,\n",
    "'BS_KFH8Q61Z.cram': 0,\n",
    "'BS_2PWHWB6B.cram': 0,\n",
    "'BS_R66JVDBS.cram': 0,\n",
    "'BS_HKQYYQZX.cram': 0,\n",
    "'BS_NJP1E2G1.cram': 0,\n",
    "'BS_EWBA2VEK.cram': 0,\n",
    "'BS_YZKT40NN.cram': 0,\n",
    "'BS_E3NB86WM.cram': 0}\n",
    "for file_obj in files.all():\n",
    "    if file_obj.name in flist:\n",
    "        flist[file_obj.name] = 1\n",
    "        print (file_obj.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b04cde7-d71b-4e26-9a30-82e4e886063c.postCGP.Gfiltered.deNovos.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "print files[0].name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Kids First ID': u'FM_KXC88W01', u'Family ID': u'GMKF0994'}\n"
     ]
    }
   ],
   "source": [
    "print (files[8].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_API', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_api', '_data', '_dirty', '_fields', '_modified_data', '_old', '_query', 'deepcopy', 'delete', 'end_time', 'equals', 'field', 'get', 'href', 'jobs', 'message', 'reload', 'start_time', 'status']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Job: name=root_strelka2, status=COMPLETED>,\n",
       " <Job: name=root_filter_vcf, status=COMPLETED>,\n",
       " <Job: name=root_samtools_tumor_cram2bam, status=COMPLETED>,\n",
       " <Job: name=root_control_free_c_r, status=COMPLETED>,\n",
       " <Job: name=root_vep_maf_annotate, status=COMPLETED>,\n",
       " <Job: name=root_samtools_normal_cram2bam, status=COMPLETED>,\n",
       " <Job: name=root_control_free_c_viz, status=COMPLETED>,\n",
       " <Job: name=root_control_free_c, status=COMPLETED>,\n",
       " <Job: name=root_merge_vcf, status=COMPLETED>,\n",
       " <Job: name=root_snpeff_annotate, status=COMPLETED>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import sevenbridges as sbg\n",
    "import sys\n",
    "#from requests import request\n",
    "\n",
    "#token = sys.argv[2]\n",
    "config = sbg.Config(profile='cavatica')\n",
    "api = sbg.Api(config=config)\n",
    "# api = sbg.Api(url='https://cavatica-api.sbgenomics.com/v2', token=token)\n",
    "\n",
    "task_list = '/Users/brownm28/Documents/2018-Aug-15_cbttc_launch/task_build/final_run/task_details/test.txt'\n",
    "task_dict = {}\n",
    "for line in open(task_list):\n",
    "    task_dict[line.rstrip('\\n')] = 0\n",
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-07'\n",
    "proj_tasks = api.tasks.query(project=project)\n",
    "#proj_tasks = api.tasks.get(id='91974cd2-43a2-4510-9513-f317f3aa6c34')\n",
    "#print(dir(proj_tasks.get_execution_details()))\n",
    "#proj_tasks.get_execution_details().jobs\n",
    "for task in proj_tasks:\n",
    "    if task.id in task_dict:\n",
    "        # print(dir(task.get_execution_details()))\n",
    "        print ('\\t'.join((task.name, task.id, str(task.price.amount))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get diagnosis by biospecimen id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diag(url, bs_id, out):\n",
    "    bs_url = url + '/biospecimens/' + bs_id\n",
    "    try:\n",
    "        bs_info = requests.request('GET', bs_url)\n",
    "        pt_link = bs_info.json()['_links']['participant']\n",
    "        pt = pt_link.split('/')\n",
    "\n",
    "        diag_link = url + '/diagnoses?participant_id=' + pt[2]\n",
    "        diag_info = requests.request('GET', diag_link)\n",
    "        i = 0\n",
    "        n = 10\n",
    "        kf_id_list = []\n",
    "        source_text = []\n",
    "        source_loc = []\n",
    "        for diag in diag_info.json()['results']:\n",
    "            kf_id_list.append(diag['kf_id'])\n",
    "            source_text.append(diag['source_text_diagnosis'])\n",
    "            source_loc.append(diag['source_text_tumor_location'])\n",
    "            i += 1\n",
    "        if i > n:\n",
    "            sys.stderr.write('WARNING: ' + bs_id + ' had more than ' + str(10) + ' diagnoses, results truncated')\n",
    "        out.write(bs_id + '\\t' + ','.join(kf_id_list) + '\\t' + ','.join(source_text) + '\\t' + ','.join(source_loc) + '\\t' + str(i) + '\\n')\n",
    "    except:\n",
    "        out.write(bs_id + '\\tNA\\tNA\\tNA\\tNA\\n')\n",
    "        sys.stderr.write('WARNING: ' + bs_id + ' has no dx info!\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_file = '/Users/brownm28/Documents/2018-Aug-15_cbttc_launch/dx_list/test.txt'\n",
    "out = open('/Users/brownm28/Documents/2018-Aug-15_cbttc_launch/dx_list/dx_table.txt', 'w')\n",
    "out.write('BS_ID\\tdx kf_ids\\tdx text\\tdx source\\tnum dx\\n')\n",
    "x = 1\n",
    "m = 10\n",
    "for bs_id in open(id_file):\n",
    "    bs_id = bs_id.rstrip('\\n')\n",
    "    # sys.stderr.write('Processing bs_id ' + bs_id + '\\n')\n",
    "    if x % m == 0:\n",
    "        sys.stderr.write('Processing the ' + str(x) + 'th bs_id ' + bs_id + '\\n')\n",
    "    x += 1\n",
    "    url = 'https://kf-api-dataservice.kidsfirstdrc.org'\n",
    "    get_diag(url, bs_id, out)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "url = 'https://kf-api-dataservice.kidsfirstdrc.org/biospecimens/BS_K049HVGR'\n",
    "test = requests.request('GET', url)\n",
    "null_item = test.json()['results']['shipment_date']\n",
    "if null_item is None:\n",
    "print (null_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search task by project, filter by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20180904\t20180907\n",
      "20180904\t20180907\n",
      "20180904\t20180907\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n",
      "20180904\t20180906\n"
     ]
    }
   ],
   "source": [
    "project = 'kfdrc-harmonization/sd-bhjxbdqk-02'\n",
    "\n",
    "tasks = api.tasks.query(project=project, order_by='created_time').all()\n",
    "in_keys = ['input_reads']\n",
    "out_fn = '/Users/brownm28/Documents/2018-Sep-10_proteomics_update/other_nantomics_file_update/dna_tasks.txt'\n",
    "date_int = 20180904\n",
    "out = open(out_fn, 'w')\n",
    "out.write('\\t'.join(['Task name', 'Date created', 'Created by', 'ID']) + '\\t' + '\\t'.join(in_keys) + '\\n')\n",
    "for task_obj in tasks:\n",
    "    day = str(task_obj.created_time.day)\n",
    "    if int(day) < 10:\n",
    "        day = '0' + day\n",
    "    month = str(task_obj.created_time.month)\n",
    "    if int(month) < 10:\n",
    "        month = '0' + month\n",
    "    create_date = str(task_obj.created_time.year) + month + day\n",
    "    create_date_int = int(create_date)\n",
    "    \n",
    "    if date_int <= create_date_int and task_obj.status == 'COMPLETED':\n",
    "        sys.stderr.write(str(date_int) + '\\t' + str(create_date_int) + '\\n')\n",
    "        out.write('\\t'.join((task_obj.name, create_date, task_obj.created_by, task_obj.id)))\n",
    "        in_fn = {}\n",
    "        for in_key in in_keys:\n",
    "            if in_key not in in_fn:\n",
    "                in_fn[in_key] = []\n",
    "            # assume file array input first, then try as a single file object\n",
    "            try:\n",
    "                for f_obj in task_obj.inputs[in_key]:\n",
    "                    in_fn[in_key].append(f_obj.name)\n",
    "            except:\n",
    "                try:\n",
    "                    in_fn[in_key].append(task_obj.inputs[in_key].name)\n",
    "                except:\n",
    "                    for i in range(0, len(in_keys), 1):\n",
    "                        out.write('\\t')\n",
    "                    out.write('\\n')\n",
    "                    sys.stderr.write('Missing input files for ' + task_obj.name + '\\t' + task_obj.id + '\\n')\n",
    "        for in_key in in_keys:\n",
    "            out.write('\\t' + ','.join(in_fn[in_key]))\n",
    "        out.write('\\n')\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BS_W72364MN\n"
     ]
    }
   ],
   "source": [
    "task = api.tasks.get(id='dd79c6e1-b711-4485-9b1a-da900728cc61')\n",
    "print (task.outputs['result'][0].metadata['Kids First Biospecimen ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
