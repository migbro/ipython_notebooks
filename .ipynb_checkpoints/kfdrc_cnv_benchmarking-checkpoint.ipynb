{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sevenbridges.http.client:Advance access features enabled. AA API calls can be subject to changes.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sevenbridges as sbg\n",
    "from sevenbridges.errors import SbgError\n",
    "from sevenbridges.http.error_handlers import rate_limit_sleeper, maintenance_sleeper\n",
    "import sys\n",
    "import re\n",
    "import concurrent.futures\n",
    "import pdb\n",
    "config = sbg.Config(profile='turbo')\n",
    "api = sbg.Api(config=config, error_handlers=[rate_limit_sleeper, maintenance_sleeper], advance_access=True)\n",
    "project = 'brownm28/mb-controlfreec-troubleshoot'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found valid file a04d1bd7-3451-40ec-a99c-1d5d13bf8a39.vardict.merged.vcf.gz PT_9QQ37AWW Tumor\n",
      "Copied file over\n",
      "Found valid file a04d1bd7-3451-40ec-a99c-1d5d13bf8a39.vardict.merged.vcf.gz.tbi PT_9QQ37AWW Tumor\n",
      "Copied file over\n",
      "Found valid file d8ccc539-5463-4217-937e-1c958dadabcd.vardict.merged.vcf.gz PT_1EQHANKW Tumor\n",
      "Copied file over\n",
      "Found valid file d8ccc539-5463-4217-937e-1c958dadabcd.vardict.merged.vcf.gz.tbi PT_1EQHANKW Tumor\n",
      "Copied file over\n",
      "Found valid file b3bccc8a-261f-4be5-978c-34c5e1075177.vardict.merged.vcf.gz PT_TAJJ9MYY Tumor\n",
      "Copied file over\n",
      "Found valid file b3bccc8a-261f-4be5-978c-34c5e1075177.vardict.merged.vcf.gz.tbi PT_TAJJ9MYY Tumor\n",
      "Copied file over\n",
      "Found valid file 48aa6252-e617-49de-a9b7-7d1af74de326.vardict.merged.vcf.gz PT_BXYKW39H Tumor\n",
      "Copied file over\n",
      "Found valid file 48aa6252-e617-49de-a9b7-7d1af74de326.vardict.merged.vcf.gz.tbi PT_BXYKW39H Tumor\n",
      "Copied file over\n",
      "Found valid file 27e72734-c076-423f-a196-6a17e524989f.vardict.merged.vcf.gz PT_53M7K3JE Tumor\n",
      "Copied file over\n",
      "Found valid file 27e72734-c076-423f-a196-6a17e524989f.vardict.merged.vcf.gz.tbi PT_53M7K3JE Tumor\n",
      "Copied file over\n",
      "Found valid file e7ea4d0d-e252-4775-aef4-93a4da18b86b.vardict.merged.vcf.gz PT_1YAJEAMJ Tumor\n",
      "Copied file over\n",
      "Found valid file e7ea4d0d-e252-4775-aef4-93a4da18b86b.vardict.merged.vcf.gz.tbi PT_1YAJEAMJ Tumor\n",
      "Copied file over\n",
      "Found valid file da93a44b-2302-4354-b193-bbbc6dbfffd5.vardict.merged.vcf.gz PT_R2TRGY6N Tumor\n",
      "Copied file over\n",
      "Found valid file da93a44b-2302-4354-b193-bbbc6dbfffd5.vardict.merged.vcf.gz.tbi PT_R2TRGY6N Tumor\n",
      "Copied file over\n",
      "Found valid file dfb0b6d4-e540-4e63-9aba-695a5c5c2a71.vardict.merged.vcf.gz PT_KWRFGRER Tumor\n",
      "Copied file over\n",
      "Found valid file dfb0b6d4-e540-4e63-9aba-695a5c5c2a71.vardict.merged.vcf.gz.tbi PT_KWRFGRER Tumor\n",
      "Copied file over\n",
      "Found valid file 269eebca-b99b-4dad-b9e7-2b8bca3f4603.vardict.merged.vcf.gz PT_ASH4P45D Tumor\n",
      "Copied file over\n",
      "Found valid file 269eebca-b99b-4dad-b9e7-2b8bca3f4603.vardict.merged.vcf.gz.tbi PT_ASH4P45D Tumor\n",
      "Copied file over\n",
      "Found valid file 39db4cb8-e42c-43f5-bf25-b4f28900af57.vardict.merged.vcf.gz PT_3WF5J3PZ Tumor\n",
      "Copied file over\n",
      "Found valid file 39db4cb8-e42c-43f5-bf25-b4f28900af57.vardict.merged.vcf.gz.tbi PT_3WF5J3PZ Tumor\n",
      "Copied file over\n",
      "Found valid file c6d73a72-fd2a-4e75-bd6f-1ed608e20b50.vardict.merged.vcf.gz PT_JF62ZBX8 Tumor\n",
      "Copied file over\n",
      "Found valid file c6d73a72-fd2a-4e75-bd6f-1ed608e20b50.vardict.merged.vcf.gz.tbi PT_JF62ZBX8 Tumor\n",
      "Copied file over\n",
      "Found valid file 2a73e035-c5b6-4618-9cf7-91f4a75de41d.vardict.merged.vcf.gz PT_GERVNCVY Tumor\n",
      "Copied file over\n",
      "Found valid file 2a73e035-c5b6-4618-9cf7-91f4a75de41d.vardict.merged.vcf.gz.tbi PT_GERVNCVY Tumor\n",
      "Copied file over\n"
     ]
    }
   ],
   "source": [
    "germ_origin = 'kfdrc-harmonization/sd-dypmehhf'\n",
    "tumor_origin= 'kfdrc-harmonization/sd-dypmehhf-03/'\n",
    "somatic_origin= 'kfdrc-harmonization/sd-dypmehhf-05'\n",
    "case_id_list = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_test_set.txt')\n",
    "\n",
    "case_list = []\n",
    "for line in case_id_list:\n",
    "    case_list.append(line.rstrip('\\n'))\n",
    "case_id_list.close()\n",
    "for case_id in case_list:\n",
    "    files = api.files.query(project=somatic_origin, metadata = {'case_id': case_id} )\n",
    "    for file_obj in files:\n",
    "        if re.search(\"vardict.merged.vcf.gz$|vardict.merged.vcf.gz.tbi$\", file_obj.name):\n",
    "            print(\"Found valid file \" + file_obj.name + \" \" + file_obj.metadata[\"Kids First Participant ID\"] + \" \" + file_obj.metadata[\"sample_type\"])\n",
    "            file_obj.copy(project=project)\n",
    "            print (\"Copied file over\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HC Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_refs(api):\n",
    "    ref_dict = {}\n",
    "    ref_dict['axiomPoly_resource_vcf'] = api.files.query(project=project, names=['Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz'])[0]\n",
    "    ref_dict['reference_dict'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.dict'])[0]\n",
    "    ref_dict['dbsnp_vcf'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.dbsnp138.vcf'])[0]\n",
    "    ref_dict['hapmap_resource_vcf'] = api.files.query(project=project, names=['hapmap_3.3.hg38.vcf.gz'])[0]\n",
    "    ref_dict['mills_resource_vcf'] = api.files.query(project=project, names=['Mills_and_1000G_gold_standard.indels.hg38.vcf.gz'])[0]\n",
    "    ref_dict['omni_resource_vcf'] = api.files.query(project=project, names=['1000G_omni2.5.hg38.vcf.gz'])[0]\n",
    "    ref_dict['one_thousand_genomes_resource_vcf'] = api.files.query(project=project, names=['1000G_phase1.snps.high_confidence.hg38.vcf.gz'])[0]\n",
    "    #ref_dict['ref_fasta'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.fasta'])[0]\n",
    "    ref_dict['reference_fasta'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.fasta'])[0]\n",
    "    #ref_dict['ref_tar_gz'] = api.files.query(project=project, names=['hg38_snpeff.tgz'])[0]\n",
    "    ref_dict['unpadded_intervals_file'] = api.files.query(project=project, names=['hg38.even.handcurated.20k.intervals'])[0]\n",
    "    ref_dict['wgs_evaluation_interval_list'] = api.files.query(project=project, names=['wgs_evaluation_regions.hg38.interval_list'])[0]\n",
    "    ref_dict['snp_sites'] = api.files.query(project=project, names=['1000G_phase3_v4_20130502.sites.hg38.vcf'])[0]\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_gvcf_test-manifest.csv')\n",
    "head = next(manifest)\n",
    "ref_obj = get_refs(api)\n",
    "# app_name = project + \"/kf-single-genotype/0\"\n",
    "app_name = project + \"/kfdrc-single-genotype-basic\"\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    in_dict = {}\n",
    "    for key in ref_obj:\n",
    "        in_dict[key] = ref_obj[key]\n",
    "    in_dict['input_vcfs'] = [api.files.get(info[0])]\n",
    "    task_name = \"SINGLE GENOTYPE GATK: \" + info[6] + \" \" + info[11] + \" \" + info[-2]\n",
    "    task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, execution_settings = {'use_memoization': True}, run=False)\n",
    "    task.inputs['output_basename'] = task.id\n",
    "    \n",
    "    task.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expand view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ControlFreeC Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_refs(api):\n",
    "    ref_dict = {}\n",
    "    ref_dict['chr_len'] = api.files.query(project=project, names=['hs38_chr.len'])[0]\n",
    "    ref_dict['reference'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.fasta'])[0]\n",
    "    ref_dict['reference_fai'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.fasta.fai'])[0]\n",
    "    ref_dict['include_expression'] = 'FILTER=\"PASS\"'\n",
    "    ref_dict['coeff_var'] = 0.05\n",
    "    ref_dict['mate_orientation_control'] = \"FR\"\n",
    "    ref_dict['mate_orientation_sample'] = \"FR\"\n",
    "    ref_dict['ploidy'] = [2,3,4]\n",
    "    ref_dict['threads'] = 16\n",
    "    ref_dict['contamination_adjustment'] = \"TRUE\"\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/kfdrc-controlfreec-wf'\n",
    "manifest = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_test_crams-manifest.csv')\n",
    "# case_id_list = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_test_set.txt')\n",
    "case_id_list = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/missed_case_list.txt')\n",
    "sex_prediction = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_sex_info_w_case_id.txt')\n",
    "# b_allele = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_test_ballele-manifest.csv')\n",
    "b_allele = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/missed_vcf-manifest.csv')\n",
    "case_list = []\n",
    "for line in case_id_list:\n",
    "    case_list.append(line.rstrip('\\n'))\n",
    "case_id_list.close()\n",
    "ref_objs = get_cf_refs(api)\n",
    "head = next(manifest)\n",
    "\n",
    "bam_dict = {}\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[9]\n",
    "    sample_id = info[11]\n",
    "    fid = info[0]\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    bam_dict[case_id][stype] = {}\n",
    "    bam_dict[case_id][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][stype]['file_obj'] = api.files.get(fid)\n",
    "    \n",
    "sex_dict = {}\n",
    "s_trans = {\"Male\": \"XY\", \"Female\": \"XX\"}\n",
    "head = next(sex_prediction)\n",
    "for line in sex_prediction:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    case_id = info[4]\n",
    "    pred_sex = info[-1]\n",
    "    ds_sex = info[1]\n",
    "    if case_id in case_list:\n",
    "        if pred_sex != \"Unknown\" and pred_sex == ds_sex:\n",
    "            sex_dict[case_id] = s_trans[pred_sex]\n",
    "        else:\n",
    "            sys.stderr.write(\"Warn, prediction for \" + case_id + \" was inconclusive.  Default to reported sex\\n\")\n",
    "            sex_dict[case_id] = s_trans[ds_sex]\n",
    "b_dict = {}\n",
    "head = next(b_allele)\n",
    "for line in b_allele:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    b_dict[case_id] = api.files.get(info[0])\n",
    "for case_id in case_list:\n",
    "    try:\n",
    "        in_dict = {}\n",
    "        for key in ref_objs:\n",
    "            in_dict[key] = ref_objs[key]\n",
    "        tumor = ''\n",
    "        normal = ''\n",
    "        for stype in bam_dict[case_id]:\n",
    "            if stype == 'Normal':\n",
    "                in_dict['input_normal'] = bam_dict[case_id][stype]['file_obj']\n",
    "                normal = bam_dict[case_id][stype]['sid']\n",
    "            else:\n",
    "                in_dict['input_tumor'] = bam_dict[case_id][stype]['file_obj']\n",
    "                tumor = bam_dict[case_id][stype]['sid']\n",
    "                in_dict['sample_name'] = tumor\n",
    "        in_dict['sex'] = sex_dict[case_id]\n",
    "        in_dict['b_allele'] = b_dict[case_id]\n",
    "        task_name = 'CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: ' + case_id + ' ' + tumor + ' ' + normal\n",
    "        # pdb.set_trace()\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "        task.inputs['output_basename'] = task.id + \"CONTAM_ADJUST\"\n",
    "        task.save()\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        print (\"Skipping due to error: \" + case_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNVkit Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ckit_refs(api):\n",
    "    ref_dict = {}\n",
    "    ref_dict['annotation_file'] = api.files.query(project=project, names=['refFlat_HG38.txt'])[0]\n",
    "    ref_dict['reference'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.fasta'])[0]\n",
    "    ref_dict['include_expression'] = 'FILTER=\"PASS\"'\n",
    "    ref_dict['wgs_mode'] = 'Y'\n",
    "    ref_dict['threads'] = 36\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/kfdrc-cnvkit-batch-wf'\n",
    "manifest = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_test_crams-manifest.csv')\n",
    "case_id_list = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_test_set.txt')\n",
    "# case_id_list = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/missed_case_list.txt')\n",
    "sex_prediction = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_sex_info_w_case_id.txt')\n",
    "b_allele = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_test_ballele-manifest.csv')\n",
    "case_list = []\n",
    "for line in case_id_list:\n",
    "    case_list.append(line.rstrip('\\n'))\n",
    "case_id_list.close()\n",
    "ref_objs = get_ckit_refs(api)\n",
    "head = next(manifest)\n",
    "bam_dict = {}\n",
    "for line in manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    stype = info[9]\n",
    "    sample_id = info[11]\n",
    "    fid = info[0]\n",
    "    if case_id not in bam_dict:\n",
    "        bam_dict[case_id] = {}\n",
    "    bam_dict[case_id][stype] = {}\n",
    "    bam_dict[case_id][stype]['sid'] = sample_id\n",
    "    bam_dict[case_id][stype]['file_obj'] = api.files.get(fid)\n",
    "    \n",
    "sex_dict = {}\n",
    "head = next(sex_prediction)\n",
    "for line in sex_prediction:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    case_id = info[4]\n",
    "    pred_sex = info[-1]\n",
    "    ds_sex = info[1]\n",
    "    if case_id in case_list:\n",
    "        if pred_sex != \"Unknown\" and pred_sex == ds_sex:\n",
    "            sex_dict[case_id] = pred_sex\n",
    "        else:\n",
    "            sys.stderr.write(\"Warn, prediction for \" + case_id + \" was inconclusive.  Default to reported sex\\n\")\n",
    "            sex_dict[case_id] = s_trans[ds_sex]\n",
    "b_dict = {}\n",
    "head = next(b_allele)\n",
    "for line in b_allele:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    b_dict[case_id] = api.files.get(info[0])\n",
    "for case_id in case_list:\n",
    "    try:\n",
    "        in_dict = {}\n",
    "        for key in ref_objs:\n",
    "            in_dict[key] = ref_objs[key]\n",
    "        tumor = ''\n",
    "        normal = ''\n",
    "        for stype in bam_dict[case_id]:\n",
    "            if stype == 'Normal':\n",
    "                in_dict['input_control'] = bam_dict[case_id][stype]['file_obj']\n",
    "                normal = bam_dict[case_id][stype]['sid']\n",
    "            else:\n",
    "                in_dict['input_sample'] = bam_dict[case_id][stype]['file_obj']\n",
    "                tumor = bam_dict[case_id][stype]['sid']\n",
    "                in_dict['tumor_sample_name'] = tumor\n",
    "        in_dict['sex'] = sex_dict[case_id]\n",
    "        in_dict['b_allele_vcf'] = b_dict[case_id]\n",
    "        task_name = 'CNVKIT FIRST PASS RERUN: ' + case_id + ' ' + tumor + ' ' + normal\n",
    "        #pdb.set_trace()\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, execution_settings={'use_memoization': True}, run=False)\n",
    "        task.inputs['output_basename'] = task.id + \"_FIRST_PASS\"\n",
    "        task.save()\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        print (\"Skipping due to error:\" + case_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tag outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PARUTJ03 BS_K2K5YSDS BS_E88G2GGG\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PASCWD03 BS_DWYR5CTE BS_WJWC3WV7\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PASTGD03 BS_W1R54A2M BS_3JR1MGPE\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PASXRJ03 BS_KXRFQF5N BS_C12CV8CF\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PASMET03 BS_RA5HNMDP BS_NVCBHA84\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PASUTC03 BS_B80Z459E BS_2M61TD7H\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PARTRP03 BS_4RX1AAVV BS_0PQA0GGY\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PASFKX03 BS_2X9EVKZ0 BS_PEGDA8G2\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PASPGB03 BS_ACCE0MEA BS_DBV7S78S\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PASUMG03 BS_WSK7MH3C BS_RD4H0EJ2\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PASVCK03 BS_KQHSSRW3 BS_VSQV5HFC\n",
      "Valid task found CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4: PASGRL03 BS_EQE447QB BS_D5VCY8WQ\n"
     ]
    }
   ],
   "source": [
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "# task name search phrase\n",
    "phrase = \"CONTROLFREEC NO CONTAM ADJUST PLOIDY 2-4\"\n",
    "# modify this to set which input file to use to tag the outputs with, may need to modify code if an array element\n",
    "in_key = 'input_tumor'\n",
    "for task in tasks:\n",
    "    if re.search(phrase, task.name):\n",
    "        sys.stderr.write('Valid task found ' + task.name + '\\n')\n",
    "        metadata = task.inputs[in_key].metadata\n",
    "        for out_key in task.outputs:\n",
    "            try:\n",
    "                if type(task.outputs[out_key]) is not list:\n",
    "                    file_obj = api.files.get(task.outputs[out_key].id)\n",
    "                    for key in metadata:\n",
    "                        file_obj.metadata[key] = metadata[key]\n",
    "                    file_obj.save()\n",
    "                else:\n",
    "                    for output in task.outputs[out_key]:\n",
    "                        file_obj = api.files.get(output.id)\n",
    "                        for key in metadata:\n",
    "                            file_obj.metadata[key] = metadata[key]\n",
    "                        file_obj.save()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Skipping \" + task.name + \" due to error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PureCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcn_refs(api):\n",
    "    ref_dict = {}\n",
    "    ref_dict['purecn_gc_ref'] = api.files.query(project=project, names=['hg38_PureCN_150bp_gc_file.txt'])[0]\n",
    "    ref_dict['dbsnp_vcf'] = api.files.query(project=project, names=['Homo_sapiens_assembly38.dbsnp138.vcf.gz'])[0]\n",
    "    ref_dict['include_expression'] = 'FILTER=\"PASS\" && (INFO/STATUS=\"Germline\" | INFO/STATUS=\"StrongSomatic\")'\n",
    "    ref_dict['genome_version'] = 'hg38'\n",
    "    ref_dict['cores'] = 16\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/kfdrc-purecn-wf'\n",
    "seg_manifest = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/cnvkit_seg-manifest.csv')\n",
    "case_id_list = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_test_set.txt')\n",
    "sex_prediction = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_sex_info_w_case_id.txt')\n",
    "somatic_germline = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_vardict_vcfs-manifest.csv')\n",
    "case_list = []\n",
    "for line in case_id_list:\n",
    "    case_list.append(line.rstrip('\\n'))\n",
    "case_id_list.close()\n",
    "ref_objs = get_pcn_refs(api)\n",
    "head = next(seg_manifest)\n",
    "seg_dict = {}\n",
    "for line in seg_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    sample_id = info[11]\n",
    "    fid = info[0]\n",
    "    seg_dict[case_id] = api.files.get(fid)\n",
    "    \n",
    "sex_dict = {}\n",
    "s_trans = {\"Male\": \"M\", \"Female\": \"F\"}\n",
    "head = next(sex_prediction)\n",
    "for line in sex_prediction:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    case_id = info[4]\n",
    "    pred_sex = info[-1]\n",
    "    ds_sex = info[1]\n",
    "    if case_id in case_list:\n",
    "        if pred_sex != \"Unknown\" and pred_sex == ds_sex:\n",
    "            sex_dict[case_id] = s_trans[pred_sex]\n",
    "        else:\n",
    "            sys.stderr.write(\"Warn, prediction for \" + case_id + \" was inconclusive.  Default to reported sex\\n\")\n",
    "            sex_dict[case_id] = s_trans[ds_sex]\n",
    "b_dict = {}\n",
    "head = next(somatic_germline)\n",
    "for line in somatic_germline:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    b_dict[case_id] = api.files.get(info[0])\n",
    "for case_id in case_list:\n",
    "    try:\n",
    "        in_dict = {}\n",
    "        for key in ref_objs:\n",
    "            in_dict[key] = ref_objs[key]\n",
    "        seg_obj = seg_dict[case_id]\n",
    "        tumor_sample_id = seg_obj.metadata['Kids First Biospecimen ID']\n",
    "        in_dict['input_seg_file'] = seg_obj\n",
    "        in_dict['tumor_sample_id'] = tumor_sample_id\n",
    "        in_dict['sex'] = sex_dict[case_id]\n",
    "        in_dict['somatic_germline_vcf'] = b_dict[case_id]\n",
    "        task_name = 'PureCN CNVKIT SEG INPUT: ' + case_id + ' ' + tumor_sample_id\n",
    "        #pdb.set_trace()\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, execution_settings={'use_memoization': True}, run=False)\n",
    "        task.inputs['output_basename'] = task.id + \"_CNVKIT_SEG\"\n",
    "        task.save()\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        print (\"Skipping due to error:\" + case_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = project + '/cnvkit-theta2-wf'\n",
    "cns_manifest = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/cns_segment-manifest.csv')\n",
    "cnn_manifest = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/cnn_cnvkit-manifest.csv')\n",
    "case_id_list = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_test_set.txt')\n",
    "somatic_germline = open('/Users/brownm28/Documents/2019-Aug-23_cnv_ts/benchmark_run/maris_vardict_vcfs-manifest.csv')\n",
    "case_list = []\n",
    "for line in case_id_list:\n",
    "    case_list.append(line.rstrip('\\n'))\n",
    "case_id_list.close()\n",
    "head = next(cns_manifest)\n",
    "cns_dict = {}\n",
    "for line in cns_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    fid = info[0]\n",
    "    cns_dict[case_id] = api.files.get(fid)\n",
    "head = next(cnn_manifest)\n",
    "cnn_dict = {}\n",
    "for line in cnn_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    fid = info[0]\n",
    "    cnn_dict[case_id] = api.files.get(fid)\n",
    "b_dict = {}\n",
    "tum_id_list = {}\n",
    "norm_id_list = {}\n",
    "head = next(somatic_germline)\n",
    "for line in somatic_germline:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    case_id = info[-2]\n",
    "    norm_id = info[15]\n",
    "    tum_id = info[18]\n",
    "    b_dict[case_id] = api.files.get(info[0])\n",
    "    tum_id_list[case_id] = tum_id\n",
    "    norm_id_list[case_id] = norm_id\n",
    "for case_id in case_list:\n",
    "    try:\n",
    "        in_dict = {}\n",
    "        in_dict['include_expression'] = 'FILTER=\"PASS\" && (INFO/STATUS=\"Germline\" | INFO/STATUS=\"StrongSomatic\")'\n",
    "        in_dict['tumor_cns'] = cns_dict[case_id]\n",
    "        in_dict['reference_cnn'] = cnn_dict[case_id]\n",
    "        in_dict['tumor_ID'] = tum_id_list[case_id]\n",
    "        in_dict['normal_ID'] = norm_id_list[case_id]\n",
    "        in_dict['paired_vcf'] = b_dict[case_id]\n",
    "        task_name = 'Theta2 Run: ' + case_id + ' ' + tumor_sample_id\n",
    "        #pdb.set_trace()\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=in_dict, run=False)\n",
    "        task.inputs['output_basename'] = task.id\n",
    "        task.save()\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        print (\"Skipping due to error:\" + case_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> <ipython-input-67-a4844147d0b8>(2)<module>()->None\n",
      "-> pdb.set_trace()\n",
      "(Pdb) dir(task)\n",
      "['_API', '_URL', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_api', '_data', '_dirty', '_fields', '_modified_data', '_old', '_query', '_serialize_execution_settings', '_serialize_input_list', '_serialize_inputs', '_to_api_file_format', 'abort', 'app', 'batch', 'batch_by', 'batch_group', 'batch_input', 'bulk_get', 'clone', 'create', 'created_by', 'created_time', 'deepcopy', 'delete', 'description', 'end_time', 'equals', 'errors', 'executed_by', 'execution_settings', 'execution_status', 'field', 'get', 'get_batch_children', 'get_execution_details', 'href', 'id', 'inputs', 'name', 'outputs', 'parent', 'price', 'project', 'query', 'reload', 'run', 'save', 'start_time', 'status', 'type', 'use_interruptible_instances', 'wait', 'warnings']\n",
      "(Pdb) p task.stats\n",
      "*** AttributeError: 'Task' object has no attribute 'stats'\n",
      "(Pdb) p task.status\n",
      "'COMPLETED'\n",
      "(Pdb) p task.inputs\n",
      "{'output_basename': '003daa8a-b59f-488c-8606-64754899e990', 'min_frac': 0.01, 'include_expression': 'FILTER=\"PASS\" && (INFO/STATUS=\"Germline\" | INFO/STATUS=\"StrongSomatic\")', 'tumor_cns': <File: id=5d8aca66e4b0950c40282304>, 'tumor_ID': 'BS_4RX1AAVV', 'normal_ID': 'BS_0PQA0GGY', 'paired_vcf': <File: id=5d8ba611e4b097679c333f34>, 'reference_cnn': <File: id=5d8aca66e4b0950c40282312>}\n",
      "(Pdb) p dir(task.inputs['reference_cnn'])\n",
      "['FOLDER_TYPE', '_API', '_URL', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_api', '_data', '_dirty', '_fields', '_modified_data', '_old', '_query', 'bulk_delete', 'bulk_edit', 'bulk_get', 'bulk_update', 'content', 'copy', 'copy_to_folder', 'create_folder', 'created_on', 'deepcopy', 'delete', 'download', 'download_info', 'equals', 'field', 'get', 'href', 'id', 'is_folder', 'list_files', 'metadata', 'modified_on', 'move_to_folder', 'name', 'origin', 'parent', 'project', 'query', 'reload', 'save', 'size', 'storage', 'stream', 'tags', 'type', 'upload']\n",
      "(Pdb) p task.inputs['reference_cnn'].metadata\n",
      "{'gender': 'Female', 'race': 'White', 'ethnicity': 'Not Hispanic or Latino', 'Kids First Participant ID': 'PT_KWRFGRER', 'disease_type': '', 'sample_id': 'GMKF-30-PARTRP03-01A-01D', 'sample_type': 'Tumor', 'platform': '', 'Kids First Biospecimen ID': 'BS_4RX1AAVV', 'Kids First Family ID': 'FM_W6CDBYXE', 'primary_site': '', 'library_id': '', 'aliquot_id': '575267', 'reference_genome': 'GRCh38', 'case_id': 'PARTRP03', 'experimental_strategy': 'WGS'}\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-a4844147d0b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'799d3c7f-73dc-4624-904e-e7aec4e98999'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhold\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_return\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;31m# The user issued a 'next' or 'until' command.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoplineno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "task = api.tasks.get('799d3c7f-73dc-4624-904e-e7aec4e98999')\n",
    "pdb.set_trace()\n",
    "hold =1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
